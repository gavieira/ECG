#+TITLE: Leitura Artigos
#+AUTHOR: Gabriel Alves Vieira
#+BIBLIOGRAPHY: Bibliometry apalike


* Artigo: 40 anos da bibliografia no brasil \cite{mugnaini2013}
** Introdução

- Uma das coisas mais importantes da bibliometria é entender a complexidade do processo de comunicação científica em que estamos inseridos.

- Pergunta: Qual a diferença de bibliometria e biblioteconomia?

- Ciência e seu potencial de propulsionar desenvolvimento socio-economico: Leva à indicadores para mensurar investimento e frutos da ciência e tecnologia (C&T).

- Isso, por sua vez, impacta o planejamento do investimento em C&T. A avaliação contínua e intensa da ciência se torna importante na definição de quem ganha financiamento.

- "Numa economia baseada em conhecimento, a publicação da pesquisa científica torna-se a moeda principal (BOURDIEU, 1994) trazendo consigo os índices e valores dela decorrentes."

- A avaliação científica apresenta então um dilema: Ela deve se valer da praticidade da bibliometria/indices/bases de dados, que podem incitar um alto grau de produtividade, ao mesmo tempo em que não ignora a excelência da pesquisa acadêmica. Ambos podem ser excludentes, dependendo da situação.

- A bibliometria é uma especialidade de outra área já estabelecida: A Ciência da Informação.

** Eventos importantes do desenvolvimento histórico da Bibliometria

- As constantes restrições oramentárias para obter acesso a periódicos foi um dos fatores que levou ao surgimento de técnicas matemáticas/estatísticas para a avaliação da produção científica.

- Primórdios da bibliometria: 1917 - Fracis J. Cole e Nellie B. Eales - "Estatística bibliográfica"

- 1927 - Alfred J Lotka: Lei matemática que diz que frentes de pesquisa são representadas por poucos autores muito produtivos.

- 1928 - P. L. K. Gross, E. M. Gross - Análise baseada em citações (Química). Busca levantar artigos mais relevantes.

- Décadas seguintes - Duas novas leis (muito conhecidas) são publicadas:

  + *Lei de dispersão das publicações de artigos em periódicos* (Samuel C. Bradford - 1934)

    - Tbm chamada "Lei de Bradford". Amplamente usada na bibliometria científica, já q periódicos são o principal veículo de comunicação.

  + Lei de George K. Zipf (1949)

    - Baseada em ranking de frequências de palavras. Muito aplicada na linguística.

- 1955 - Eugene Garfield

  + Publica artigo sobre um índice de citação (parece importante, provavelmente esbarrarei nisso depois)

  + No mesmo artigo, menciona a idéia de fator de impacto de periódicos. Aparentemente, esse tema já foi tratado por outros autores antes, mas foi popularizado por esse artigo de Garfield.

- 1960 - Inúmeros marcos:

  + Termo 'bibliometria' popularizado por Alan Pritchard (mas criado bem antes, em 1934, por Paul Otlet).

  + Criação do Science Citation Index (SCI), por Eugene Garfield, que também transforma a Lei de Dispersão de Bradford na "lei de concentração de Garfield", criando um núcleo de periódicos principais abrangindo a ciência mundial.

  + Garfiled também fundou o *Institute for Scientific Information (ISI)*. Por mais que o nome atual seja Clarivate Analytics (e antes disso, Thomson Scientific), a sigla “ISI” é a referência mais popular.


  + Derek J. de Solla Price: Origem de nova especialidade: a *Cientometria.*

    - 'A Cientometria foi chamada por Price, em 1969, “ciência das ciências”, por estudar o comportamento das ciências, se atendo não apenas às publicações, mas ao sistema de pesquisa como um todo.'

    - Ou seja, a Bibliometria está inserida na Cientometria.

    - A princípio, análises quantitativas da produção científica não atentavam para a política científica, algo que muda na década de 70

- Década de 70: Barateamento de bens associados à informática, ampliação de bancos de dados bibliométricos e grande desenvovlimento na área.

- Década de 80: ampliação das possíveis aplicações da bibliometria. Mapeamentos gráficos e modelagem matemáticas.

** Inserção e desenvolvimento no Brasil

- Artigo pioneiro: Urbizagástegui-Alvarado (1984)

  + Levantamento de trabalhos bibliométricos - 2 leis mais usadas

    - 50% usam a Lei de Bradford

    - 14% usam a Lei de Lotka

  + MACHADO (2007), por outro lado, encontra a Análise de Citação como técnica de análise prevalente. Possivelmente a maior disponibilidade de computadores e poder de processamento...

- Instituto Brasileiro de Informação em CiênciaTecnologia (IBICT) - primeiro indício de institucionalização

- Desenvolvimento da bibliometria (contexto histórico): resposta à importância que passou a ser creditada à informação, não apenas científica, após a segunda guerra mundial.

- "A ciência da informação recorre à disciplinas métricas, como a bibliometria e, mais recentemente, cientometria e infometria." (MACHADO, 2007)

- "Num estudo mais recente, Meneghini e Packer (2010) analisaram a produção científica não apenas em Bibliometria, mas incluíram áreas correlatas como a Cientometria, Informetria, Avaliação de Produção Científica, entre outras, e ainda fizeram uso de fontes de informação com maior abrangência da produção científica nacional – o Google Acadêmico e a Plataforma Lattes – não restringindo a publicações da área de Ciência da Informação."

  + *Ou seja, Bibliometria e Avaliação da Produção científica podem ser consideradas coisas distintas?*

- Dicas de periódicos (onde os brasileiros publicam mais):

  + Nacional: Ciência da Informação

  + Internac: Scientometrics

- Bibliometria é parte da ciência da informação, mas é útil à comunidade científica como um todo, permitindo compreender e criticar a política científica nacional e seus métodos de avaliação.

** Fontes de informação e indicadores bibliométricos para subsídio à política científica brasileira

- Brasil da década de 70: Concepção e desenvolvimento de um sistema de desenvolvimento científico e tecnológico. O que gera, por sua vez, uma nova classificação de periódicos (que na verdade foi um fênomeno internacional)

- No Brasil, surge o sistema de avaliação de periódicos QUALIS, extensamente abordado no artigo...

- Outras iniciativas citadas:

  + Web of Science - Interface de acesso ao Science Citation Index (SCI)

    - O SCI, por sua vez, apresenta 3 versões: (i) Science, (ii) Social Sciences e Arts & Humanities e (iii) Journal Citation Reports (JCR)

    - WoS correu atrás de periódicos regionais. Ex:

      + " O total de periódicos brasileiros indexados na WoS, que em 2005 era 27, alcança um total de 132 em 2010 (TESTA, 2011)."

  + Portal de Periódicos da CAPES (Periodicos nacionais e internacionais)

  + SciELO (Scientific Electronic Library Online) - Foco em periódicos nacionais

  + JCR - O que é?

  + Google Scholar

    - Gratuito (como tudo da google)

    - Alta capacidade de recuperação de artigos não encontrados nos índices tradicionais

  + Scopus

    - Da editora comercial Elsevier (assim como o Mendeley)

    - Cobertura abrangente: periódicos nacionais e regionais.

    - Indexa grande número de periódicos nacionais (especialmente após parceria com SCImago)

- Indicadores dessas bases passaram a compor a avaliação da produção científica Brasileira. O Qualis passou por mudanças, por exemplo. É importante se manter atento a essas mudanças, que nos afetam diretamente.

- Índice h

  + Criado por Jorge E. Hirsch para comparação entre pesquisadores.

  + Quase automaticamente adaptado para analisar periódicos

  + Disponibilizado por Web of Science e Scopus.

  + Assim como o fator de impacto, sua simplicidade metodológica fez com que esse índice extrapolasse a bolha dos especialistas em cientometria.

  + Tanto é que vários outros índices criados pela *International Society for Informetrics and Scientometrics (ISSI)* não são conhecidos pela comunidade científica.

- Muganini e Sales (2011):

  + ìndices de citação são os principais indicadores usados na avaliação da produção científica nacional.

  + Fator de impacto das revistas também é mto considerado, apesar de estar sempre sujeitos à inúmeras críticas

  + Índice H não é tão usado, muito embora componha critérios de algumas áreas, como no caso das ciencias da saude.

** Críticas à consagração de um indicador: alternativas e o ferramental metodológico disponível

- JCR - Journal Citation Index. Periódico anual que dá informações sobre os mais diversos periódicos das ciencias naturais e sociais, assim como provê os *fatores de impacto* dessas revistas.

- A publicação do JCR, desde 1975, pelo ISI, reforça a proeminencia das revistas/artigos/ciencia /mainstream/. Isso, em grande parte, pelo fator de impacto, o qual vem sendo cada vez mais criticado nas mais diversas publicações.

- 5 críticas predominantes:

  1. Originalmente desenvolvido para desenvolvimento de coleções, não para avaliação;

  2. Incomparabilidade, dadas as especificidades entre áreas;

  3. Assimetria entre elementos contados no numerador e denominador;

  4. Janela de citação de dois anos;

  5. Estabelecimento da língua inglesa e centralização americana.

- O terceiro fator pode ser manipulado por revistas para aumentar seu fator de impacto.

- Revistas geralmente rejeitam publicações que potencialmente não serão tão citadas pq poucas citações levam a quedas no fator de impacto

- Há casos mais extremos, como revistas especializadas que passaram a não publicar nenhum artigo de caso clínico, já que esses geralmente não são tão citado. Uma decisão completamente editorial.

- O corpo editorial da revista usou isso para tentar aumentar de forma forçosa o fator de impacto. É basicamente um jogo editorial para aumentar o numerador e diminuir o denominador do fator de impacto.

- O denominador restringe os tipos de artigos considerados, mas o numerador não. Logo, outra estratégia para "inflar" o fator de impacto é a publicação de bons editoriais, alatamente citáveis.

- Glänzel e Moed (2002):

  + Autores falam como o uso do fator de impacto está associado à fatores como "facilidade de compreensão" (afinal, é apenas a média de citações recebidas pelos artigos do periódico), "robustez" e "rápida disponibilidade".

  + Mas tbm falam de limitações, como "a falta de normalização das práticas de referência; a não discriminação de artigos de revisão, que são muito mais citados; a incapacidade de uma única medida de aferir padrões de citação de periódicos; e o problema da frequente utilização do FI isolado do seu contexto (MOED, 2005)."


- Também há várias ressalvas sobre o quão estatísticamente válido é usar apenas a média de citações como indicador do impacto de uma revista.

- Quando o FI é usado, comumente não são usados testes estatísticos para validá-lo (Frank - 2003)

- Seria a média uma medida adequada, já que há uma grande discrepancia no numero de citações de diferentes artigos? (Colquhoun 2003)

- Sem falar que algumas áreas simplesmente possuem menos pessoas trabalhando nelas. Logo, o número de citações (e impacto das revistas/artigos) acaba não refletindo a qualidade da pesquisa.

- Assumir que fator de impacto significa qualidade de um dado periodico é muito propenso a erro, já que isso implica "assumir perfeita comunicação na comunidade científica internacional" (Velho, 1986). Assumir que todos os pesquisadores de todas as áreas possuem igual probabilidade de citar o seu artigo, independente da área de atuação dos mesmos.

- "Saha, Saint e Christakis (2003) mencionam que o FI reflete a reputação de um periódico, mais do que sua qualidade." Eu adicionaria que reflete a popularidade dos periódicos tbm...

- De forma geral, indicadores bibliometricos podem medir impacto, mas não qualidade. E os índices, dentre eles o fator de impacto de periódicos, podem sim ser úteis quando usados cuidadosamente.

- Todas essas críticas ao FI vem levando à criação e adoção de indicadores alternativos.

- Boa parte do trabalho dos bibliometristas é converter a informação bibliogŕafica em bibliometrica. "A primeira, fiel ao manuscrito do autor, com seus códigos, abreviações e erros; e a segunda, exige cuidadosa padronização para garantia da qualidade da análise quantitativa"

- Com o avanço e barateamento de ferramentas/computadores, vivemos em uma era da "bibliometria de escritório", impossível há alguns anos. Uma era onde dá pra fazer coisas interessantes na área com um computador na mão e uma idéiana cabeça.

- O movimento Open Source e Open Access também desempenham funções importantes nisso.

** Considerações finais

- Países cuja publicação científica é sub-representada no contexto internacional devem dar um grande peso a métricas como o Fator de Impacto na definição de políticas públicas de financiamento científico?

- É mto comum nas agências de fomento a premiação pela publicação em periódicos de "alto impacto"

- Apesar disso, o sistema de avaliação feito pela Capes continua mudando e se adequando à novos contextos. Assim sendo, é no mínimo desejável que a comuniade científica se envolva em discussões sobre o tema.

- O autor sugere que uma possivel causa da diminuição do uso da lei de bradford é o uso das bases de dados, que estabelecem as revistas importantes de uma dada área. Mas será que as bases de dados estão definindo bem as coleções de periódicos especializados? Será que não estamos "confortaveis" com o que nos é servido?

- Mais do que isso, será que os periódicos são uma boa unidade de avaliação? Ou deveríamos passar a considerar a análise a nível de artigo como uma alternativa?

* Livro: \cite{mugnaini2017a}

- Pular artigo “Avaliação Institucional na USP”.

** Discussões gerais sobre as características mais relevantes de infraestruturas de pesquisa para a cientometria

- Bibliometria/cientometria envolvem custos substanciais. Ter uma infraestrutura adequada à pesquisa bibliométrica "profissional" tem um grande custo envolvido.

- Pesquisar diferença entre cientometria, bibliometria, tecnometria (associado à patentes) e altmetria (métrica baseada no uso  de fontes de dados alternativos, comumente associado à recepção da ciência em outras fontes, como redes sociais), webometria...

** Rumo a indicadores para ‘abertura’ de políticas de ciência e tecnologia1

- Fala na introdução como o uso simplista de metricas vem sendo criticado, e como está havendo um empenho para melhorar a robustez das métricas, com incorporação dos mais diversos dados, como os altmétricos ou a adição de periódicos nacionais/regionais. Em suma, devem ter mais inputs.

- "Com isso, as comunidades de indicadores e de políticas da C&T voltaram a acreditar que a cientometria deve contar com múltiplas fontes de dados que podem proporcionar ‘indicadores parciais convergentes’ (MARTIN; IRVINE, 1983)."

- Aumentar os inputs tbm aumenta os outputs, o que adiciona possiblidade de interpretações contrastantes e abre margem para viéses (mas ainda assim menos do que quando não há discussão), mas tbm permite tomar decisões mais ponderadas.

- Cita artigo que *não é de review* (RAFOLS et al. 2012) para ilustrar o aumento dos inputs e seu impacto nos outputs.

- Indicadores como "dispositivos discutíveis, que permitam aprendizado" (Barré, 2010, pg.227)

- Duas dimensões:

  + Amplitude: Associada ao número de inputs

  + Abertura: O quanto que os outputs permitem interpretações plurais e opções de políticas contrastantes a serem debatidas. Quanto maior a abertura, menor a tendência de busca por uma única melhor explicação, método ou resposta. É mais holístico.

- A avaliação cientpométrica convencional tende a ser bastante estreita nas duas dimensões.

- Mesmo quando a análise é ampla, ela perde abertura ao sumarizar os inputs em uma única medida. Essa transformação limita a discussão sobre desempenho e define de maneira inequívoca qual universidade/pesquisador é "melhor". Para além disso, essa redução tbm é mais sujeita a viéses.

- O contrário pode ser verdade: a análise pode não ser ampla, mas conceitualizar/operacionalizar seus outputs de forma a gerar suposições/resultados constrastantes.

- Apesar de haver desafios associados à maior amplitude ae abertura, como a questão da visualização dos dados (é difícil fazer uma redução de dimensão quando os resultados vêm de fontes de dados muito distintas, muito embora seja possível operacionalizar eles de forma distinta), é importante evitar que ‘Medidas estatísticas tendem a substituir o debate político pelo conhecimento técnico’ (MERRY, 2011). Sob essas circunstâncias, torna-se imperativo que hajam debates mais abertos envolvendo as escolhas normativas cruciais subjacentes aos indicadores (BARRÉ, 2010). Com isso, teremos avaliações mais rigorosas e confiáveis.

** A pesquisa bibliométrica na era do big data: Desafios e oportunidades

- Nem sempre mais é melhor. Dados podem ter diferentes qualidades.

- Assim como em qqr análise estatística, as conclusoes tiradas da análise se aplicam somente à amostra utilizada. Características das amostras mudam dependendo do subset utilizado (parametros de est. descritiva e outros)

- Um grande desafio da bigdata bibliometrica é a aplicação de metodologias para limpeza/análise/visualização de dados

- Visualização dos dados também é complexo. Muitas dimensões, que geralmente devem ser reduzidas ao msm tempo em que mantêm as relações observadas. Várias técnicas são usadas para simplificar a representação dos dados, como *análise de agrupamento* e *análise fatorial para dados quantitativos*, assim como *métodos baseados em linguagem*.

- A análise dos dados tbm é um ponto complicado, já que a enorme diversidade de análises/metodologias disponíveis permitem que os pesquisadores cheguem a diversos resultados com os mesmos dados. Logo, a adequação da escolha metodológica deve ser justicada caso a caso.

- Mas as oportunidades são enormes também. Há mtos dados e porgramas disponíveis para trabalhar com esse crescente contingente de informação bibliográfica.

- Redes de citações: Extremamente usada, mas tem uma desvantagem: se não há citação, não há relação. Assim sendo, pesquisadores que não se conhecem/citam, mas estão na mesma área ou compartilham interesses não têm suas similaridades identificadas por esse tipo de análise.

- Análise de linguagem: primeiramente, usava co-ocorrência de palavras em títulos ou palavras-chave para estabelecer relações. Hj, com Natural Language Processing e afins, essas análises passam a ser passíveis de serem utilizadas em textos integrais. Também há outras abordagens, como *comparações baseadas em texto utilizando modelagem de tópicos (WALLACH, 2006)*. Métodos baseados em texto e em citações podem se complementar.

** Avaliação Institucional na USP

- Vários pormenores sobre os tipos de avaliação institucional e como esse processo se dá na USP. Não é mto interessante.


** Políticas Públicas em Ciência e Tecnologia no Brasil: desafios e propostas para utilização de indicadores na avaliação

- Fala sobre o sistema de avaliação da pós-graduação brasileira (realizado pela CAPES) em detalhe.

- Parece um bom artigo para ser adicionado aos principais...

- Artigo recomendado: "Dez coisas que você deveria saber sobre o Qualis"

* Artigo \cite{roldan-valadez2019}

- Paper fala sobre o uso de medidas bibliométricas para escolher a revista mais adequada para o seu paper baseado em impacto e prestígio.
- "Since there is a journal performance market and an article performance market, each one with its patterns, an integrative use of these metrics, rather than just the impact factor alone, might represent the fairest and most legitimate approach to assess the influence and importance of an acceptable research issue, and not only a sound journal in their respective disciplines."
- Autor fala que, apesar das críticas ao fator de impacto das revistas por vários acadêmicos, é fato que os autores geralmente dão grande importância ao fator de impacto em suas decisões sobre onde submeter os manuscritos.
- Daí, começa a falar sobre as mais diversas métricas. Histórico, como elas são calculadas, quem está interessado na mesma, seus pontos fortes e críticas.

** Metricas (journals)
  + IF
    - Publicado anualmente pelo Journal Citation Reports (JCR)
    - Descrição bem detalhada sobre o indicador. Ótima tabela que fala das condições que impactam o IF. Fala sobre a questão das cartas e editoriais e como eles podem ser contados no numerador se citados, mas não no denominador.
    - Inclusive, faz sentido esses itens não serem contados, pois normalmente não são citados mesmo, e adicioná-los diminuiria artificialmente o fator de impacto. Entretanto, do jeito que está, as revistas com mais prestígio tendem a ter seu IF inflado (todo mundo envia cartas e geralmente tem bons editoriais). Tbm abre margem para inchar esse valor ao aumentar o numero de editoriais e priorizar artigos de revisão. Não seria mais interessante considerar citações desse tipo de documento separadamente, em outra métrica, que seja?
    - Também fala de como, para o IF, a distribuição das citações é não-paramétrica. E na verdade, menos de 20% dos artigos concentram mais de 50% das citações.
  + Cited Half-Life
    - Medida da taxa de declínio da curva de citação
  + CiteScore (Uma nova forma de se avaliar o impacto das revistas - Está ganhando mta projeção. Talvez a evolução do IF?)
    - Incorpora SCImago journal rank e Source-Normalised IMpact per paper
  + SCImago journal rank (SJR)
    - Ao contrário do IF, que não dá peso para as citações, ele dá um peso maior para citações dos journals com maior SJR.
  + Source-Normalised Impact per paper (SNIP)
    - Calcula impacto por citação ao mesmo tempo que considera o total de citações de uma área.
    - Janela de publicação maior (3 anos)
    - Permite comparação entre áreas diferentes
  + Eigenfactor metrics
    - Consiste no Eigenfactor score e Article Influence. Disponiveis para o JCR depois de 2007
    - Tem uma ótima tabela comparando os dois tbm
  + Eigenfactor score (ES)
    - Num de vezes artigos de uma dada revista q foram publicados nos ultimos 5 anos foram citados nesse ano (JCR - IF year).
    - Citações têm peso diferente, dependendo do journal. Journal self-citation removidas (só são consideradas citações de uma revista para outra).
    - Algoritmo complexo, similar a Google Page Rank
    - Calcula disseminção do artigo
    - Não tem denominador. Logo, é sensível à quantidade de itens citáveis. Em outras palavras, revistas com mais artigos tendem a ter ES maior.
  + Article INfluence Score (AIS)
    - Baseado no ES
    - Determina a influencia dos artigos de um jornal após os 5 anos da data de publicação dos mesmos.
    - Ao contrário do ES, ele possui numerador e denominador
    - Cálculo: ES dividido pelo num de artigos no jornal, normalizado como fração de todos os artigos
  + Immediacy Index
    - Mede o quanto que artigos recentes de um journal são citados. Ou seja, o quão rápido esses papers desses journals estão sendo adotados na literatura.

** Métricas (Pesquisador)

- H-index
  + Combina produtividade e impacto
  + Criado para avaliar autores, mas pode ser usado para qr conjunto de documentos (ex: publicações de um departamento)
  + Os outros indices tentam abordar problemas/limitações específicas do H-index
- G-index
- HC-index
- Individual H-index
- E-index
- M-index
- Q-index

** Altmetrics
- "Altmetrics covers not just citation counts but also various other aspects of the impact of an article such as how many data and knowledge bases refer to it, article views, full-text down- loads, Facebook likes, or mentions in social media and news media [78]."

** Proposed method to use bibliometrics

- Os autores tbm sugerem um pipeline/metodologia para planejar em qual revista sumeter o trabalho, acompanhar a importancia do paper e ter uma perspectiva sobre a performance anos depois.
- Essa é uma abordagem mais integrativa, que não se baseia apenas no IF.
- Talvez ler para entender isso melhor depois...


* Artigo: \cite{wang2019}

- Bibliometria só diz respeito à avaliação do impacto de artigos dentro da academia, mas não versa sobre a influencia de pesquisadores fora da academia, e o nome dos autores (para além de outros fatores) estão associados ao quanto os papers são citados. A altmetria tbm visa uma medição do impacto da pesquisa em uma esfera mais social. Um dos maiores beneficios da altmetric é seu potencial de mensurar o impacto mais amplo da pesquisa, aquele que vai para além do meio científico.
- Janela de 3 anos: aparenetemente, bom período para todas as áreas:
  + "And according to Glänzel (2008), the use of a 3-year citation window is “a good compromise between the fast reception of life science and technology literature and that of the slowly ageing theoretical and mathematical subjects”" - artigo dos sete mitos
- Usa uma combinação de preditores obtidos a partir de índices bibliométricos e altmétricos nos primeiros dois anos após a publicação dos artigos para predizer quais artigos se tornarão altamente citados. Consegue fazer isso com um bom poder de predição com as abordagens de machine learning utilizadas. Chega à conclusão que os melhores preditores englobam tanto ínidices altmetricos quanto bibliométricos (muito embora os bibliométricos sejam a maioria, usar ambos parece aumentar o poder de previsão).


* Artigo: \cite{eysenbach2006}

- Duas opções para tornar o paper público: Open Acess ou Self-Archive.
- Mas será que o fato do paper estar público tem impacto no quanto ele é citado?
- OBS: Papers com mais autores: tendem a ser mais citados, isso pode vir de mais autocitações e/ou pelo paper ter de fato maior qualidade (mais pessoas trabalharam nele, afinal)
- Trabalho mostra que o paper estar em open access aumenta a immediacy - o quanto que ele é citado no começo da sua vida. Mas também parece aumentar a quantidade de citações de forma geral.


* Artigo (review): \cite{pendlebury2009}

- Dá um resumo dos marcos históricos da bibliometria. Dos poloneses, passando por Garfield até o estabelecimento de centros de pesquisa na área.
- Esse autor diz que bibliometria e cientometria são nomes usados para a mesma coisa.
- Sugere o livro "Citation Analysis in Research Evaluation", por Henk F. Moed, como um bom review do campo da bibliometria até o ano de 2005.
- JCR não tem apenas o IF das revistas. Tem tbm várias outras informações/métricas, como o immediacy index e meia-vida de citação.
- Logo, usar o fator de impacto sozinho para definir onde publicar ou o valor de um artigo não é justificado, já que mesmo a revista que gera o fator de impacto gera tantas outras métricas que poderiam ser levadas em consideração. (E diga-se de passagem, mesmo o Garfield sempre disse que o fator de impacto é só mais uma métrica, e que não deveria (mas possivelmente seria) ser usada para classificar artigos)
- Críticas sobre o Fator de Impacto com relação a como esse é usado (erroneamente) para dar juízo de valor sobre artigos individuais devem ser direcionadas às pessoas que fazem esse mal uso da métrica, não à métrica em si...
- "H-index, v-index, g-index, y-index, Eigenfactor, audi- ence-factor: What is the non-bibliometrican to think of this mélange of measures? It is important to recognize that different measures attempt to answer different questions and that each will emphasize or highlight cer- tain aspects and nuances of a phenomenon. This is not to deny that some measures may be better, in general terms, than others. There is certainly room for advance- ment in terms of new and better measures. But it is also necessary to point out that there is a fallacy in demanding a single-number metric or just one approach to analysis. "
- "O q as citações medem, afinal?" - Pergunta é abordada em um livro \cite{moed2006}
- Citações representam noções de uso, recepção, utilidade, influencia, e o nebuloso termo "impacto". Citações, entretanto, *não representam medidas de qualidade*. Para averiguar a qualidade de um trabalho, *é estrtitamente necessario o julgamento humano*, por mais que ele possa ter seus viéses e problemas.

* Artigo (review): \cite{waltman2016}
- Fala bastante sobre databases bibliograficas (WoS, Scopus e Google Scholar)
- Depois, fala sobre indicadores de impacto baseados em citação
- Paper enorme (não vou passar pra banca), mas explica tudo nos mínimos detalhes. Bom ler para preparar a apresentação
- Fala muito sobre janela de citação, auto-citação, normalização... Muito bom

* Artigo (review): \cite{tahamtan2016}
- Autor fala muito sobre a importância das citações para mensurar  a qualidade de um artigo, sendo que a citação não mede isso... Mas dá uma cutucada nessa visão simplista dps. Dps ele até comenta que diferentes pesquisadores terão diferentes opiniões sobre o q exatamente é qualidade.
- Basicamente, a qualidade da análise estatistica do paper não impacta o numero de citações
- Paper com equações diferenciais e mtas notas de rodapé tendem a ter menos citações

* IDEIAS

- Falar sobre a institucionalização da ciência e como o lab adotou uma ideologia capitalista (desenterrar os textos do Rômulo)
- Citações são diferentes entre si: algumas são para isso, algumas para aquilo. E se houvesse uma forma de classificação de citações, para atribuir pesos diferentes a elas? Agora, com uma cada vez maior disponibilidade de artigos full-text, isso se torna cada vez mais uma possibilidade.
- Pq as pessoas continuam usando tanto o IF? Bom, pq as pessoas continuam adotando 0,05 como limiar de significância para teste estatístico? Meio que se tornou uma convenção. Algo que as pessoas nem param para pensar sobre.
- Será que tem algum artigo que eu possa usar no arquivo de srtigos do reproducibilitea?
- Encontrar artigos sobre:
  + Os manifestos sobre a bibliometria
  + Os bancos de dados usados
  + Softwares usados (citnetexplorer, publish or perish...)
- Tentar pesquisar no web of science/scielo/scientometrics por artigos de revisão
- Pesquisar depois qual o fator de impacto para que a pós pague pelo artigo. E discutir que usar só isso como critério é um mal uso do fator de impacto, pois publicar numa revista de alto impacto não significa que o artigo é de qualidade ou que será bem citado.
- Nas métricas bibliometricas para revistas, falar pelo menos do IF e (claro) do QUALIS
- Mostrar (com exemplos) que muito da vida moderna envolve caracterização de atividades humanas em termos de estatísticas. Daí falar que o mesmo é válido para a ciência.
- Problema editorial: Quando os pesos são diferentes por revista, e isso é usado para dar peso à citações, isso não torna o IF algo recursivo? Como que uma nova revista irá surgir e aumentar seu impacto sem as falcatruas dos editoriais e afins?
- Como o fator de impacto é uma consequencia e tbm uma causa de citações, pode ser complicado trabalhar (só) com ela.

*TODO

Estudar melhor o que é o Science Citation Index (SCI) e suas divisões, JCR e ISI.






\bibliography{Bibliometry}
\bibliographystyle{apalike}
