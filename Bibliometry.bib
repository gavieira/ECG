
@article{abramo2011,
  title = {Evaluating Research: From Informed Peer Review to Bibliometrics},
  shorttitle = {Evaluating Research},
  author = {Abramo, Giovanni and D'Angelo, Ciriaco Andrea},
  year = {2011},
  month = jun,
  volume = {87},
  pages = {499--514},
  issn = {0138-9130, 1588-2861},
  doi = {10.1007/s11192-011-0352-7},
  abstract = {National research assessment exercises are becoming regular events in ever more countries. The present work contrasts the peer-review and bibliometrics approaches in the conduct of these exercises. The comparison is conducted in terms of the essential parameters of any measurement system: accuracy, robustness, validity, functionality, time and costs. Empirical evidence shows that for the natural and formal sciences, the bibliometric methodology is by far preferable to peer-review. Setting up national databases of publications by individual authors, derived from Web of Science or Scopus databases, would allow much better, cheaper and more frequent national research assessments.},
  file = {/home/gabriel/Dropbox/zotero-library/Abramo_D’Angelo_2011_Evaluating research.pdf},
  journal = {Scientometrics},
  language = {en},
  number = {3}
}

@article{abramo2019,
  title = {Peer Review versus Bibliometrics: {{Which}} Method Better Predicts the Scholarly Impact of Publications?},
  shorttitle = {Peer Review versus Bibliometrics},
  author = {Abramo, Giovanni and D'Angelo, Ciriaco Andrea and Reale, Emanuela},
  year = {2019},
  month = oct,
  volume = {121},
  pages = {537--554},
  issn = {0138-9130, 1588-2861},
  doi = {10.1007/s11192-019-03184-y},
  abstract = {In this work, we try to answer the question of which method, peer review versus bibliometrics, better predicts the future overall scholarly impact of scientific publications. We measure the agreement between peer review evaluations of Web of Science indexed publications submitted to the first Italian research assessment exercise and long-term citations of the same publications. We do the same for an early citation-based indicator. We find that the latter shows stronger predictive power, i.e. it more reliably predicts late citations in all the disciplinary areas examined, and for any citation time window starting 1 year after publication.},
  file = {/home/gabriel/Dropbox/zotero-library/Abramo et al_2019_Peer review versus bibliometrics.pdf},
  journal = {Scientometrics},
  keywords = {todo},
  language = {en},
  number = {1}
}

@article{abramo2019a,
  title = {Predicting Publication Long-Term Impact through a Combination of Early Citations and Journal Impact Factor},
  author = {Abramo, Giovanni and D'Angelo, Ciriaco Andrea and Felici, Giovanni},
  year = {2019},
  month = feb,
  volume = {13},
  pages = {32--49},
  issn = {1751-1577},
  doi = {10.1016/j.joi.2018.11.003},
  abstract = {The ability to predict the long-term impact of a scientific article soon after its publication is of great value towards accurate assessment of research performance. In this work we test the hypothesis that good predictions of long-term citation counts can be obtained through a combination of a publication's early citations and the impact factor of the hosting journal. The test is performed on a corpus of 123,128 WoS publications authored by Italian scientists, using linear regression models. The average accuracy of the prediction is good for citation time windows above two years, decreases for lowly-cited publications, and varies across disciplines. As expected, the role of the impact factor in the combination becomes negligible after only two years from publication.},
  file = {/home/gabriel/Dropbox/zotero-library/Abramo et al_2019_Predicting publication long-term impact through a combination of early.pdf},
  journal = {Journal of Informetrics},
  keywords = {Bibliometrics,Citation time window,Regression analysis,Research assessment},
  language = {en},
  number = {1}
}

@article{abramo2020,
  title = {Informed Peer Review for Publication Assessments: {{Are}} Improved Impact Measures Worth the Hassle?},
  shorttitle = {Informed Peer Review for Publication Assessments},
  author = {Abramo, Giovanni and D'Angelo, Ciriaco Andrea and Felici, Giovanni},
  year = {2020},
  month = aug,
  volume = {1},
  pages = {1321--1333},
  issn = {2641-3337},
  doi = {10.1162/qss_a_00051},
  abstract = {In this work we ask whether and to what extent applying a predictor of a publication's impact that is better than early citations has an effect on the assessment of the research performance of individual scientists. Specifically, we measure the total impact of Italian professors in the sciences and economics over time, valuing their publications first by early citations and then by a weighted combination of early citations and the impact factor of the hosting journal. As expected, the scores and ranks of the two indicators show a very strong correlation, but significant shifts occur in many fields, mainly in economics and statistics, and mathematics and computer science. The higher the share of uncited professors in a field and the shorter the citation time window, the more recommendable is recourse to the above combination.},
  file = {/home/gabriel/Dropbox/zotero-library/Abramo et al_2020_Informed peer review for publication assessments.pdf},
  journal = {Quantitative Science Studies},
  number = {3}
}

@article{aksnes2004,
  title = {Peer Reviews and Bibliometric Indicators: {{A}} Comparative Study at a {{Norwegian University}}},
  shorttitle = {Peer Reviews and Bibliometric Indicators},
  author = {Aksnes, Dag and Taxt, Randi Elisabeth},
  year = {2004},
  month = apr,
  volume = {13},
  pages = {33--41},
  doi = {10.3152/147154404781776563},
  abstract = {This study investigates the relationship between bibliometric indicators and the outcomes of peer reviews. Based on a case study of research groups at the University of Bergen, Norway, we examine how various bibliometric indicators correlate with evaluation ratings given by expert committees. The analysis shows positive but relatively weak correlations for all the selected indicators. Particular attention is devoted to the reasons for the discrepancies. We find that shortcomings of the peers' assessments, of the bibliometric indicators, as well as lack of comparability, can explain why the correlation was not stronger.},
  file = {/home/gabriel/Dropbox/zotero-library/Aksnes_Taxt_2004_Peer reviews and bibliometric indicators.pdf},
  journal = {Research Evaluation - RES EVALUAT}
}

@article{andrade2009,
  title = {{QUALIS: Quo Vadis?}},
  shorttitle = {{QUALIS}},
  author = {de Andrade, Jailson B. and Galembeck, Fernando},
  year = {2009},
  volume = {32},
  pages = {5--5},
  publisher = {{Sociedade Brasileira de Qu\'imica}},
  issn = {0100-4042, 0100-4042, 1678-7064},
  doi = {10.1590/S0100-40422009000100001},
  file = {/home/gabriel/Dropbox/zotero-library/Andrade_Galembeck_2009_QUALIS.pdf},
  journal = {Qu\'imica Nova},
  language = {pt}
}

@book{andres2009,
  title = {Measuring Academic Research: How to Undertake a Bibliometric Study},
  shorttitle = {Measuring Academic Research},
  author = {Andr{\'e}s, Ana},
  year = {2009},
  publisher = {{Chandos Publishing}},
  address = {{Oxford}},
  abstract = {Many analyses have been applied in relation to bibliometric studies, but few have shown how to actually carry out the analysis. This book shows how to undertake a bibliometric study, providing a guide from the first step in which the study has to be set, to the analysis and interpretation},
  annotation = {OCLC: ocn370609754},
  file = {/home/gabriel/Dropbox/zotero-library/Andrés_2009_Measuring academic research.pdf},
  isbn = {978-1-84334-528-2 978-1-84334-529-9},
  keywords = {Bibliometría,Bibliometrics,Bibliometrie,Methode,Methodology,Onderzoek},
  lccn = {Z669.8 .A65 2009}
}

@article{araujo2006,
  title = {{Bibliometria: evolu\c{c}\~ao hist\'orica e quest\~oes atuais}},
  shorttitle = {{Bibliometria}},
  author = {Ara{\'u}jo, Carlos A. A.},
  year = {2006},
  month = dec,
  volume = {12},
  pages = {11--32},
  issn = {1808-5245},
  abstract = {Promove-se uma an\'alise do campo de conhecimento intitulado bibliometria. Inicialmente, s\~ao vistas as tr\^es leis fundadoras do campo, a lei de produtividade de autores de Lotka, a lei de dispers\~ao de peri\'odicos de Bradford e a lei de freq\"u\^encia de palavras de Zipf, bem como seus desdobramentos e aplica\c{c}\~oes em tempos recentes. S\~ao tamb\'em vistos a teoria epid\^emica e a an\'alise de cita\c{c}\~oes, tamb\'em em suas aplica\c{c}\~oes contempor\^aneas, como por exemplo os estudos de frente de pesquisa e fator de impacto. Por fim, analisa-se o desenvolvimento deste campo de estudos no Brasil e as tend\^encias atuais, com destaque para as abordagens que buscam ampliar o escopo dos estudos realizados integrando os m\'etodos bibliom\'etricos a distintos corpos te\'oricos.},
  copyright = {Direitos autorais},
  file = {/home/gabriel/Dropbox/zotero-library/Araújo_2006_Bibliometria.pdf},
  journal = {Em Quest\~ao},
  keywords = {análise de citações,Bibliometria,Bibliometría. Ley de Lotka. Ley de Bradford. Ley de Zipf. Análisis de citaciones. Factor de impacto.,Bibliometrics,Bradford’s Law,Citation analysis,fator de impacto,fav,Impact factor,Lei de Bradford,Lei de Lotka,Lei de Zipf,Lotka’s Law,top5,Zipf’s Law},
  language = {pt},
  number = {1}
}

@article{araujo2020,
  title = {{Novo Qualis: rumos e rumores}},
  shorttitle = {{Novo Qualis}},
  author = {Araujo, Valdei},
  year = {2020},
  month = dec,
  volume = {40},
  pages = {7--9},
  publisher = {{Associa\c{c}\~ao Nacional de Hist\'oria - ANPUH}},
  issn = {0102-0188, 0102-0188, 1806-9347},
  doi = {10.1590/1806-93472020v40n85-00},
  file = {/home/gabriel/Dropbox/zotero-library/Araujo_2020_Novo Qualis.pdf},
  journal = {Revista Brasileira de Hist\'oria},
  language = {pt}
}

@article{asongu2016,
  title = {A {{Brief Future}} of {{Time}} in the {{Monopoly}} of {{Scientific Knowledge}}},
  author = {Asongu, Simplice A. and Nwachukwu, Jacinta C.},
  year = {2016},
  month = dec,
  volume = {58},
  pages = {638--671},
  issn = {1478-3320},
  doi = {10.1057/s41294-016-0008-y},
  abstract = {This paper provides global empirical evidence on cross-country differences in scientific and technical publications. Its purpose is to model the future of scientific knowledge monopoly in order to understand whether the impressive growth experienced by latecomers in the industry has been accompanied by a similar catch-up in scientific capabilities and knowledge contribution. The empirical evidence for the period 1994\textendash 2010 is based on 41 panels which together consist of 99 countries. The large dataset allows us to disaggregate countries into fundamental characteristics based on income levels (high-income, lower-middle-income, upper-middle-income and low-income), legal origins (English common-law, French civil-law, German civil-law and Scandinavian civil-law) and regional proximity (South Asia, Europe and Central Asia; East Asia and the Pacific; Middle East and North Africa; Latin America and the Caribbean and Sub-Saharan Africa). Three main issues are investigated: the presence or not of catch-up processes, the speed of the catch-up processes and the time needed for a complete elimination of country differences in scientific and technical publications. The findings based on absolute and conditional catch-up patterns broadly show that advanced countries will continue to dominate in scientific knowledge contribution. Policy implications are discussed.},
  file = {/home/gabriel/Dropbox/zotero-library/Asongu_Nwachukwu_2016_A Brief Future of Time in the Monopoly of Scientific Knowledge.pdf},
  journal = {Comparative Economic Studies},
  keywords = {todo},
  language = {en},
  number = {4}
}

@article{ayres2020,
  title = {Speaking up for {{Mental Health}}},
  author = {Ayres, Zo{\"e} and Welsh, Andrea and Tijdink, Joeri},
  year = {2020},
  month = aug,
  volume = {13},
  publisher = {{American Physical Society}},
  abstract = {Three advocates for combatting mental-health issues in academia share ideas for making a more supportive community.},
  copyright = {\textcopyright 2020 by the American Physical Society. All rights reserved.},
  journal = {Physics},
  keywords = {fav,todo},
  language = {en}
}

@article{baccini2020,
  title = {On the Agreement between Bibliometrics and Peer Review: {{Evidence}} from the {{Italian}} Research Assessment Exercises},
  shorttitle = {On the Agreement between Bibliometrics and Peer Review},
  author = {Baccini, Alberto and Barabesi, Lucio and De Nicolao, Giuseppe},
  year = {2020},
  volume = {15},
  pages = {e0242520},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0242520},
  abstract = {This paper analyzes the concordance between bibliometrics and peer review. It draws evidence from the data of two experiments of the Italian governmental agency for research evaluation. The experiments were performed by the agency for validating the adoption in the Italian research assessment exercises of a dual system of evaluation, where some outputs were evaluated by bibliometrics and others by peer review. The two experiments were based on stratified random samples of journal articles. Each article was scored by bibliometrics and by peer review. The degree of concordance between the two evaluations is then computed. The correct setting of the experiments is defined by developing the design-based estimation of the Cohen's kappa coefficient and some testing procedures for assessing the homogeneity of missing proportions between strata. The results of both experiments show that for each research areas of science, technology, engineering and mathematics the degree of agreement between bibliometrics and peer review is-at most-weak at an individual article level. Thus, the outcome of the experiments does not validate the use of the dual system of evaluation in the Italian research assessments. More in general, the very weak concordance indicates that metrics should not replace peer review at the level of individual article. Hence, the use of the dual system in a research assessment might worsen the quality of information compared to the adoption of peer review only or bibliometrics only.},
  file = {/home/gabriel/Dropbox/zotero-library/Baccini et al_2020_On the agreement between bibliometrics and peer review.pdf},
  journal = {PloS One},
  keywords = {Bibliometrics,Humans,Italy,Peer Review,Peer Review; Research,Publishing},
  language = {eng},
  number = {11},
  pmcid = {PMC7673579},
  pmid = {33206715}
}

@book{ball2017,
  title = {An {{Introduction}} to {{Bibliometrics}}: {{New Development}} and {{Trends}}},
  shorttitle = {An {{Introduction}} to {{Bibliometrics}}},
  author = {Ball, Rafael},
  year = {2017},
  month = sep,
  publisher = {{Chandos Publishing}},
  abstract = {An Introduction to Bibliometrics: New Development and Trends provides a comprehensible, readable and easy to read introduction to bibliometrics. Importantly, the book surveys the latest developments of bibliometrics (such as altmetrics, etc.) and how the field is likely to change over the next decade. In the literature, bibliometrics is generally discussed from one of two perspectives: (1) Purely mathematical/statistical or (2) Its sociological implications. Both approaches are very far from how most users want to apply bibliometrics. This book fills that need by providing tactics on how bibliometrics can be applied to their sphere of scientific activity.Provides readers with an understanding of bibliometric indicators, including their background and significance, classification in quantitative performance, and an evaluation of science and researchIncludes an overview of the most important indicators, their areas of application, and where and when they should and should not be usedDiscusses future trends in the quantitative performance evaluation of scientific research},
  googlebooks = {wrlvDgAAQBAJ},
  isbn = {978-0-08-102151-4},
  keywords = {Computers / Business \& Productivity Software / General,Social Science / General},
  language = {en}
}

@article{barata2016,
  title = {Dez Coisas Que Voc\^e Deveria Saber Sobre o {{Qualis}}},
  author = {Barata, Rita de C{\'a}ssia Barradas},
  year = {2016},
  volume = {13},
  file = {/home/gabriel/Zotero/storage/4M5WS5NS/Dez coisas que você deveria saber sobre o Qualis.pdf},
  journal = {Revista Brasileira de P\'os-Gradua\c{c}\~ao},
  number = {30}
}

@article{belter2015,
  title = {Bibliometric Indicators: Opportunities and Limits},
  shorttitle = {Bibliometric Indicators},
  author = {Belter, Christopher W.},
  year = {2015},
  month = oct,
  volume = {103},
  pages = {219--221},
  issn = {1536-5050},
  doi = {10.3163/1536-5050.103.4.014},
  file = {/home/gabriel/Dropbox/zotero-library/Belter_2015_Bibliometric indicators.pdf},
  journal = {Journal of the Medical Library Association : JMLA},
  keywords = {fav,top5},
  number = {4},
  pmcid = {PMC4613388},
  pmid = {26512227}
}

@article{bensman2007,
  title = {Garfield and the Impact Factor},
  author = {Bensman, Stephen J.},
  year = {2007},
  volume = {41},
  pages = {93--155},
  issn = {1550-8382},
  doi = {10.1002/aris.2007.1440410110},
  annotation = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/aris.2007.1440410110},
  copyright = {Copyright \textcopyright{} 2007 American Society for Information Science and Technology},
  file = {/home/gabriel/Dropbox/zotero-library/Bensman_2007_Garfield and the impact factor.pdf},
  journal = {Annual Review of Information Science and Technology},
  language = {en},
  number = {1}
}

@article{besselaar2020,
  title = {Bibliometrically {{Disciplined Peer Review}}: On {{Using Indicators}} in {{Research Evaluation}}},
  shorttitle = {Bibliometrically {{Disciplined Peer Review}}},
  author = {van den Besselaar, Peter and Sandstr{\"o}m, Ulf},
  year = {2020},
  month = jun,
  volume = {2},
  pages = {5},
  publisher = {{Levy Library Press}},
  issn = {2689-5870},
  doi = {10.29024/sar.16},
  abstract = {Article: Bibliometrically Disciplined Peer Review: on Using Indicators in Research Evaluation},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  file = {/home/gabriel/Dropbox/zotero-library/Besselaar_Sandström_2020_Bibliometrically Disciplined Peer Review.pdf},
  journal = {Scholarly Assessment Reports},
  keywords = {fav,todo},
  language = {eng},
  number = {1}
}

@article{blumel2020,
  title = {Studying Review Articles in Scientometrics and beyond: A Research Agenda},
  shorttitle = {Studying Review Articles in Scientometrics and Beyond},
  author = {Bl{\"u}mel, Clemens and Schniedermann, Alexander},
  year = {2020},
  month = jul,
  volume = {124},
  pages = {711--728},
  issn = {1588-2861},
  doi = {10.1007/s11192-020-03431-7},
  abstract = {Review articles are an often neglected genre in scholarly communication. Though there was intense discussion about review articles in scientometrics in the 1970s and 1980s, we find less studies devoted to this genre within the last 20~years. Yet, recent discussions in other fields, such as linguistics, sociology or medicine imply that review articles are part of important debates about problems of research in academia, such as research quality or transparency. Against that background, the purpose of this paper is to review recent developments for the study of review articles in scientometrics and beyond, to discuss theoretical, conceptual and empirical accounts of how review articles can be defined, and to identify major methodological and conceptual challenges for studying review articles. Based on reviewing work and inputs received from of a workshop conducted at a Conference of the International Society of Informetrics in September 2019, we propose a research agenda for the study of review articles. We have identified six realms of study in this area: (1) the study of methodological caveats resulting from the usage of scholarly databases, (2) the study of field specific patterns of reception and usage of review articles, (3) the study of argumentative and textual structures of review articles, (4) the exploration of organizations and infrastructures for review articles, (5) the study of epistemic roles of review articles, and (6) the analysis of authorship patterns in review articles.},
  file = {/home/gabriel/Dropbox/zotero-library/Blümel_Schniedermann_2020_Studying review articles in scientometrics and beyond.pdf},
  journal = {Scientometrics},
  keywords = {todo},
  language = {en},
  number = {1}
}

@article{bornmann2011,
  title = {Scientific Peer Review},
  author = {Bornmann, Lutz},
  year = {2011},
  volume = {45},
  pages = {197--245},
  issn = {1550-8382},
  doi = {10.1002/aris.2011.1440450112},
  annotation = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/aris.2011.1440450112},
  copyright = {Copyright \textcopyright{} 2011 American Society for Information Science and Technology},
  file = {/home/gabriel/Dropbox/zotero-library/Bornmann_2011_Scientific peer review.pdf},
  journal = {Annual Review of Information Science and Technology},
  language = {en},
  number = {1}
}

@article{bornmann2014,
  title = {Do Altmetrics Point to the Broader Impact of Research? {{An}} Overview of Benefits and Disadvantages of Altmetrics},
  shorttitle = {Do Altmetrics Point to the Broader Impact of Research?},
  author = {Bornmann, Lutz},
  year = {2014},
  month = sep,
  abstract = {Today, it is not clear how the impact of research on other areas of society than science should be measured. While peer review and bibliometrics have become standard methods for measuring the impact of research in science, there is not yet an accepted framework within which to measure societal impact. Alternative metrics (called altmetrics to distinguish them from bibliometrics) are considered an interesting option for assessing the societal impact of research, as they offer new ways to measure (public) engagement with research output. Altmetrics is a term to describe web-based metrics for the impact of publications and other scholarly material by using data from social media platforms (e.g. Twitter or Mendeley). This overview of studies explores the potential of altmetrics for measuring societal impact. It deals with the definition and classification of altmetrics. Furthermore, their benefits and disadvantages for measuring impact are discussed.},
  archiveprefix = {arXiv},
  eprint = {1406.7091},
  eprinttype = {arxiv},
  file = {/home/gabriel/Dropbox/zotero-library/Bornmann_2014_Do altmetrics point to the broader impact of research.pdf},
  journal = {arXiv:1406.7091 [physics, stat]},
  keywords = {Computer Science - Digital Libraries,Physics - Physics and Society,Statistics - Applications},
  primaryclass = {physics, stat}
}

@article{bornmann2016a,
  title = {To What Extent Does the {{Leiden}} Manifesto Also Apply to Altmetrics? {{A}} Discussion of the Manifesto against the Background of Research into Altmetrics},
  shorttitle = {To What Extent Does the {{Leiden}} Manifesto Also Apply to Altmetrics?},
  author = {Bornmann, Lutz and Haunschild, Robin},
  year = {2016},
  month = aug,
  volume = {40},
  pages = {529--543},
  doi = {10.1108/OIR-09-2015-0314},
  abstract = {Purpose \textendash{} Hicks et al. (2015) have formulated the so-called Leiden manifesto, in which they have assembled the ten principles for a meaningful evaluation of research on the basis of bibliometric data. The paper aims to discuss this issue. Design/methodology/approach \textendash{} In this work the attempt is made to indicate the relevance of the Leiden manifesto for altmetrics. Findings \textendash{} As shown by the discussion of the ten principles against the background of the knowledge about and the research into altmetrics, the principles also have a great importance for altmetrics and should be taken into account in their application. Originality/value \textendash{} Altmetrics is already frequently used in the area of research evaluation. Thus, it is important that the user of altmetrics data knows the relevance of the Leiden manifesto also in this area.},
  file = {/home/gabriel/Dropbox/zotero-library/Bornmann_Haunschild_2016_To what extent does the Leiden manifesto also apply to altmetrics.pdf},
  journal = {Online Information Review},
  keywords = {todo}
}

@article{bornmann2018,
  title = {Critical Rationalism and the Search for Standard (Field-Normalized) Indicators in Bibliometrics},
  author = {Bornmann, Lutz and Marx, Werner},
  year = {2018},
  month = aug,
  volume = {12},
  pages = {598--604},
  issn = {1751-1577},
  doi = {10.1016/j.joi.2018.05.002},
  abstract = {Bibliometrics plays an increasingly important role in research evaluation. However, no gold standard exists for a set of reliable and valid (field-normalized) impact indicators in research evaluation. This opinion paper recommends that bibliometricians develop and analyze these impact indicators against the backdrop of Popper's critical rationalism. The studies critically investigating the indicators should publish the results in such a way that they can be included in meta-analyses. The results of meta-analyses give guidance on which indicators can then be part of a set of indicators used as standard in bibliometrics. The generation and continuous revision of the standard set could be handled by the International Society for Informetrics and Scientometrics (ISSI).},
  file = {/home/gabriel/Dropbox/zotero-library/Bornmann_Marx_2018_Critical rationalism and the search for standard (field-normalized) indicators.pdf},
  journal = {Journal of Informetrics},
  keywords = {Bibliometrics,Field-normalized indicators,Standards},
  language = {en},
  number = {3}
}

@article{brito2019,
  title = {Evaluating Research and Researchers by the Journal Impact Factor: {{Is}} It Better than Coin Flipping?},
  shorttitle = {Evaluating Research and Researchers by the Journal Impact Factor},
  author = {Brito, Ricardo and {Rodr{\'i}guez-Navarro}, Alonso},
  year = {2019},
  month = feb,
  volume = {13},
  pages = {314--324},
  issn = {1751-1577},
  doi = {10.1016/j.joi.2019.01.009},
  abstract = {The journal impact factor (JIF) is the average of the number of citations of the papers published in a journal, calculated according to a specific formula; it is extensively used for the evaluation of research and researchers. The method assumes that all papers in a journal have the same scientific merit, which is measured by the JIF of the publishing journal. This implies that the number of citations measures scientific merits but the JIF does not evaluate each individual paper by its own number of citations. Therefore, in the comparative evaluation of two papers, the use of the JIF implies a risk of failure, which occurs when a paper in the journal with the lower JIF is compared to another with fewer citations in the journal with the higher JIF. To quantify this risk of failure, this study calculates the failure probabilities, taking advantage of the lognormal distribution of citations. In two journals whose JIFs are ten-fold different, the failure probability is low. However, in most cases when two papers are compared, the JIFs of the journals are not so different. Then, the failure probability can be close to 0.5, which is equivalent to evaluating by coin flipping.},
  file = {/home/gabriel/Dropbox/zotero-library/Brito_Rodríguez-Navarro_2019_Evaluating research and researchers by the journal impact factor.pdf},
  journal = {Journal of Informetrics},
  keywords = {Failure probability,Impact factor,Research evaluation},
  language = {en},
  number = {1}
}

@article{butler2007,
  title = {Assessing University Research: A Plea for a Balanced Approach},
  shorttitle = {Assessing University Research},
  author = {Butler, Linda},
  year = {2007},
  month = oct,
  volume = {34},
  pages = {565--574},
  issn = {03023427, 14715430},
  doi = {10.3152/030234207X254404},
  file = {/home/gabriel/Dropbox/zotero-library/Butler_2007_Assessing university research.pdf},
  journal = {Science and Public Policy},
  keywords = {fav,top5},
  language = {en},
  number = {8}
}

@article{butler2017,
  title = {The {{Evolution}} of {{Current Research Impact Metrics}}: {{From Bibliometrics}} to {{Altmetrics}}?},
  shorttitle = {The {{Evolution}} of {{Current Research Impact Metrics}}},
  author = {Butler, Joseph S. and Kaye, I. David and Sebastian, Arjun S. and Wagner, Scott C. and Morrissey, Patrick B. and Schroeder, Gregory D. and Kepler, Christopher K. and Vaccaro, Alexander R.},
  year = {2017},
  month = jun,
  volume = {30},
  pages = {226--228},
  issn = {2380-0186},
  doi = {10.1097/BSD.0000000000000531},
  abstract = {The prestige of publication has been based on traditional citation metrics, most commonly journal impact factor. However, the Internet has radically changed the speed, flow, and sharing of medical information. Furthermore, the explosion of social media, along with development of popular professional and scientific websites and blogs, has led to the need for alternative metrics, known as altmetrics, to quantify the wider impact of research. We explore the evolution of current research impact metrics and examine the evolving role of altmetrics in measuring the wider impact of research. We suggest that altmetrics used in research evaluation should be part of an informed peer-review process such as traditional metrics. Moreover, results based on altmetrics must not lead to direct decision making about research, but instead, should be used to assist experts in making decisions. Finally, traditional and alternative metrics should complement, not replace, each other in the peer-review process.},
  file = {/home/gabriel/Dropbox/zotero-library/Butler et al_2017_The Evolution of Current Research Impact Metrics.pdf},
  journal = {Clinical Spine Surgery},
  language = {en-US},
  number = {5}
}

@article{cabanac2021,
  title = {Day-to-Day Discovery of Preprint\textendash Publication Links},
  author = {Cabanac, Guillaume and Oikonomidi, Theodora and Boutron, Isabelle},
  year = {2021},
  month = apr,
  issn = {1588-2861},
  doi = {10.1007/s11192-021-03900-7},
  abstract = {Preprints promote the open and fast communication of non-peer reviewed work. Once a preprint is published in a peer-reviewed venue, the preprint server updates its web page: a prominent hyperlink leading to the newly published work is added. Linking preprints to publications is of utmost importance as it provides readers with the latest version of a now certified work. Yet leading preprint servers fail to identify all existing preprint\textendash publication links. This limitation calls for a more thorough approach to this critical information retrieval task: overlooking published evidence translates into partial and even inaccurate systematic reviews on health-related issues, for instance. We designed an algorithm leveraging the Crossref public and free source of bibliographic metadata to comb the literature for preprint\textendash publication links. We tested it on a reference preprint set identified and curated for a living systematic review on interventions for preventing and treating COVID-19 performed by international collaboration: the COVID-NMA initiative (covid-nma.com). The reference set comprised 343 preprints, 121 of which appeared as a publication in a peer-reviewed journal. While the preprint servers identified 39.7\% of the preprint\textendash publication links, our linker identified 90.9\% of the expected links with no clues taken from the preprint servers. The accuracy of the proposed linker is 91.5\% on this reference set, with 90.9\% sensitivity and 91.9\% specificity. This is a 16.26\% increase in accuracy compared to that of preprint servers. We release this software as supplementary material to foster its integration into preprint servers' workflows and enhance a daily preprint\textendash publication chase that is useful to all readers, including systematic reviewers. This preprint\textendash publication linker currently provides day-to-day updates to the biomedical experts of the COVID-NMA initiative.},
  file = {/home/gabriel/Dropbox/zotero-library/Cabanac et al_2021_Day-to-day discovery of preprint–publication links.pdf},
  journal = {Scientometrics},
  language = {en}
}

@article{cabezas-clavijo2013,
  title = {Reviewers' Ratings and Bibliometric Indicators: Hand in Hand When Assessing over Research Proposals?},
  shorttitle = {Reviewers' Ratings and Bibliometric Indicators},
  author = {{Cabezas-Clavijo}, Alvaro and {Robinson-Garc{\'i}a}, Nicol{\'a}s and Escabias, Manuel and {Jim{\'e}nez-Contreras}, Evaristo},
  year = {2013},
  volume = {8},
  pages = {e68258},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0068258},
  abstract = {BACKGROUND: The peer review system has been traditionally challenged due to its many limitations especially for allocating funding. Bibliometric indicators may well present themselves as a complement. OBJECTIVE: We analyze the relationship between peers' ratings and bibliometric indicators for Spanish researchers in the 2007 National R\&D Plan for 23 research fields. METHODS AND MATERIALS: We analyze peers' ratings for 2333 applications. We also gathered principal investigators' research output and impact and studied the differences between accepted and rejected applications. We used the Web of Science database and focused on the 2002-2006 period. First, we analyzed the distribution of granted and rejected proposals considering a given set of bibliometric indicators to test if there are significant differences. Then, we applied a multiple logistic regression analysis to determine if bibliometric indicators can explain by themselves the concession of grant proposals. RESULTS: 63.4\% of the applications were funded. Bibliometric indicators for accepted proposals showed a better previous performance than for those rejected; however the correlation between peer review and bibliometric indicators is very heterogeneous among most areas. The logistic regression analysis showed that the main bibliometric indicators that explain the granting of research proposals in most cases are the output (number of published articles) and the number of papers published in journals that belong to the first quartile ranking of the Journal Citations Report. DISCUSSION: Bibliometric indicators predict the concession of grant proposals at least as well as peer ratings. Social Sciences and Education are the only areas where no relation was found, although this may be due to the limitations of the Web of Science's coverage. These findings encourage the use of bibliometric indicators as a complement to peer review in most of the analyzed areas.},
  file = {/home/gabriel/Dropbox/zotero-library/PloS One/2013/Cabezas-Clavijo et al_2013_Reviewers' ratings and bibliometric indicators.pdf},
  journal = {PloS One},
  keywords = {Bibliometrics,Biomedical Research,Databases; Factual,fav,Financing; Organized,Humans,Publications,Publishing,Research Design,Research Personnel,Spain},
  language = {eng},
  number = {6},
  pmcid = {PMC3695904},
  pmid = {23840840}
}

@article{cagan2013,
  title = {The {{San Francisco Declaration}} on {{Research Assessment}}},
  author = {Cagan, Ross},
  year = {2013},
  month = jul,
  volume = {6},
  pages = {869--870},
  issn = {1754-8403},
  doi = {10.1242/dmm.012955},
  abstract = {On December 16, 2012, a group of editors and publishers of scholarly journals, including representatives from The Company of Biologists (COB), publisher of Disease Models \&amp; Mechanisms, gathered at the Annual Meeting of The American Society for Cell Biology in San Francisco, CA, USA to discuss current issues related to how the quality of research output is evaluated, and how the primary scientific literature is cited.The impetus for the meeting was the consensus that impact factors for many cell biology journals do not accurately reflect the value to the cell biology community of the work published in these journals; this also extends to other fields in the biological sciences. The group therefore wanted to discuss how to better align measures of journal and article impact with journal quality.},
  file = {/home/gabriel/Dropbox/zotero-library/Cagan_2013_The San Francisco Declaration on Research Assessment.pdf},
  journal = {Disease Models \& Mechanisms},
  keywords = {fav,todo},
  number = {4}
}

@book{cantu-ortiz2017,
  title = {Research {{Analytics}}: {{Boosting University Productivity}} and {{Competitiveness}} through {{Scientometrics}}},
  shorttitle = {Research {{Analytics}}},
  author = {{Cantu-Ortiz}, Francisco J.},
  year = {2017},
  month = oct,
  publisher = {{CRC Press}},
  abstract = {The growth of machines and users of the Internet has led to the proliferation of all sorts of data concerning individuals, institutions, companies, governments, universities, and all kinds of known objects and events happening everywhere in daily life. Scientific knowledge is not an exception to the data boom. The phenomenon of data growth in science pushes forth as the number of scientific papers published doubles every 9\textendash 15 years, and the need for methods and tools to understand what is reported in scientific literature becomes evident.  As the number of academicians and innovators swells, so do the number of publications of all types, yielding outlets of documents and depots of authors and institutions that need to be found in Bibliometric databases. These databases are dug into and treated to hand over metrics of research performance by means of Scientometrics that analyze the toil of individuals, institutions, journals, countries, and even regions of the world.  The objective of this book is to assist students, professors, university managers, government, industry, and stakeholders in general, understand which are the main Bibliometric databases, what are the key research indicators, and who are the main players in university rankings and the methodologies and approaches that they employ in producing ranking tables.  The book is divided into two sections. The first looks at Scientometric databases, including Scopus and Google Scholar as well as institutional repositories. The second section examines the application of Scientometrics to world-class universities and the role that Scientometrics can play in competition among them. It looks at university rankings and the methodologies used to create these rankings. Individual chapters examine specific rankings that include:   QS World University Scimago Institutions Webometrics U-Multirank U.S. News \& World Report The book concludes with a discussion of university performance in the age of research analytics.},
  file = {/home/gabriel/Dropbox/zotero-library/Cantu-Ortiz_2017_Research Analytics.pdf},
  googlebooks = {lD0PEAAAQBAJ},
  isbn = {978-1-4987-8638-6},
  keywords = {Business \& Economics / Government \& Business,Computers / Data Science / Data Analytics,Computers / Information Technology,Mathematics / Probability \& Statistics / General},
  language = {en}
}

@article{carvalho2020,
  title = {{A escolha do peri\'odico cient\'ifico sob a perspectiva financeira: an\'alise do estrato A1 na \'area 21}},
  shorttitle = {{A escolha do peri\'odico cient\'ifico sob a perspectiva financeira}},
  author = {de Carvalho, Mois{\'e}s Vieira and Guimar{\~a}es, Juliana Bohnen and Bicalho, Camila Cristina Fonseca and da Silva, Tha{\'i}ze Cristina Diniz and de Brito, Avner Henrique Del Peloso and Machado, Frederico Sander Mansur and Coimbra, C{\^a}ndido Celso},
  year = {2020},
  month = dec,
  volume = {42},
  publisher = {{Col\'egio Brasileiro de Ci\^encias do Esporte}},
  issn = {0101-3289, 0101-3289, 2179-3255},
  doi = {10.1590/rbce.42.2019.217},
  abstract = {RESUMO O objetivo do estudo foi classificar as revistas A1, \'area 21, de acordo com as taxas envolvidas no processo de publica\c{c}\~ao. Os peri\'odicos foram selecionados a partir da \'area Educa\c{c}\~ao F\'isica, quadri\^enio 2013-2016. A busca foi realizada em Abril de 2019. As informa\c{c}\~oes referentes ao custeio inclu\'iram taxas de submiss\~ao, processamento e/ou tramita\c{c}\~ao, publica\c{c}\~ao e cobran\c{c}as adicionais. As despesas com o acesso aberto tamb\'em foram atribu\'idas aos autores. Os peri\'odicos foram classificados dos mais baratos para os mais caros. Em caso de igualdade nos valores cobrados, utilizou-se o fator de impacto como crit\'erio de desempate, seguindo a ordem decrescente para esse \'indice. Dos 235 peri\'odicos, somente 8 apresentaram gratuidade no processo. Considerando o cen\'ario de financiamentos limitados para pesquisa tais achados poderiam impactar na produtividade cient\'ifica nacional.},
  file = {/home/gabriel/Dropbox/zotero-library/Carvalho et al_2020_A escolha do periódico científico sob a perspectiva financeira.pdf},
  journal = {Revista Brasileira de Ci\^encias do Esporte},
  keywords = {Custo,Fator de impacto de periódicos,Publicação,Qualis/Capes},
  language = {pt}
}

@article{chahrour2020,
  title = {A {{Bibliometric Analysis}} of {{COVID}}-19 {{Research Activity}}: {{A Call}} for {{Increased Output}}},
  shorttitle = {A {{Bibliometric Analysis}} of {{COVID}}-19 {{Research Activity}}},
  author = {Chahrour, Mohamad and Assi, Sahar and Bejjani, Michael and Nasrallah, Ali A and Salhab, Hamza and Fares, Mohamad Y and Khachfe, Hussein H},
  year = {2020},
  month = mar,
  issn = {2168-8184},
  doi = {10.7759/cureus.7357},
  abstract = {Background: The novel coronavirus disease 2019 (COVID-19) has impacted many countries across all inhabited continents, and is now considered a global pandemic, due to its high rate of infectivity. Research related to this disease is pivotal for assessing pathogenic characteristics and formulating therapeutic strategies. The aim of this paper is to explore the activity and trends of COVID-19 research since its outbreak in December 2019. Methods: We explored the PubMed database and the World Health Organization (WHO) database for publications pertaining to COVID-19 since December 2019 up until March 18, 2020. Only relevant observational and interventional studies were included in our study. Data on COVID-19 incidence were extracted from the WHO situation reports. Research output was assessed with respect to gross domestic product (GDP) and population of each country. Results: Only 564 publications met our inclusion criteria. These articles came from 39 different countries, constituting 24\% of all affected countries. China produced the greatest number of publications with 377 publications (67\%). With respect to continental research activity, Asian countries had the highest research activity with 434 original publications (77\%). In terms of publications per million persons (PPMPs), Singapore had the highest number of publications with 1.069 PPMPs. In terms of publications per billion-dollar GDP, Mauritius ranked first with 0.075. Received 03/19/2020 Review began 03/20/2020 Review ended 03/20/2020 Published 03/21/2020 \textcopyright{} Copyright 2020 Chahrour et al. This is an open access article distributed under the terms of the Creative Commons Attribution License CC-BY 4.0., which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Conclusion: COVID-19 is a major disease that has impacted international public health on a global level. Observational studies and therapeutic trials pertaining to COVID-19 are essential for assessing pathogenic characteristics and developing novel treatment options.},
  file = {/home/gabriel/Dropbox/zotero-library/Chahrour et al_2020_A Bibliometric Analysis of COVID-19 Research Activity.pdf},
  journal = {Cureus},
  language = {en}
}

@article{chamberlain22,
  title = {Consuming {{Article}}-{{Level Metrics}}: {{Observations}} and {{Lessons}}},
  shorttitle = {Consuming {{Article}}-{{Level Metrics}}},
  author = {Chamberlain, Scott},
  year = {22},
  volume = {25},
  pages = {4},
  issn = {1041-0031},
  doi = {10.3789/isqv25no2.2013.02},
  file = {/home/gabriel/Dropbox/zotero-library/Chamberlain_2013_Consuming Article-Level Metrics.pdf},
  journal = {Information Standards Quarterly},
  language = {en},
  number = {2}
}

@techreport{chiarelli2019,
  title = {Accelerating Scholarly Communication: {{The}} Transformative Role of Preprints},
  shorttitle = {Accelerating Scholarly Communication},
  author = {Chiarelli, Andrea and Johnson, Rob and Pinfield, Stephen and Richens, Emma},
  year = {2019},
  month = sep,
  institution = {{Zenodo}},
  doi = {10.5281/ZENODO.3357727},
  abstract = {The preprints landscape is evolving rapidly, and the full impact of sharing articles in pre-review form remains to be seen. After publishing our initial report `The evolving preprint landscape' in 2018 and a slide deck 'Practices, drivers and impediments in the use of preprints' in spring 2019, we are now able to share our final report 'Accelerating scholarly communication - The transformative role of preprints'. Preprints (tentatively defined as versions of research papers typically prior to peer review and publication in a journal) have become more widespread in a number of disciplines over the last few years, partly to counter the slow pace of the traditional publishing process and partly to allow authors to reach a broader audience. Knowledge Exchange, in collaboration with Research Consulting, investigated this phenomenon in order to explore the current place of preprints in the scholarly communication process. In this context, we interviewed 38 stakeholders, including researchers, research performing organisations, research funding organisations and preprint service providers, and reviewed over 60 literature sources. Our key results include the benefits and challenges for researchers in using preprints as well as the establishment of trust without peer review including the role of twitter. Moreover, we reflect on the responsibilities for preprint posting in the future and the role of scholarly communities and commercial publishers. In addition to our latest report you can find our detailed analysis in the preprint 'Preprints and Scholarly Communication: Adoption, Practices, Drivers and Barriers' by Research Consulting on F1000. {$<$}em{$>$}* Please note two corrections to Appendix A of the report 'Accelerating scholarly communication - The transformative role of preprints'. In table A2:{$<$}/em{$>$} {$<$}em{$>$}Thomas L\"osch's affiliation is listed as Universit\"at Bamberg. The correct affiliation is DIPF Leibniz Institute for Research and Information in Education{$<$}/em{$>$} {$<$}em{$>$}Zoe Ancion's affiliation is listed as DIPF Leibniz Institute for Research and Information in Education. The correct affiliation is ANR{$<$}/em{$>$}},
  copyright = {Creative Commons Attribution 4.0 International, Open Access},
  file = {/home/gabriel/Dropbox/zotero-library/Chiarelli et al_2019_Accelerating scholarly communication.pdf},
  keywords = {Knowledge Exchange; KE; Research Consulting; Preprints; Scholarly Communication; Open Scholarship; Open Science; Open Research},
  language = {en}
}

@article{coelho2019,
  title = {Decentralising Scientific Publishing: Can the Blockchain Improve Science Communication?},
  shorttitle = {Decentralising Scientific Publishing},
  author = {Coelho, Fl{\'a}vio Code{\c c}o and Brand{\~a}o, Adeilton},
  year = {2019},
  volume = {114},
  pages = {e190257},
  issn = {1678-8060, 0074-0276},
  doi = {10.1590/0074-02760190257},
  file = {/home/gabriel/Dropbox/zotero-library/Coelho_Brandão_2019_Decentralising scientific publishing.pdf},
  journal = {Mem\'orias do Instituto Oswaldo Cruz},
  keywords = {todo},
  language = {en}
}

@article{craig2007,
  title = {Do {{Open Access Articles Have Greater Citation Impact}}? {{A Critical Review}} of the {{Literature}}},
  shorttitle = {Do {{Open Access Articles Have Greater Citation Impact}}?},
  author = {Craig, Iain and Plume, Andrew and Mcveigh, Marie and Pringle, James},
  year = {2007},
  month = jul,
  volume = {1},
  pages = {239--248},
  doi = {10.1016/j.joi.2007.04.001},
  abstract = {The last few years have seen the emergence of several open access options in scholarly communication which can broadly be grouped into two areas referred to as `gold' and `green' open access (OA). In this article we review the literature examining the relationship between OA status and citation counts of scholarly articles. Early studies showed a correlation between the free online availability or OA status of articles and higher citation counts, and implied causality without due consideration of potential confounding factors. More recent investigations have dissected the nature of the relationship between article OA status and citations. Three non-exclusive postulates have been proposed to account for the observed citation differences between OA and non-OA articles: an open access postulate, a selection bias postulate, and an early view postulate. The most rigorous study to date (in condensed matter physics) showed that, after controlling for the early view postulate, the remaining difference in citation counts between OA and non-OA articles is explained by the selection bias postulate. No evidence was found to support the OA postulate per se; i.e. article OA status alone has little or no effect on citations. Further studies using a similarly rigorous approach are required to determine the generality of this finding.},
  file = {/home/gabriel/Dropbox/zotero-library/Craig et al_2007_Do Open Access Articles Have Greater Citation Impact.pdf},
  journal = {J. Informetrics},
  keywords = {todo}
}

@article{cueto2019,
  title = {{A hist\'oria das ci\^encias e o Qualis Peri\'odicos}},
  author = {Cueto, Marcos},
  year = {2019},
  month = nov,
  volume = {26},
  pages = {1083--1084},
  publisher = {{Casa de Oswaldo Cruz, Funda\c{c}\~ao Oswaldo Cruz}},
  issn = {0104-5970, 0104-5970, 1678-4758},
  doi = {10.1590/S0104-59702019000400001},
  file = {/home/gabriel/Dropbox/zotero-library/Cueto_2019_A história das ciências e o Qualis Periódicos.pdf},
  journal = {Hist\'oria, Ci\^encias, Sa\'ude-Manguinhos},
  language = {pt}
}

@article{curry2019,
  title = {Research Evaluation and {{DORA}}: {{Philosophy}} and {{Practice}}},
  shorttitle = {Research Evaluation and {{DORA}}},
  author = {Curry, Stephen},
  year = {2019},
  file = {/home/gabriel/Dropbox/zotero-library/Curry_2019_Research evaluation and DORA.pdf;/home/gabriel/Zotero/storage/BQG9QVIC/Curry - 2019 - Research evaluation and DORA Philosophy and Pract.pdf},
  keywords = {fav}
}

@article{das2017,
  title = {Citation Impact: {{Manipulation}} and Monopoly},
  shorttitle = {Citation Impact},
  author = {Das, KusalK},
  year = {2017},
  volume = {2},
  pages = {67},
  issn = {2468-838X},
  doi = {10.4103/bjhs.bjhs_34_17},
  file = {/home/gabriel/Dropbox/zotero-library/Das_2017_Citation impact.pdf},
  journal = {BLDE University Journal of Health Sciences},
  keywords = {todo},
  language = {en},
  number = {2}
}

@article{demeis2003,
  title = {The Growing Competition in {{Brazilian}} Science: Rites of Passage, Stress and Burnout},
  shorttitle = {The Growing Competition in {{Brazilian}} Science},
  author = {{de Meis}, L. and Velloso, A. and Lannes, D. and Carmo, M. S. and {de Meis}, C.},
  year = {2003},
  month = sep,
  volume = {36},
  pages = {1135--1141},
  publisher = {{Associa\c{c}\~ao Brasileira de Divulga\c{c}\~ao Cient\'ifica}},
  issn = {0100-879X, 0100-879X, 1414-431X},
  doi = {10.1590/S0100-879X2003000900001},
  abstract = {Brazil's scientific community is under pressure. Each year there is an increase in its contribution to international science and in the number of students who are trained to do research and teach at an advanced level. Most of these activities are carried out in state and federal universities, but with government funding that has decreased by more than 70\% since 1996. Interviews with graduate students, post-doctoral fellows and professors in one university department with a strong research tradition illustrate the level of stress engendered by the conflict between increasing competition and diminishing resources, and serve to underscore the negative effects on creativity and on the tendency to choose science as a career.},
  file = {/home/gabriel/Dropbox/zotero-library/de Meis et al_2003_The growing competition in Brazilian science.pdf},
  journal = {Brazilian Journal of Medical and Biological Research},
  keywords = {Academic pressure,fav,Mental suffering,MSc and PhD students,Public and private universities,Publish or perish,Science funding,top5},
  language = {en}
}

@article{demeis2003a,
  title = {Impact Factors: Just Part of a Research Treadmill},
  shorttitle = {Impact Factors},
  author = {{de Meis}, Leopoldo and {do Carmo}, Maria Scarlet and {de Meis}, Carla},
  year = {2003},
  month = aug,
  volume = {424},
  pages = {723--723},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/424723b},
  copyright = {2003 Nature Publishing Group},
  file = {/home/gabriel/Dropbox/zotero-library/de Meis et al_2003_Impact factors.pdf},
  journal = {Nature},
  keywords = {fav},
  language = {en},
  number = {6950}
}

@article{derrick2013,
  title = {Democratising Research Evaluation: {{Achieving}} Greater Public Engagement with Bibliometrics-Informed Peer Review},
  shorttitle = {Democratising Research Evaluation},
  author = {Derrick, Gemma E. and Pavone, Vincenzo},
  year = {2013},
  month = oct,
  volume = {40},
  pages = {563--575},
  issn = {0302-3427},
  doi = {10.1093/scipol/sct007},
  abstract = {The ability of metrics to represent complex information about research in an accessible format has previously been overlooked in preference to debate about their shortcomings as research evaluation tools. Here, we argue that bibliometrics have the potential to widen scientific participation by allowing non-academic stakeholders to access scientific decision making, thereby increasing the democratisation of science. Government policies from 3 countries (UK, Australia and Spain) are reviewed. Each country outlines a commitment to the democratisation of science for one set of policies whilst ignoring this commitment when developing parallel research evaluation policies. We propose a change in dialogue from whether bibliometrics should be used to how they should be used in future evaluations. Future research policies should take advantage of bibliometrics to foster greater democratisation of research to create more socially-reflexive evaluation systems.},
  file = {/home/gabriel/Dropbox/zotero-library/Derrick_Pavone_2013_Democratising research evaluation.pdf},
  journal = {Science and Public Policy},
  keywords = {fav},
  number = {5}
}

@article{dougherty2019,
  title = {Analyzing {{Neoliberalism}} in {{Theory}} and {{Practice}}: {{The Case}} of {{Performance}}-{{Based Funding}} for {{Higher Education}}},
  shorttitle = {Analyzing {{Neoliberalism}} in {{Theory}} and {{Practice}}},
  author = {Dougherty, Kevin J. and Natow, Rebecca Spiro},
  year = {2019},
  doi = {10.7916/d8-a1kt-7p96},
  abstract = {Neoliberal ideas \textendash{} whether the new public management, principal-agent theory, or performance management \textendash{} have provided rationale for sweeping reforms in the governance and operation of higher education. Despite this, little attention has been devoted to how well neoliberal theory illuminates the policy process by which neoliberal policy is enacted and implemented. This paper expands our understanding of the origins, implementation, and impacts of neoliberal policies by examining the case of performance-based funding (PBF) for higher education in the United States, Europe, Canada, Australia, and elsewhere. With regard to policy origins, neoliberal theory anticipates the key role that top government officials play in the development of PBF but fails to anticipate the important roles of business and higher education institutions in the formation of neoliberal policies. Neoliberal theory notes the important role of monetary incentives as policy instruments and the obstacles posed by gaming on the part of agents, but the implementation of PBF also involves other policy instruments and faces additional obstacles to implementation. Policy outcomes fitting the neoliberal focus on organizational effectiveness and efficiency are only weakly produced by PBF, but PBF is associated with a host of unintended impacts that neoliberal theory ignores.},
  file = {/home/gabriel/Dropbox/zotero-library/Dougherty_Natow_2019_Analyzing Neoliberalism in Theory and Practice.pdf},
  language = {en}
}

@article{durieux2010,
  title = {Bibliometric {{Indicators}}: {{Quality Measurements}} of {{Scientific Publication}}},
  shorttitle = {Bibliometric {{Indicators}}},
  author = {Durieux, Val{\'e}rie and Gevenois, Pierre Alain},
  year = {2010},
  month = apr,
  volume = {255},
  pages = {342--351},
  publisher = {{Radiological Society of North America}},
  issn = {0033-8419},
  doi = {10.1148/radiol.09090626},
  abstract = {Bibliometrics is a set of mathematical and statistical methods used to analyze and measure the quantity and quality of books, articles, and other forms of publications. There are three types of bibliometric indicators: quantity indicators, which measure the productivity of a particular researcher; quality indicators, which measure the quality (or ``performance'') of a researcher's output; and structural indicators, which measure connections between publications, authors, and areas of research. Bibliometric indicators are especially important for researchers and organizations, as these measurements are often used in funding decisions, appointments, and promotions of researchers. As more and more scientific discoveries occur and published research results are read and then quoted by other researchers, bibliometric indicators are becoming increasingly important. This article provides an overview of the currently used bibliometric indicators and summarizes the critical elements and characteristics one should be aware of when evaluating the quantity and quality of scientific output.\textcopyright{} RSNA, 2010},
  file = {/home/gabriel/Dropbox/zotero-library/Durieux_Gevenois_2010_Bibliometric Indicators.pdf},
  journal = {Radiology},
  keywords = {fav,top5},
  number = {2}
}

@article{edwards2017,
  title = {Academic {{Research}} in the 21st {{Century}}: {{Maintaining Scientific Integrity}} in a {{Climate}} of {{Perverse Incentives}} and {{Hypercompetition}}},
  shorttitle = {Academic {{Research}} in the 21st {{Century}}},
  author = {Edwards, Marc A. and Roy, Siddhartha},
  year = {2017},
  month = jan,
  volume = {34},
  pages = {51--61},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  doi = {10.1089/ees.2016.0223},
  abstract = {Over the last 50 years, we argue that incentives for academic scientists have become increasingly perverse in terms of competition for research funding, development of quantitative metrics to measure performance, and a changing business model for higher education itself. Furthermore, decreased discretionary funding at the federal and state level is creating a hypercompetitive environment between government agencies (e.g., EPA, NIH, CDC), for scientists in these agencies, and for academics seeking funding from all sources\textemdash the combination of perverse incentives and decreased funding increases pressures that can lead to unethical behavior. If a critical mass of scientists become untrustworthy, a tipping point is possible in which the scientific enterprise itself becomes inherently corrupt and public trust is lost, risking a new dark age with devastating consequences to humanity. Academia and federal agencies should better support science as a public good, and incentivize altruistic and ethical outcomes, while de-emphasizing output.},
  file = {/home/gabriel/Dropbox/zotero-library/Edwards_Roy_2017_Academic Research in the 21st Century.pdf},
  journal = {Environmental Engineering Science},
  keywords = {fav},
  number = {1}
}

@article{eysenbach2006,
  title = {Citation {{Advantage}} of {{Open Access Articles}}},
  author = {Eysenbach, Gunther},
  year = {2006},
  month = may,
  volume = {4},
  pages = {e157},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.0040157},
  abstract = {Open access (OA) to the research literature has the potential to accelerate recognition and dissemination of research findings, but its actual effects are controversial. This was a longitudinal bibliometric analysis of a cohort of OA and non-OA articles published between June 8, 2004, and December 20, 2004, in the same journal (PNAS: Proceedings of the National Academy of Sciences). Article characteristics were extracted, and citation data were compared between the two groups at three different points in time: at ``quasi-baseline'' (December 2004, 0\textendash 6 mo after publication), in April 2005 (4\textendash 10 mo after publication), and in October 2005 (10\textendash 16 mo after publication). Potentially confounding variables, including number of authors, authors' lifetime publication count and impact, submission track, country of corresponding author, funding organization, and discipline, were adjusted for in logistic and linear multiple regression models. A total of 1,492 original research articles were analyzed: 212 (14.2\% of all articles) were OA articles paid by the author, and 1,280 (85.8\%) were non-OA articles. In April 2005 (mean 206 d after publication), 627 (49.0\%) of the non-OA articles versus 78 (36.8\%) of the OA articles were not cited (relative risk = 1.3 [95\% Confidence Interval: 1.1\textendash 1.6]; p = 0.001). 6 mo later (mean 288 d after publication), non-OA articles were still more likely to be uncited (non-OA: 172 [13.6\%], OA: 11 [5.2\%]; relative risk = 2.6 [1.4\textendash 4.7]; p {$<$} 0.001). The average number of citations of OA articles was higher compared to non-OA articles (April 2005: 1.5 [SD = 2.5] versus 1.2 [SD = 2.0]; Z = 3.123; p = 0.002; October 2005: 6.4 [SD = 10.4] versus 4.5 [SD = 4.9]; Z = 4.058; p {$<$} 0.001). In a logistic regression model, controlling for potential confounders, OA articles compared to non-OA articles remained twice as likely to be cited (odds ratio = 2.1 [1.5\textendash 2.9]) in the first 4\textendash 10 mo after publication (April 2005), with the odds ratio increasing to 2.9 (1.5\textendash 5.5) 10\textendash 16 mo after publication (October 2005). Articles published as an immediate OA article on the journal site have higher impact than self-archived or otherwise openly accessible OA articles. We found strong evidence that, even in a journal that is widely available in research libraries, OA articles are more immediately recognized and cited by peers than non-OA articles published in the same journal. OA is likely to benefit science by accelerating dissemination and uptake of research findings.},
  file = {/home/gabriel/Dropbox/zotero-library/Eysenbach_2006_Citation Advantage of Open Access Articles.pdf},
  journal = {PLOS Biology},
  keywords = {Bibliometrics,Citation analysis,Institutional repositories,Internet,Open access publishing,Peer review,Scientific publishing,Scientists},
  language = {en},
  number = {5}
}

@article{feldman2018,
  title = {Metric {{Power}} and the {{Academic Self}}: {{Neoliberalism}}, {{Knowledge}} and {{Resistance}} in the {{British University}}},
  shorttitle = {Metric {{Power}} and the {{Academic Self}}},
  author = {Feldman, Zeena and Sandoval, Marisol},
  year = {2018},
  month = jan,
  volume = {16},
  pages = {214--233},
  issn = {1726-670X},
  doi = {10.31269/triplec.v16i1.899},
  abstract = {This article discusses the experience of being an academic in the UK in the contemporary climate of neoliberal capitalism and `metric power' (Beers 2016). Drawing on existing literature and our own practice, the first portion of the paper explores the relationship between neoliberalism, metrics and knowledge. We then examine how neoliberal mantras and instruments impact the university's structures and processes, and reflect on consequences for the academic self. We take as a starting point the context of increasing workloads and the pressure on academics to excel in multiple roles, from `world-leading' researchers to `excellent' teachers and `service providers' to professional administrators performing recruitment and (self)marketing tasks. Neoliberal academia, we suggest, promotes a meritocratic ideology of individual achievement that frames success and failure as purely personal `achievements', which encourages a competitive ethos and chronic self-criticism. This article insists that these problems need to be understood in the context of neoliberal policy-making and the corporatisation of knowledge, including funding cuts and grant imperatives, the low status of teaching, the cynical instrumentation of university league tables, and increased institutional reliance on precarious academic labour. The article goes on to focus on responses that resist, challenge or, in some cases, compound, the problems identified in part one. Responses by dissatisfied academics range in style and approach \textendash{} some decide against an academic career; others adopt a strategy of individual withdrawal within the system by trying to create and protect spaces of independence \textendash{} for example, by refusing to engage beyond officially required minimums. This article argues that opportunities for positive systemic change can be found in collective efforts to oppose the status quo and to create alternatives for how academic labour is organised. Therein, solidarity can act as an instrument of opposition to the individualisation of the neoliberal academic self.},
  file = {/home/gabriel/Dropbox/zotero-library/Feldman_Sandoval_2018_Metric Power and the Academic Self.pdf},
  journal = {tripleC: Communication, Capitalism \& Critique. Open Access Journal for a Global Sustainable Information Society},
  keywords = {Academic Labour,Co-operative University,Higher Education Policy,Metric Culture,Metrics,Neoliberalism,Resistance,Trade Unions,UK Academia},
  language = {en},
  number = {1}
}

@article{fernandes2019,
  title = {How {{QUALIS CAPES}} Influences {{Brazilian}} Academic Production? {{A}} Stimulus or a Barrier for Advancement?},
  shorttitle = {How {{QUALIS CAPES}} Influences {{Brazilian}} Academic Production?},
  author = {Fernandes, Gustavo Andrey Almeida Lopes and Manchini, Leonardo De Oliveira},
  year = {2019},
  month = may,
  volume = {39},
  pages = {285--305},
  publisher = {{Editora 34}},
  issn = {0101-3157, 0101-3157, 1809-4538},
  doi = {10.1590/0101-31572019-3006},
  abstract = {ABSTRACT This study delves into the consequences of QUALIS CAPES. To do that, data on the editorial boards of the journals classified as A1 and A2 in the areas of Business, Accounting and Tourism; and Economics are collected. Findings show that the US and the UK dominate the academic production. Brazil and other emerging countries are not relevant. Issues of the five top journals of each area were analyzed, showing that QUALIS may bias research in the country to issues not connected to Brazilian questions.},
  file = {/home/gabriel/Dropbox/zotero-library/Fernandes_Manchini_2019_How QUALIS CAPES influences Brazilian academic production.pdf},
  journal = {Brazilian Journal of Political Economy},
  keywords = {Development,government policy,research},
  language = {en}
}

@article{ferreira2010,
  title = {Bibliometria Na Avalia\c{c}\~ao de Peri\'odicos Cient\'ificos},
  author = {Ferreira, Ana Gabriela},
  year = {2010},
  month = jan,
  volume = {11},
  abstract = {Resumo: O presente trabalho pretende apresentar a interela\c{c}\~ao entre a Bibliometria e a avalia\c{c}\~ao de peri\'odicos cient\'ificos. O estudo \'e um artigo de revis\~ao. Apresenta a conceitua\c{c}\~ao de Bibliometria, bem como as principais \'areas de aplica\c{c}\~ao dos estudos bibliom\'etrico e as tr\^es principais leis: Lei de Lotka, Lei de Bradford e Lei de Zipf. Apresenta como as tr\^es leis podem se relacionar. Conceitua peri\'odico cient\'ifico, peri\'odico cient\'ifico eletr\^onico e discute sobre a avalia\c{c}\~ao das revistas cient\'ificas. Aborda como as novas tecnologias influenciam os estudos bibliom\'etrico e a avalia\c{c}\~ao de peri\'odicos. Conclui que os estudos bibliom\'etrico s\~ao ferramentas de inestim\'avel valor para a avalia\c{c}\~ao de peri\'odicos e para o desenvolvimento da ci\^encia como um todo. Palavras-chave: Bibliometria. Lel Bibliometrica. Peri\'odico Cient\'ifico. Avalia\c{c}\~ao. Abstract: This paper intends to present the relation between Bibliometrics and how this can help in the evaluation of scientific journals. The study is a review article. Presents the concept of Bibliometrics and the main areas of application of bibliometric studies and the three main laws: Lotka\textasciiacute s Law, Bradfords Law and Zipf\textasciiacute s Law. Shows how the three laws can relate. Conceptualized journal, electronic journal and discusses the evaluation of scientific journals. Discusses how new technologies influence the bibliometric study and evaluation of journals. Concludes that the bibliometric studies are invaluable tools for the evaluation of journals and the development of science as a whole. Keywords: Bibliometrics. Bibliometric Laws. Scientific Journals. Evaluation.},
  file = {/home/gabriel/Dropbox/zotero-library/Ferreira_2010_Bibliometria na avaliação de periódicos científicos.pdf},
  journal = {DataGramaZero, Rio de Janeiro}
}

@misc{fiormonte,
  title = {Knowledge {{Monopolies}} and {{Global Academic Publishing}}},
  author = {Fiormonte, Domenico and {University of Roma Tre, Italy} and Priego, Ernesto and {City University London, UK}},
  doi = {10.15200/winn.147220.00404},
  file = {/home/gabriel/Dropbox/zotero-library/Fiormonte et al_Knowledge Monopolies and Global Academic Publishing.pdf},
  keywords = {todo},
  language = {en}
}

@article{fortunato2018,
  title = {Science of Science},
  author = {Fortunato, Santo and Bergstrom, Carl T. and B{\"o}rner, Katy and Evans, James A. and Helbing, Dirk and Milojevi{\'c}, Sta{\v s}a and Petersen, Alexander M. and Radicchi, Filippo and Sinatra, Roberta and Uzzi, Brian and Vespignani, Alessandro and Waltman, Ludo and Wang, Dashun and Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  year = {2018},
  month = mar,
  volume = {359},
  issn = {0036-8075},
  doi = {10.1126/science.aao0185},
  abstract = {The complexity of science. Science can be seen as an expanding and evolving network of ideas, scholars and papers. SciSci searches for universal and domain-specific laws underlying the structure and dynamics of science.,},
  file = {/home/gabriel/Dropbox/zotero-library/Fortunato et al_2018_Science of science.pdf},
  journal = {Science (New York, N.Y.)},
  number = {6379},
  pmcid = {PMC5949209},
  pmid = {29496846}
}

@article{frey2010,
  title = {Do Rankings Reflect Research Quality?},
  author = {Frey, Bruno S. and Rost, Katja},
  year = {2010},
  month = may,
  volume = {13},
  pages = {1--38},
  issn = {1514-0326},
  doi = {10.1016/S1514-0326(10)60002-5},
  abstract = {Publication and citation rankings have become major indicators of the scientific worth of universities and determine to a large extent the career of individual scholars. Such rankings do not effectively measure research quality, which should be the essence of any evaluation. These quantity rankings are not objective; two citation rankings, based on different samples, produce entirely different results. For that reason, an alternative ranking is developed as a quality indicator, based on membership on academic editorial boards of professional journals. It turns out that the ranking of individual scholars based on that measure is far from objective. Furthermore, the results differ markedly, depending on whether research quantity or quality is considered. Thus, career decisions based on rankings are dominated by chance and do not reflect research quality. We suggest that evaluations should rely on multiple criteria. Public management should return to approved methods such as engaging independent experts who in turn provide measurements of research quality for their research communities. JEL classification codes: H43, L15, O38},
  file = {/home/gabriel/Dropbox/zotero-library/Frey_Rost_2010_Do rankings reflect research quality.pdf},
  journal = {Journal of Applied Economics},
  keywords = {evaluations,rankings,research quality,scholars,todo,universities},
  language = {en},
  number = {1}
}

@article{gabardo2018,
  title = {{Sistema Qualis: an\'alise cr\'itica da pol\'itica de avalia\c{c}\~ao de peri\'odicos cient\'ificos no Brasil}},
  shorttitle = {{Sistema Qualis}},
  author = {Gabardo, Emerson and Hachem, Daniel Wunder and Hamada, Guilherme},
  year = {2018},
  month = jan,
  volume = {1},
  pages = {144--185},
  issn = {1982-9957},
  doi = {10.17058/rdunisc.v1i54.12000},
  abstract = {O artigo analisa o atual sistema de avalia\c{c}\~ao da produ\c{c}\~ao cient\'ifica publicada pelos professores e alunos dos programas de p\'os-gradua\c{c}\~ao stricto sensu (Mestrados e Doutorados) no Brasil. Em destaque, descreve a pol\'itica do Qualis Peri\'odicos, elaborando uma vis\~ao cr\'itica a respeito dos seus pontos positivos e negativos. Prop\~oe que o Qualis n\~ao \'e meramente um instrumento de avalia\c{c}\~ao, mas de ampla regula\c{c}\~ao do setor educacional superior brasileiro. Descreve sinteticamente as bases e indexadores mais importantes atualmente utilizados pelas ag\^encias de avalia\c{c}\~ao. Aponta os principais problemas da avalia\c{c}\~ao de peri\'odicos na \'Area do Direito, descrevendo detalhadamente as etapas e os v\'icios do processo avaliativo de revistas nacionais e estrangeiras no quadri\^enio 2013-2016 e examinando criticamente os crit\'erios utilizados para a classifica\c{c}\~ao dos peri\'odicos estrangeiros, que acabaram por promover um desest\'imulo \`a produ\c{c}\~ao cient\'ifica internacional na \'Area. Conclui pela necessidade de uma vis\~ao mais ampla da CAPES a respeito do processo regulat\'orio de avalia\c{c}\~ao, bem como pela necessidade de respeito \`as singularidades de cada \'Area. Por fim, afirma a necessidade de cumprimento das normas de Direito Administrativo, para maior efici\^encia e legitimidade do sistema.},
  copyright = {Direitos autorais 2018 Revista do Direito},
  file = {/home/gabriel/Dropbox/zotero-library/Gabardo et al_2018_Sistema Qualis.pdf},
  journal = {Revista do Direito},
  keywords = {avaliação da educação superior,CAPES,indexadores de periódicos,Qualis Periódicos,regulação da educação.},
  language = {pt},
  number = {54}
}

@article{garfield1955,
  title = {Citation {{Indexes}} for {{Science}}: {{A New Dimension}} in {{Documentation}} through {{Association}} of {{Ideas}}},
  shorttitle = {Citation {{Indexes}} for {{Science}}},
  author = {Garfield, Eugene},
  year = {1955},
  month = jul,
  volume = {122},
  pages = {108--111},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.122.3159.108},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 1955 by the American Association for the Advancement of Science},
  file = {/home/gabriel/Dropbox/zotero-library/Garfield_1955_Citation Indexes for Science.pdf},
  journal = {Science},
  keywords = {fav,top5},
  language = {en},
  number = {3159},
  pmid = {14385826}
}

@article{garner2018,
  title = {Bibliometric Indices: Defining Academic Productivity and Citation Rates of Researchers, Departments and Journals},
  shorttitle = {Bibliometric Indices},
  author = {Garner, Rebecca M. and Hirsch, Joshua A. and Albuquerque, Felipe C. and Fargen, Kyle M.},
  year = {2018},
  month = feb,
  volume = {10},
  pages = {102--106},
  issn = {1759-8486},
  doi = {10.1136/neurintsurg-2017-013265},
  abstract = {There has been an increasing focus on academic productivity for the purposes of promotion and funding within departments and institutions but also for comparison of individuals, institutions, specialties, and journals. A number of quantitative indices are used to investigate and compare academic productivity. These include various calculations attempting to analyze the number and citations of publications in order to capture both the quality and quantity of publications, such as the h index, the e index, impact factor, and Eigenfactor score. The indices have varying advantages and limitations and thus a basic knowledge is required in order to understand their potential utility within academic medicine. This article describes the various bibliometric indices and discusses recent applications of these metrics within the neurological sciences.},
  file = {/home/gabriel/Dropbox/zotero-library/Garner et al_2018_Bibliometric indices.pdf},
  journal = {Journal of Neurointerventional Surgery},
  keywords = {academic productivity,bibliometrics,Bibliometrics,Biomedical Research,citation analysis,Efficiency,fav,h index,Humans,Journal Impact Factor,Neurosciences,Periodicals as Topic,top5},
  language = {eng},
  number = {2},
  pmid = {28824008}
}

@article{gasparyan2017,
  title = {The {{Journal Impact Factor}}: {{Moving Toward}} an {{Alternative}} and {{Combined Scientometric Approach}}},
  shorttitle = {The {{Journal Impact Factor}}},
  author = {Gasparyan, Armen Yuri and Nurmashev, Bekaidar and Yessirkepov, Marlen and Udovik, Elena E. and Baryshnikov, Aleksandr A. and Kitas, George D.},
  year = {2017},
  volume = {32},
  pages = {173},
  issn = {1011-8934, 1598-6357},
  doi = {10.3346/jkms.2017.32.2.173},
  file = {/home/gabriel/Zotero/storage/GT2PY23I/Gasparyan et al. - 2017 - The Journal Impact Factor Moving Toward an Altern.pdf},
  journal = {Journal of Korean Medical Science},
  language = {en},
  number = {2}
}

@article{geuna2003,
  title = {University {{Research Evaluation}} and {{Funding}}: {{An International Comparison}}},
  shorttitle = {University {{Research Evaluation}} and {{Funding}}},
  author = {Geuna, Aldo and Martin, Ben R.},
  year = {2003},
  volume = {41},
  pages = {277--304},
  issn = {0026-4695},
  doi = {10.1023/B:MINE.0000005155.70870.bd},
  abstract = {Many countries have introduced evaluations of university research, reflecting global demands for greater accountability. This paper compares methods of evaluation used across twelve countries in Europe and the Asia-Pacific region. On the basis of this comparison, and focusing in particular on Britain, we examine the advantages and disadvantages of performance-based funding in comparison with other approaches to funding. Our analysis suggests that, while initial benefits may outweigh the costs, over time such a system seems to produce diminishing returns. This raises important questions about its continued use.},
  file = {/home/gabriel/Dropbox/zotero-library/Geuna_Martin_2003_University Research Evaluation and Funding.pdf},
  journal = {Minerva},
  language = {en},
  number = {4}
}

@book{gingras2016,
  title = {Bibliometrics and {{Research Evaluation}}: {{Uses}} and {{Abuses}}},
  shorttitle = {Bibliometrics and {{Research Evaluation}}},
  author = {Gingras, Yves},
  year = {2016},
  month = sep,
  publisher = {{MIT Press}},
  abstract = {Why bibliometrics is useful for understanding the global dynamics of science but generate perverse effects when applied inappropriately in research evaluation and university rankings.The research evaluation market is booming. ``Ranking,'' ``metrics,'' ``h-index,'' and ``impact factors'' are reigning buzzwords. Government and research administrators want to evaluate everything\textemdash teachers, professors, training programs, universities\textemdash using quantitative indicators. Among the tools used to measure ``research excellence,'' bibliometrics\textemdash aggregate data on publications and citations\textemdash has become dominant. Bibliometrics is hailed as an ``objective'' measure of research quality, a quantitative measure more useful than ``subjective'' and intuitive evaluation methods such as peer review that have been used since scientific papers were first published in the seventeenth century. In this book, Yves Gingras offers a spirited argument against an unquestioning reliance on bibliometrics as an indicator of research quality. Gingras shows that bibliometric rankings have no real scientific validity, rarely measuring what they pretend to.Although the study of publication and citation patterns, at the proper scales, can yield insights on the global dynamics of science over time, ill-defined quantitative indicators often generate perverse and unintended effects on the direction of research. Moreover, abuse of bibliometrics occurs when data is manipulated to boost rankings. Gingras looks at the politics of evaluation and argues that using numbers can be a way to control scientists and diminish their autonomy in the evaluation process. Proposing precise criteria for establishing the validity of indicators at a given scale of analysis, Gingras questions why universities are so eager to let invalid indicators influence their research strategy.},
  file = {/home/gabriel/Dropbox/zotero-library/Gingras_2016_Bibliometrics and Research Evaluation2.pdf},
  googlebooks = {0aExDQAAQBAJ},
  isbn = {978-0-262-33766-3},
  keywords = {Education / Evaluation \& Assessment,Language Arts \& Disciplines / Library \& Information Science / General},
  language = {en}
}

@book{gingras2016a,
  title = {Bibliometrics and {{Research Evaluation}}: {{Uses}} and {{Abuses}}},
  shorttitle = {Bibliometrics and {{Research Evaluation}}},
  author = {Gingras, Yves},
  year = {2016},
  month = sep,
  publisher = {{MIT Press}},
  abstract = {Why bibliometrics is useful for understanding the global dynamics of science but generate perverse effects when applied inappropriately in research evaluation and university rankings.The research evaluation market is booming. ``Ranking,'' ``metrics,'' ``h-index,'' and ``impact factors'' are reigning buzzwords. Government and research administrators want to evaluate everything\textemdash teachers, professors, training programs, universities\textemdash using quantitative indicators. Among the tools used to measure ``research excellence,'' bibliometrics\textemdash aggregate data on publications and citations\textemdash has become dominant. Bibliometrics is hailed as an ``objective'' measure of research quality, a quantitative measure more useful than ``subjective'' and intuitive evaluation methods such as peer review that have been used since scientific papers were first published in the seventeenth century. In this book, Yves Gingras offers a spirited argument against an unquestioning reliance on bibliometrics as an indicator of research quality. Gingras shows that bibliometric rankings have no real scientific validity, rarely measuring what they pretend to.Although the study of publication and citation patterns, at the proper scales, can yield insights on the global dynamics of science over time, ill-defined quantitative indicators often generate perverse and unintended effects on the direction of research. Moreover, abuse of bibliometrics occurs when data is manipulated to boost rankings. Gingras looks at the politics of evaluation and argues that using numbers can be a way to control scientists and diminish their autonomy in the evaluation process. Proposing precise criteria for establishing the validity of indicators at a given scale of analysis, Gingras questions why universities are so eager to let invalid indicators influence their research strategy.},
  file = {/home/gabriel/Dropbox/zotero-library/Gingras_2016_Bibliometrics and Research Evaluation.pdf},
  googlebooks = {0aExDQAAQBAJ},
  isbn = {978-0-262-33766-3},
  keywords = {Education / Evaluation \& Assessment,Language Arts \& Disciplines / Library \& Information Science / General},
  language = {en}
}

@article{glanzel2002,
  title = {Journal Impact Measures in Bibliometric Research},
  author = {Gl{\"a}nzel, Wolfgang and Moed, Henk F},
  year = {2002},
  pages = {23},
  file = {/home/gabriel/Dropbox/zotero-library/Glänzel_Moed_2002_Journal impact measures in bibliometric research.pdf},
  keywords = {fav,top5},
  language = {en}
}

@article{glanzel2008,
  title = {Seven {{Myths}} in {{Bibliometrics About}} Facts and Fiction in Quantitative Science Studies},
  author = {Gl{\"a}nzel, Wolfgang},
  year = {2008},
  month = jun,
  volume = {2},
  pages = {9--17},
  issn = {0973-7766, 2168-930X},
  doi = {10.1080/09737766.2008.10700836},
  file = {/home/gabriel/Dropbox/zotero-library/Glänzel_2008_Seven Myths in Bibliometrics About facts and fiction in quantitative science.pdf},
  journal = {Collnet Journal of Scientometrics and Information Management},
  keywords = {fav,top5},
  language = {en},
  number = {1}
}

@article{godin2006,
  title = {On the Origins of Bibliometrics},
  author = {Godin, Beno{\^i}t},
  year = {2006},
  month = jul,
  volume = {68},
  pages = {109--133},
  publisher = {{Akad\'emiai Kiad\'o, co-published with Springer Science+Business Media B.V., Formerly Kluwer Academic Publishers B.V.}},
  issn = {0138-9130, 1588-2861},
  doi = {10.1007/s11192-006-0086-0},
  abstract = {{$<$}section class="abstract"{$><$}h2 class="abstractTitle text-title my-1" id="d801795152e136"{$>$}Summary~~{$<$}/h2{$><$}p{$>$}Among the many statistics on science, called scientometrics, bibliometrics holds a privileged place. Bibliometrics is one  of the few subfields concerned with measuring the output side of science. According to most ``histories'', bibliometrics owes  its systematic development mainly to D.J.D. Price and Eugene Garfield, as founders. The few works conducted before the 1950s  are usually relegated to prehistory. This paper documents how the systematic counting of publications originated with psychologists.  In the early 1900s, psychologists began collecting statistics on their discipline. Publications came to be counted in addresses,  reviews and histories of psychology for several decades. The aim was to contribute to the advancement of psychology. Far from  being a negligible output of a prehistoric type, both the volume and the systematicness of these efforts are witnesses to  what should be considered as pioneering work, and their authors considered as forerunners to bibliometrics.  {$<$}/p{$><$}/section{$>$}},
  chapter = {Scientometrics},
  file = {/home/gabriel/Dropbox/zotero-library/Godin_2006_On the origins of bibliometrics.pdf},
  journal = {Scientometrics},
  language = {en\_US},
  number = {1}
}

@book{goldfinch2012,
  title = {Prometheus {{Assessed}}?: {{Research Measurement}}, {{Peer Review}}, and {{Citation Analysis}}},
  shorttitle = {Prometheus {{Assessed}}?},
  author = {Goldfinch, Shaun and Yamamoto, Kiyoshi},
  year = {2012},
  month = apr,
  publisher = {{Elsevier}},
  abstract = {This book examines the problems, pitfalls and opportunities of different models of assessing research quality, drawing on studies from around the world. Aimed at academics, education officials and public servants, key features include an overview of the argument of whether research should be assessed and how research quality should be determined. Prometheus Assessed? offers a survey of research assessment models in the US, UK, Japan and New Zealand and includes an examination of citation analysis and comparison between the different models.Should research be assessed and what is research quality?Survey of research assessment models in US, UK, Japan and New ZealandExamination of citation analysis},
  file = {/home/gabriel/Dropbox/zotero-library/Goldfinch_Yamamoto_2012_Prometheus Assessed.pdf},
  googlebooks = {h19EAgAAQBAJ},
  isbn = {978-1-78063-301-5},
  keywords = {Language Arts \& Disciplines / Library \& Information Science / General},
  language = {en}
}

@article{gonzalez-betancor2019,
  title = {Publication Modalities `Article in Press' and `Open Access' in Relation to Journal Average Citation},
  author = {{Gonz{\'a}lez-Betancor}, Sara M. and {Dorta-Gonz{\'a}lez}, Pablo},
  year = {2019},
  month = sep,
  volume = {120},
  pages = {1209--1223},
  issn = {1588-2861},
  doi = {10.1007/s11192-019-03156-2},
  abstract = {There has been a generalization in the use of two publication practices by scientific journals during the past decade: (1) `article in press' or early view, which allows access to the accepted paper before its formal publication in an issue; (2) `open access', which allows readers to obtain it freely and free of charge. This paper studies the influence of both publication modalities on the average impact of the journal and its evolution over time. It tries to identify the separate effect of access on citation into two major parts: early view and selection effect, managing to provide some evidence of the positive effect of both. Scopus is used as the database and CiteScore as the measure of journal impact. The prevalence of both publication modalities is quantified. Differences in the average impact factor of group of journals, according to their publication modalities, are tested. The evolution over time of the citation influence, from 2011 to 2016, is also analysed. Finally, a linear regression to explain the correlation of these publication practices with the CiteScore in 2016, in a ceteris paribus context, is estimated. Our main findings show evidence of a positive correlation between average journal impact and advancing the publication of accepted articles, moreover this correlation increases over time. The open access modality, in a ceteris paribus context, also correlates positively with average journal impact.},
  file = {/home/gabriel/Dropbox/zotero-library/González-Betancor_Dorta-González_2019_Publication modalities ‘article in press’ and ‘open access’ in relation to.pdf},
  journal = {Scientometrics},
  language = {en},
  number = {3}
}

@book{guedon2010,
  title = {In {{Oldenburg\'s}} Long Shadow: Librarians, Research Scientists, Publishers, and the Control of Scientific Publishing},
  shorttitle = {In {{Oldenburg\'s}} Long Shadow},
  author = {Gu{\'e}don, Jean-Claude},
  year = {2010},
  publisher = {{Association of Research Libraries}},
  address = {{Washington, D.C}},
  annotation = {OCLC: 255735567},
  file = {/home/gabriel/Dropbox/zotero-library/Guédon_2010_In Oldenburgś long shadow.pdf},
  isbn = {978-1-59407-829-3 978-0-918006-81-3},
  keywords = {todo},
  language = {en}
}

@article{haeffner-cavaillon2009,
  title = {The Use of Bibliometric Indicators to Help Peer-Review Assessment},
  author = {{Haeffner-Cavaillon}, Nicole and {Graillot-Gak}, Claude},
  year = {2009},
  month = feb,
  volume = {57},
  pages = {33--38},
  issn = {0004-069X},
  doi = {10.1007/s00005-009-0004-2},
  abstract = {Inserm is the only French public research institution entirely dedicated to human health. Inserm supports research across the biomedical spectrum in all major disease areas, from fundamental lab-based science to clinical trials. To translate its scientists findings into tangible health benefits Inserm has its own affiliated company, Inserm Transfert, which works with industry. Since 2001, Inserm has set up the on-line file management software for the evaluation of researchers and laboratories, called EVA (www.eva.inserm.fr). EVA includes all grant applications, assessment reports, grading evaluation forms and include an automated bibliometric indicator software that enables to calculate for each researcher of the teams, the number of publications, impact factor of journals, number of citations, citation index, number of Top 1\% publications \ldots{} The indicators take into account research fields, the year of publications, the author position within the participants., Bibliometrics is now considered as a tool for science policy providing indicators to measure productivity and scientific quality, thereby supplying a basis for evaluating and orienting R\&D. It is also a potential tool for evaluation. It is neutral, allows comparative (national \& international) assessment and may select papers in the forefront in all fields. For each team bibliometric indicators were calculated for all researchers with permanent positions or long term positions (3 to 5 years). The use of bibliometric indicators requires a great vigilance but according to our experience they without any doubt enrich the committee's debates. We present the analysis of the data of 600 research teams evaluated in 2007\textendash 2008.},
  file = {/home/gabriel/Dropbox/zotero-library/Haeffner-Cavaillon_Graillot-Gak_2009_The use of bibliometric indicators to help peer-review assessment4.pdf},
  journal = {Archivum Immunologiae et Therapiae Experimentalis},
  keywords = {todo},
  number = {1},
  pmcid = {PMC3957005},
  pmid = {19219530}
}

@article{hajjem2006,
  title = {Ten-{{Year Cross}}-{{Disciplinary Comparison}} of the {{Growth}} of {{Open Access}} and {{How}} It {{Increases Research Citation Impact}}},
  author = {Hajjem, C. and Harnad, S. and Gingras, Y.},
  year = {2006},
  month = aug,
  abstract = {Lawrence (2001)found computer science articles that were openly accessible (OA) on the Web were cited more. We replicated this in physics. We tested 1,307,038 articles published across 12 years (1992-2003) in 10 disciplines (Biology, Psychology, Sociology, Health, Political Science, Economics, Education, Law, Business, Management). A robot trawls the Web for full-texts using reference metadata ISI citation data (signal detectability d'=2.45; bias = 0.52). Percentage OA (relative to total OA + NOA) articles varies from 5\%-16\% (depending on discipline, year and country) and is slowly climbing annually (correlation r=.76, sample size N=12, probability p {$<$} 0.005). Comparing OA and NOA articles in the same journal/year, OA articles have consistently more citations, the advantage varying from 36\%-172\% by discipline and year. Comparing articles within six citation ranges (0, 1, 2-3, 4-7, 8-15, 16+ citations), the annual percentage of OA articles is growing significantly faster than NOA within every citation range (r {$>$} .90, N=12, p {$<$} .0005) and the effect is greater with the more highly cited articles (r = .98, N=6, p {$<$} .005). Causality cannot be determined from these data, but our prior finding of a similar pattern in physics, where percent OA is much higher (and even approaches 100\% in some subfields), makes it unlikely that the OA citation advantage is merely or mostly a self-selection bias (for making only one's better articles OA). Further research will analyze the effect's timing, causal components and relation to other variables.},
  archiveprefix = {arXiv},
  eprint = {cs/0606079},
  eprinttype = {arxiv},
  file = {/home/gabriel/Dropbox/zotero-library/Hajjem et al_2006_Ten-Year Cross-Disciplinary Comparison of the Growth of Open Access and How it.pdf},
  journal = {arXiv:cs/0606079},
  keywords = {Computer Science - Digital Libraries}
}

@article{hammarfelt2017,
  title = {Indicators as Judgment Devices: {{An}} Empirical Study of Citizen Bibliometrics in Research Evaluation},
  shorttitle = {Indicators as Judgment Devices},
  author = {Hammarfelt, Bj{\"o}rn and Rushforth, Alexander D.},
  year = {2017},
  month = jul,
  volume = {26},
  pages = {169--180},
  issn = {0958-2029},
  doi = {10.1093/reseval/rvx018},
  abstract = {A researcher's number of publications has been a fundamental merit in the competition for academic positions since the late 18th century. Today, the simple counting of publications has been supplemented with a whole range of bibliometric indicators, which supposedly not only measures the volume of research but also its impact. In this study, we investigate how bibliometrics are used for evaluating the impact and quality of publications in two specific settings: biomedicine and economics. Our study exposes the various metrics used in external evaluations of candidates for academic positions at Swedish universities. Moreover, we show how different bibliometric indicators, both explicitly and implicitly, are employed to assess and rank candidates. Our findings contribute to a further understanding of bibliometric indicators as `judgment devices' that are employed in evaluating individuals and their published works within specific fields. We also show how `expertise' in using bibliometrics for evaluative purposes is negotiated at the interface between domain knowledge and skills in using indicators. In line with these results, we propose that the use of metrics we report is best described as a form of `citizen bibliometrics'\textemdash an underspecified term which we build upon in the article.},
  file = {/home/gabriel/Dropbox/zotero-library/Hammarfelt_Rushforth_2017_Indicators as judgment devices.pdf},
  journal = {Research Evaluation},
  number = {3}
}

@article{hammarfelt2018,
  title = {What Is a Discipline? {{The}} Conceptualization of Research Areas and Their Operationalization in Bibliometric Research},
  author = {Hammarfelt, Bj{\"o}rn},
  year = {2018},
  pages = {8},
  abstract = {This paper highlights disadvantages of conceptual impreciseness, and advocates further attention to the labels and concepts used when classifying clusters or groups based on bibliographic data. The main focus of the analysis is on the concept of `discipline' and how it is used in bibliometric research, but the implications concern a broader array of related terms.},
  file = {/home/gabriel/Dropbox/zotero-library/Hammarfelt_2018_What is a discipline.pdf},
  language = {en}
}

@book{harzing2010,
  title = {The {{Publish Or Perish Book}}: {{Your Guide}} to {{Effective}} and {{Responsible Citation Analysis}}},
  shorttitle = {The {{Publish Or Perish Book}}},
  author = {Harzing, Anne-Wil},
  year = {2010},
  publisher = {{Tarma Software Research Pty Limited}},
  abstract = {The first chapter provides a brief introduction to citation analysis as well as an overview of the most popular data sources and metrics in use. Part 1: How to use Publish or Perish more effectively The first part provides step-by-step instructions on how to use Publish or Perish more effectively. An introduction to the main features of the software is first provided in Chapter 2. Chapters 3 and 4 subsequently provide detailed instructions on how to conduct effect Author and Journal Queries. Chapter 5 is devoted to the broader applications of the General Citation search that can be used to find particular papers, conduct advanced author and journal queries, compare institutional performance and conduct a literature review. Finally, Chapter 6 discusses how the Multi-query Center can be used to effectively store and manage queries for future use. Part 2: Day-to-day uses of Publish or Perish citation analysis In Part 2, I present the most common day-to-day uses of the Publish or Perish software. Chapter 7 provides tips and tricks for academics that need to make their case for tenure or promotion. I discuss the importance of reference groups as well as several ways to show your citation record to its best advantage. In Chapter 8, I discuss how to evaluate other academics. The examples in this chapter vary from a 5-minute preparation before meeting someone you don't know, to evaluating editorial board members or prospective PhD supervisors, from writing up tributes (or laudations) and eulogies to deciding on publication awards and preparing for a job interview. Chapter 9 turns the tables and looks at citation analysis for Deans and other academic administrators. It includes four topics: the need to accept Google Scholar as an alternative data source, the myths about self-citation, the inappropriateness of citation analysis at early career stages, and the differences in citation impact across disciplines.},
  file = {/home/gabriel/Dropbox/zotero-library/Harzing_2010_The Publish Or Perish Book.pdf},
  isbn = {978-0-9808485-2-6},
  language = {en}
}

@article{hatch2020,
  title = {Changing How We Evaluate Research Is Difficult, but Not Impossible},
  author = {Hatch, Anna and Curry, Stephen},
  year = {2020},
  month = aug,
  volume = {9},
  pages = {e58654},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.58654},
  abstract = {The San Francisco Declaration on Research Assessment (DORA) was published in 2013 and described how funding agencies, institutions, publishers, organizations that supply metrics, and individual researchers could better evaluate the outputs of scientific research. Since then DORA has evolved into an active initiative that gives practical advice to institutions on new ways to assess and evaluate research. This article outlines a framework for driving institutional change that was developed at a meeting convened by DORA and the Howard Hughes Medical Institute. The framework has four broad goals: understanding the obstacles to changes in the way research is assessed; experimenting with different approaches; creating a shared vision when revising existing policies and practices; and communicating that vision on campus and beyond.},
  file = {/home/gabriel/Dropbox/zotero-library/Hatch_Curry_2020_Changing how we evaluate research is difficult, but not impossible.pdf},
  journal = {eLife},
  keywords = {careers in science,culture change,fav,institutional change,research assessment,research culture,todo}
}

@incollection{haustein2015,
  title = {The {{Use}} of {{Bibliometrics}} for {{Assessing Research}}: {{Possibilities}}, {{Limitations}} and {{Adverse Effects}}},
  shorttitle = {The {{Use}} of {{Bibliometrics}} for {{Assessing Research}}},
  booktitle = {Incentives and {{Performance}}},
  author = {Haustein, Stefanie and Larivi{\`e}re, Vincent},
  editor = {Welpe, Isabell M. and Wollersheim, Jutta and Ringelhan, Stefanie and Osterloh, Margit},
  year = {2015},
  pages = {121--139},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-09785-5_8},
  abstract = {Researchers are used to being evaluated: publications, hiring, tenure and funding decisions are all based on the evaluation of research. Traditionally, this evaluation relied on judgement of peers but, in the light of limited resources and increased bureaucratization of science, peer review is getting more and more replaced or complemented with bibliometric methods. Central to the introduction of bibliometrics in research evaluation was the creation of the Science Citation Index (SCI) in the 1960s, a citation database initially developed for the retrieval of scientific information. Embedded in this database was the Impact Factor, first used as a tool for the selection of journals to cover in the SCI, which then became a synonym for journal quality and academic prestige. Over the last 10 years, this indicator became powerful enough to influence researchers' publication patterns in so far as it became one of the most important criteria to select a publication venue. Regardless of its many flaws as a journal metric and its inadequacy as a predictor of citations on the paper level, it became the go-to indicator of research quality and was used and misused by authors, editors, publishers and research policy makers alike. The h-index, introduced as an indicator of both output and impact combined in one simple number, has experienced a similar fate, mainly due to simplicity and availability. Despite their massive use, these measures are too simple to capture the complexity and multiple dimensions of research output and impact. This chapter provides an overview of bibliometric methods, from the development of citation indexing as a tool for information retrieval to its application in research evaluation, and discusses their misuse and effects on researchers' scholarly communication behavior.},
  file = {/home/gabriel/Dropbox/zotero-library/Haustein_Larivière_2015_The Use of Bibliometrics for Assessing Research.pdf},
  isbn = {978-3-319-09784-8 978-3-319-09785-5},
  keywords = {fav},
  language = {en}
}

@article{hayashi2013,
  title = {{Afinidades eletivas entre a cientometria e os estudos sociais da ci\^encia}},
  author = {Hayashi, Maria Cristina Piumbato Innocentini},
  year = {2013},
  month = sep,
  volume = {5},
  pages = {57--88},
  issn = {1984-9605},
  doi = {10.20396/rfe.v5i2.8635395},
  copyright = {Copyright (c) 2018 Filosofia e Educa\c{c}\~ao},
  file = {/home/gabriel/Dropbox/zotero-library/Hayashi_2013_Afinidades eletivas entre a cientometria e os estudos sociais da ciência.pdf},
  journal = {Filosofia e Educa\c{c}\~ao},
  keywords = {Cientometria. Bibliometria. Estudos sociais da ciência.,todo},
  language = {pt},
  number = {2}
}

@article{hicks2015,
  title = {Bibliometrics: {{The Leiden Manifesto}} for Research Metrics},
  shorttitle = {Bibliometrics},
  author = {Hicks, Diana and Wouters, Paul and Waltman, Ludo and {de Rijcke}, Sarah and Rafols, Ismael},
  year = {2015},
  month = apr,
  volume = {520},
  pages = {429--431},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/520429a},
  abstract = {Use these ten principles to guide research evaluation, urge Diana Hicks, Paul Wouters and colleagues.},
  copyright = {2015 Nature Publishing Group},
  file = {/home/gabriel/Dropbox/zotero-library/Hicks et al_2015_Bibliometrics.pdf},
  journal = {Nature},
  keywords = {todo},
  language = {en},
  number = {7548}
}

@article{hlavcheva2019,
  title = {A {{Survey}} of {{Informetric Methods}} and {{Technologies}}},
  author = {Hlavcheva, Yu. M. and Kanishcheva, O. V. and Borysova, N. V.},
  year = {2019},
  month = may,
  volume = {55},
  pages = {503--513},
  issn = {1573-8337},
  doi = {10.1007/s10559-019-00158-z},
  abstract = {A survey of informetric methods and technologies is presented. Problems and directions of informetrics are defined. The interrelations between the concepts such as scientometrics, bibliometrics, informetrics, webometrics, and altmetrics are shown. The existing informetric models and methods and also topical problems of informetrics are analyzed. Available analytic-and-search scientometric databases and systems are considered and their drawbacks and advantages are revealed. Characteristics of scientometric systems, their components, and factors that affect scientometric indices are determined. Based on the conducted research, promising directions for developing scientometric systems are formulated.},
  file = {/home/gabriel/Dropbox/zotero-library/Hlavcheva et al_2019_A Survey of Informetric Methods and Technologies.pdf},
  journal = {Cybernetics and Systems Analysis},
  keywords = {todo},
  language = {en},
  number = {3}
}

@article{holsapple2018,
  title = {Isn't It about Time to Meet {{DORA}}?},
  author = {Holsapple, Clyde W.},
  year = {2018},
  month = oct,
  volume = {28},
  pages = {287--290},
  publisher = {{Taylor \& Francis}},
  issn = {1091-9392},
  doi = {10.1080/10919392.2018.1522774},
  annotation = {\_eprint: https://doi.org/10.1080/10919392.2018.1522774},
  file = {/home/gabriel/Dropbox/zotero-library/Holsapple_2018_Isn’t it about time to meet DORA.pdf},
  journal = {Journal of Organizational Computing and Electronic Commerce},
  number = {4}
}

@article{jack2021,
  title = {Scientific Knowledge Production and Economic Catching-up: An Empirical Analysis},
  shorttitle = {Scientific Knowledge Production and Economic Catching-Up},
  author = {Jack, Pablo and Lachman, Jeremias and L{\'o}pez, Andr{\'e}s},
  year = {2021},
  month = apr,
  issn = {1588-2861},
  doi = {10.1007/s11192-021-03973-4},
  abstract = {This paper aims to investigate the relationship between the production of scientific knowledge and level of income for a panel of 56 countries during the period 1996\textendash 2015. We argue that the accumulation of scientific knowledge is a key factor for the enhancement of educational and technological capabilities within an economy, and hence may have a positive impact on GDP per capita levels. We use academic publications in refereed journals (in all areas and specifically in engineering) as a proxy of scientific performance. As regards the impacts of scientific performance, we distinguish between high- and middle-income countries and, among the latter, between Asian and Latin America. The results show that academic publications are consistently and positively correlated with income per capita, for both middle and high-income countries. We also find non-linear effects in both groups. Those effects are lower for middle-income countries suggesting the presence of decreasing returns on academic performance. Finally, while Asian countries benefited from specialization in engineering research, no such effects were found for their Latin American peers.},
  file = {/home/gabriel/Dropbox/zotero-library/Jack et al_2021_Scientific knowledge production and economic catching-up.pdf},
  journal = {Scientometrics},
  keywords = {todo},
  language = {en}
}

@article{jaffe2020,
  title = {{{QUALIS}}: {{The}} Journal Ranking System Undermining the Impact of {{Brazilian}} Science},
  shorttitle = {{{QUALIS}}},
  author = {Jaff{\'e}, Rodolfo},
  year = {2020},
  month = nov,
  volume = {92},
  publisher = {{Academia Brasileira de Ci\^encias}},
  issn = {0001-3765, 0001-3765, 1678-2690},
  doi = {10.1590/0001-3765202020201116},
  abstract = {Abstract A system called QUALIS was implemented in Brazil in 2009, intended to rank graduate programs from different subject areas and promote selected national journals. Since this system uses a complicated suit of criteria (differing among subject areas) to group journals into discrete categories, it could potentially create incentives to publish in low-impact journals ranked highly by QUALIS. Here I assess the influence of the QUALIS journal ranking system on the global impact of Brazilian science. Brazil shows a steeper decrease in the number of citations per document since the implementation of this QUALIS system, compared to the top Latin American countries publishing more scientific articles. All subject areas showed some degree of bias, with social sciences being usually more biased than natural sciences. Lastly, the decrease in the number of citations over time proved steeper in a more biased subject area, suggesting a faster shift towards low-impact journals. Overall, the findings documented here suggest that the QUALIS system has undermined the global impact of Brazilian science, and reinforce a recent recommendation from an official committee evaluating graduate programs to eliminate QUALIS. A system based on impact metrics could avoid introducing distorted incentives, and thereby boost the global impact of Brazilian science.},
  file = {/home/gabriel/Dropbox/zotero-library/Jaffé_2020_QUALIS.pdf},
  journal = {Anais da Academia Brasileira de Ci\^encias},
  keywords = {CAPES,citations,fav,impact factor,scientometrics,Scimago,Scopus,todo},
  language = {en}
}

@article{jappe2018,
  title = {Does Bibliometric Research Confer Legitimacy to Research Assessment Practice? {{A}} Sociological Study of Reputational Control, 1972-2016},
  shorttitle = {Does Bibliometric Research Confer Legitimacy to Research Assessment Practice?},
  author = {Jappe, Arlette and Pithan, David and Heinze, Thomas},
  editor = {Lozano, Sergi},
  year = {2018},
  month = jun,
  volume = {13},
  pages = {e0199031},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0199031},
  abstract = {The use of bibliometric measures in the evaluation of research has increased considerably based on expertise from the growing research field of evaluative citation analysis (ECA). However, mounting criticism of such metrics suggests that the professionalization of bibliometric expertise remains contested. This paper investigates why impact metrics, such as the journal impact factor and the h-index, proliferate even though their legitimacy as a means of professional research assessment is questioned. Our analysis is informed by two relevant sociological theories: Andrew Abbott's theory of professions and Richard Whitley's theory of scientific work. These complementary concepts are connected in order to demonstrate that ECA has failed so far to provide scientific authority for professional research assessment. This argument is based on an empirical investigation of the extent of reputational control in the relevant research area. Using three measures of reputational control that are computed from longitudinal inter-organizational networks in ECA (1972\textendash 2016), we show that peripheral and isolated actors contribute the same number of novel bibliometric indicators as central actors. In addition, the share of newcomers to the academic sector has remained high. These findings demonstrate that recent methodological debates in ECA have not been accompanied by the formation of an intellectual field in the sociological sense of a reputational organization. Therefore, we conclude that a growing gap exists between an academic sector with little capacity for collective action and increasing demand for routine performance assessment by research organizations and funding agencies. This gap has been filled by database providers. By selecting and distributing research metrics, these commercial providers have gained a powerful role in defining de-facto standards of research excellence without being challenged by expert authority.},
  file = {/home/gabriel/Dropbox/zotero-library/Jappe et al_2018_Does bibliometric research confer legitimacy to research assessment practice.pdf},
  journal = {PLOS ONE},
  keywords = {fav},
  language = {en},
  number = {6}
}

@article{jarneving2005,
  title = {A Comparison of Two Bibliometric Methods for Mapping of the Research Front},
  author = {Jarneving, Bo},
  year = {2005},
  month = nov,
  volume = {65},
  pages = {245--263},
  issn = {1588-2861},
  doi = {10.1007/s11192-005-0270-7},
  abstract = {This paper builds on previous research concerned with the classification and specialty mapping of research fields. Two methods are put to test in order to decide if significant differences as to mapping results of the research front of a science field occur when compared. The first method was based on document co-citation analysis where papers citing co-citation clusters were assumed to reflect the research front. The second method was bibliographic coupling where likewise citing papers were assumed to reflect the research front. The application of these methods resulted in two different types of aggregations of papers: (1) groups of papers citing clusters of co-cited works and (2) clusters of bibliographically coupled papers. The comparision of the two methods as to mapping results was pursued by matching word profiles of groups of papers citing a particular co-citation cluster with word profiles of clusters of bibliographically coupled papers. Findings suggested that the research front was portrayed in two considerably different ways by the methods applied. It was concluded that the results in this study would support a further comparative study of these methods on a more detailed and qualitative ground. The original data set encompassed 73,379 articles from the fifty most cited environmental science journals listed in Journal Citation Report, science edition downloaded from the Science Citation Index on CD-ROM.},
  file = {/home/gabriel/Dropbox/zotero-library/Jarneving_2005_A comparison of two bibliometric methods for mapping of the research front.pdf},
  journal = {Scientometrics},
  language = {en},
  number = {2}
}

@article{johnson2020,
  title = {Peer Review versus the H-Index for Evaluation of Individual Researchers in the Biological Sciences},
  author = {Johnson, Steven D.},
  year = {2020},
  month = oct,
  volume = {116},
  pages = {1--5},
  publisher = {{Academy of Science of South Africa}},
  issn = {0038-2353},
  doi = {10.17159/sajs.2020/8700},
  file = {/home/gabriel/Dropbox/zotero-library/Johnson_2020_Peer review versus the h-index for evaluation of individual researchers in the.pdf},
  journal = {South African Journal of Science},
  number = {9-10}
}

@article{joshi2014,
  title = {Bibliometric Indicators for Evaluating the Quality of Scientifc Publications},
  author = {Joshi, Medha A.},
  year = {2014},
  month = mar,
  volume = {15},
  pages = {258--262},
  issn = {1526-3711},
  doi = {10.5005/jp-journals-10024-1525},
  abstract = {Evaluation of quality and quantity of publications can be done using a set of statistical and mathematical indices called bibliometric indicators. Two major categories of indicators are (1) quantitative indicators that measure the research productivity of a researcher and (2) performance indicators that evaluate the quality of publications. Bibliometric indicators are important for both the individual researcher and organizations. They are widely used to compare the performance of the individual researchers, journals and universities. Many of the appointments, promotions and allocation of research funds are based on these indicators. This review article describes some of the currently used bibliometric indicators such as journal impact factor, crown indicator, h-index and it's variants. It is suggested that for comparison of scientific impact and scientific output of researchers due consideration should be given to various factors affecting theses indicators.},
  file = {/home/gabriel/Dropbox/zotero-library/Joshi_2014_Bibliometric indicators for evaluating the quality of scientifc publications.pdf},
  journal = {The Journal of Contemporary Dental Practice},
  keywords = {Authorship,Bibliometrics,Dental Research,fav,Humans,Journal Impact Factor,Periodicals as Topic,Publishing},
  language = {eng},
  number = {2},
  pmid = {25095854}
}

@article{juznic2010,
  title = {Scientometric Indicators: Peer-Review, Bibliometric Methods and Conflict of Interests},
  shorttitle = {Scientometric Indicators},
  author = {Ju{\v z}ni{\v c}, Primo{\v z} and Pe{\v c}lin, Stojan and {\v Z}aucer, Matja{\v z} and Mandelj, Tilen and Pu{\v s}nik, Miro and Dem{\v s}ar, Franci},
  year = {2010},
  month = nov,
  volume = {85},
  pages = {429--441},
  issn = {1588-2861},
  doi = {10.1007/s11192-010-0230-8},
  abstract = {The paper discusses the role of scientometric indicators in peer-review selection of research project proposals. An ex post facto evaluation was made of three calls for research project proposals in Slovenia: 2003 with a peer review system designed in a way that conflict of interest was not avoided effectively, 2005 with a sound international peer-review system with minimized conflict of interest influence but a limited number of reviewers, and 2008 with a combination of scientometric indicators and a sound international peer review with minimized conflict of interest influence. The hypothesis was that the three different peer review systems would have different correlations with the same set of scientometric indicators. In the last two decision-making systems (2005 and 2008) where conflict of interest was effectively avoided, we have a high percentage (65\%) of projects that would have been selected in the call irrespective of the method (peer review or bibliometrics solely). In contrast, in the 2003 call there is a significantly smaller percentage (49\%) of projects that would have been selected in the call irrespective of the method (peer review or bibliometrics solely). It was shown that while scientometric indicators can hardly replace the peer-review system as the ultimate decision-making and support system, they can reveal its weaknesses on one hand and on the other can verify peer-review scores and minimize conflict of interest if necessary.},
  file = {/home/gabriel/Zotero/storage/RUMRLVYA/Južnič et al. - 2010 - Scientometric indicators peer-review, bibliometri.pdf},
  journal = {Scientometrics},
  keywords = {todo},
  language = {en},
  number = {2}
}

@article{kamrani,
  title = {Do Researchers Know What the H-Index Is? {{And}} How Do They Estimate Its Importance?},
  author = {Kamrani, Pantea},
  pages = {20},
  abstract = {The h-index is a widely used scientometric indicator on the researcher level working with a simple combination of publication and citation counts. In this article, we pursue two goals, namely the collection of empirical data about researchers' personal estimations of the importance of the h-index for themselves as well as for their academic disciplines, and on the researchers' concrete knowledge on the h-index and the way of its calculation. We worked with an online survey (including a knowledge test on the calculation of the h-index), which was finished by 1081 German university professors. We distinguished between the results for all participants, and, additionally, the results by gender, generation, and field of knowledge. We found a clear binary division between the academic knowledge fields: For the sciences and medicine the h-index is important for the researchers themselves and for their disciplines, while for the humanities and social sciences, economics, and law the h-index is considerably less important. Two fifths of the professors do not know details on the h-index or wrongly deem to know what the h-index is and failed our test. The researchers' knowledge on the h-index is much smaller in the academic branches of the humanities and the social sciences. As the h-index is important for many researchers and as not all researchers are very knowledgeable about this author-specific indicator, it seems to be necessary to make researchers more aware of scholarly metrics literacy.},
  file = {/home/gabriel/Dropbox/zotero-library/Kamrani_Do researchers know what the h-index is.pdf},
  language = {en}
}

@article{karanatsiou,
  title = {Bibliometrics and {{Altmetrics}} Literature Review: {{Performance}} Indicators and Comparison Analysis},
  author = {Karanatsiou, Dimitra and Misirlis, Nikolaos and Vlachopoulou, Maro},
  pages = {21},
  file = {/home/gabriel/Dropbox/zotero-library/Karanatsiou et al_Bibliometrics and Altmetrics literature review.pdf},
  language = {en}
}

@article{kellner2008,
  title = {H-Index in the {{Brazilian Academy}} of {{Sciences}}: Comments and Concerns},
  shorttitle = {H-Index in the {{Brazilian Academy}} of {{Sciences}}},
  author = {Kellner, Alexander W. A. and Ponciano, Luiza C. M. O.},
  year = {2008},
  month = dec,
  volume = {80},
  pages = {771--781},
  publisher = {{Academia Brasileira de Ci\^encias}},
  issn = {0001-3765, 0001-3765, 1678-2690},
  doi = {10.1590/S0001-37652008000400016},
  abstract = {Bibliometric parameters have been used in order to evaluate a scientist's performance. The h-index has been gradually accepted as the most adequate parameter for this purpose. To have an idea of this index among Brazilian scientists, we performed an analysis of this parameter for the full members of the Brazilian Academy of Sciences (BAS). The h-index of 402 members listed in 10 distinct categories by the BAS was determined, cross-checked with the curriculum vitae of each of them listed at the Plataforma Lattes database (CVL) and compared with each other. Despite the large production, mostly in journals without impact factor, the h-indexes among the BAS members are comparatively low and show a large variation in all of the 10 categories, particularly in Biomedical and Physical sciences. The highest average of h-index values was found in Biomedical, Health and Chemical sciences; the lowest values were found in Human sciences where this index is meaningless. Several problems due to the trend that new and "fresh" publications need be constantly produced (the "bakery-effect") are discussed. This study points to the need of developing countries such as Brazil to invest in national scientific journals in order to make them gradually part of the mainstream journals. This would have a positive effect on bibliometric parameters of Brazilian researchers, including the h-index.},
  file = {/home/gabriel/Dropbox/zotero-library/Kellner_Ponciano_2008_H-index in the Brazilian Academy of Sciences.pdf},
  journal = {Anais da Academia Brasileira de Ci\^encias},
  keywords = {bibliometric indexes,Brazilian Academy of Sciences,h-index,scientometrics},
  language = {en}
}

@article{kellner2017,
  title = {The {{Qualis}} System: A Perspective from a Multidisciplinary Journal},
  shorttitle = {The {{Qualis}} System},
  author = {Kellner, Alexander W. A.},
  year = {2017-Jul-Sep},
  volume = {89},
  pages = {1339--1342},
  publisher = {{Academia Brasileira de Ci\^encias}},
  issn = {0001-3765, 0001-3765, 1678-2690},
  doi = {10.1590/0001-37652017893},
  file = {/home/gabriel/Dropbox/zotero-library/Kellner_2017_The Qualis system.pdf},
  journal = {Anais da Academia Brasileira de Ci\^encias},
  language = {en}
}

@article{kokol,
  title = {Application of Bibliometrics in Medicine: A Historical Bibliometrics Analysis},
  shorttitle = {Application of Bibliometrics in Medicine},
  author = {Kokol, Peter and Vo{\v s}ner, Helena Bla{\v z}un and Zavr{\v s}nik, Jernej},
  volume = {n/a},
  issn = {1471-1842},
  doi = {10.1111/hir.12295},
  abstract = {Background The application of bibliometrics in medicine enables one to analyse vast amounts of publications and their production patterns on macroscopic and microscopic levels. Objectives The aim of the study was to analyse the historical perspective of research literature production regarding application of bibliometrics in medicine. Methods Publications related to application of bibliometrics in medicine from 1970 to 2018 were harvested from the Scopus bibliographic database. Reference Publication Year Spectroscopy was triangulated with the VOSViewer to identify historical roots and evolution of topics and clinical areas. Results The search resulted in 6557 publications. The literature production trend was positive. Historical roots analysis identified 33 historical roots and 16 clinical areas where bibliometrics was applied. Discussion The increase in productivity in application of bibliometrics in medicine might be attributed to increased use of quantitative metrics in research evaluation, publish or perish phenomenon and the increased use of evidence-based medicine. Conclusion The trend of the literature production was positive. Medicine was in the forefront of knowledge development in bibliometrics. reference publication year spectroscopy proved to be an accurate method which was able to identify most of the historical roots.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/hir.12295},
  copyright = {\textcopyright{} 2020 Health Libraries Group},
  file = {/home/gabriel/Dropbox/zotero-library/Kokol et al_Application of bibliometrics in medicine.pdf},
  journal = {Health Information \& Libraries Journal},
  keywords = {bibliometrics,biomedical,citation analysis,evidence-based medicine (EBM),research},
  language = {en},
  number = {n/a}
}

@article{kostenko2015,
  title = {Scientometrics: {{A Tool}} for {{Monitoring}} and {{Support}} of {{Research}}},
  author = {Kostenko, L and Zhabin, A and Kuznetsov, A and Lukashevich, T and Kukharchuk, E and Simonenko, T},
  year = {2015},
  pages = {7},
  abstract = {The origins of scientometrics (research metrics) are discussed. The approaches to research evaluation are reviewed, and the tendency to replacing formal quantitative indicators by expert review based on bibliometric indicators is emphasized. The principles of ``Leiden Manifesto of Scientometrics'' are set out, providing for transparent monitoring and support of research and encouraging constructive dialog between the scientific community and the public. The methodological framework and the peculiarities of implementation of the information and analytical system ``Bibliometryka Ukrayinskoyi Nauky'' (``Bibliometrics of the Ukrainian Science''), constructed by the Vernadsky National Library of Ukraine, are shown. The proposals on creating advisory councils, responsible for formulating conclusions on the research effectiveness of institutions, are given. The feasibility of building a common platform for expert evaluation of research for the Eastern Partnership Countries by launching similar bibliometric projects in these countries and their further convergence is considered.},
  file = {/home/gabriel/Dropbox/zotero-library/Kostenko et al_2015_Scientometrics.pdf},
  keywords = {todo},
  language = {en}
}

@article{kowaltowski2021,
  title = {Responsible {{Science Assessment}}: Downplaying Indexes, Boosting Quality},
  shorttitle = {Responsible {{Science Assessment}}},
  author = {Kowaltowski, Alicia J. and Silber, Ariel M. and Oliveira, Marcus F.},
  year = {2021},
  month = feb,
  volume = {93},
  publisher = {{Academia Brasileira de Ci\^encias}},
  issn = {0001-3765, 0001-3765, 1678-2690},
  doi = {10.1590/0001-3765202120191513},
  abstract = {Abstract Scientists are facing enormous pressures posed by growing scientific communities and stagnant/reduced funding. In this scenario, mechanisms of knowledge achievement and management, as well as how recruitment, progression and evaluation are carried out should be reevaluated. We argue here that knowledge has become a profitable commodity and, as a consequence, excessive academic quantification, individual output assessment problems and abusive editorial market strategies have reached unsustainable levels. We propose to reinforce existing guidelines and to establish new ones to overcome these issues. Our proposal, the Initiative for Responsible Scientific Assessment (IRSA), has the main goal to strengthen and expand previous movements in the scientific community to promote higher quality research assessment, focused on better Science.},
  file = {/home/gabriel/Dropbox/zotero-library/Kowaltowski et al_2021_Responsible Science Assessment.pdf},
  journal = {Anais da Academia Brasileira de Ci\^encias},
  keywords = {Evaluation,fav,impact factor,peer-review,policy,quantophrenia,todo,university},
  language = {en}
}

@article{kuhlmannjr.2014,
  title = {{Publica\c{c}\~ao em peri\'odicos cient\'ificos: \'etica, qualidade e avalia\c{c}\~ao da pesquisa}},
  shorttitle = {{Publica\c{c}\~ao em peri\'odicos cient\'ificos}},
  author = {Kuhlmann Jr., Moys{\'e}s},
  year = {2014},
  month = mar,
  volume = {44},
  pages = {16--32},
  publisher = {{Funda\c{c}\~ao Carlos Chagas}},
  issn = {0100-1574, 0100-1574, 1980-5314},
  doi = {10.1590/198053142877},
  abstract = {A baixa qualidade de artigos enviados aos peri\'odicos cient\'ificos e os ardis utilizados para publicar - que resultariam de uma pol\'itica de avalia\c{c}\~ao acad\^emica que valoriza a quantidade de trabalhos publicados ponderada pela pontua\c{c}\~ao das revistas - preocupam cada vez mais editores e pesquisadores. Este artigo problematiza a no\c{c}\~ao de produtivismo e a rela\c{c}\~ao causal que se estabelece entre a press\~ao para publicar e a qualidade dos artigos, argumentando que o problema, no mais das vezes, se defronta diretamente com o pr\'oprio processo da produ\c{c}\~ao cient\'ifica. Discorre-se sobre quest\~oes relacionadas \`a avalia\c{c}\~ao e aos princ\'ipios \'eticos envolvidos na elabora\c{c}\~ao e submiss\~ao de artigos. Indica-se a leitura dos documentos aprovados na 2\textordfeminine{} Confer\^encia sobre a Integridade na Pesquisa, ocorrida em Cingapura, em 2010 - publicados nesta edi\c{c}\~ao - que estabelecem padr\~oes internacionais para editores de peri\'odicos e para autores, e que constituem um importante auxiliar na forma\c{c}\~ao de pesquisadores.},
  file = {/home/gabriel/Dropbox/zotero-library/Kuhlmann Jr._2014_Publicação em periódicos científicos.pdf},
  journal = {Cadernos de Pesquisa},
  keywords = {artigos científicos,avaliação,ética,qualidade},
  language = {pt}
}

@article{kumar2009,
  title = {Impact of the Impact Factor in Biomedical Research: Its Use and Misuse},
  shorttitle = {Impact of the Impact Factor in Biomedical Research},
  author = {Kumar, V. and Upadhyay, S. and Medhi, B.},
  year = {2009},
  month = aug,
  volume = {50},
  pages = {752--755},
  issn = {0037-5675},
  abstract = {The impact factor was created in the biomedical research field in order to measure a journal's value by calculating the average number of citations per article over a period of time. It was initially developed to help libraries decide which highly-cited journals to subscribe to. However, at present, it is being misused to judge the quality of a researcher or medical scientist as well as the quality of the work done. It contains serious sources of errors and flaws, resulting in strong biases against culture- and language-bound medical subspecialties. The present article is aimed to highlight the impact of the impact factor in the biomedical research, as well as its use and misuse.},
  file = {/home/gabriel/Dropbox/zotero-library/Kumar et al_2009_Impact of the impact factor in biomedical research.pdf},
  journal = {Singapore Medical Journal},
  keywords = {Bibliometrics,Biomedical Research,Databases; Bibliographic,fav,Journal Impact Factor,Periodicals as Topic,Publishing,Reproducibility of Results,Time Factors},
  language = {eng},
  number = {8},
  pmid = {19710969}
}

@article{kumar2015,
  title = {Popular {{Scientometric Analysis}}, {{Mapping}} and {{Visualisation Softwares}}: {{An Overview}}},
  author = {Kumar, Ashok and Shivarama, J and Choukimath, Puttaraj A},
  year = {2015},
  pages = {14},
  abstract = {Measurement of scientific productivity has been regarded as main indicator of ascertaining impact of research over scientific community. To showcase the impact of research using science mapping and visualisation, social network analysis has been developed over the period of time. These methods help researchers to understand the structural, temporal and dynamic development of a discipline. The present paper provides a comprehensive overview of widely used softwares used for scientometric analysis, mapping and visualisation.},
  file = {/home/gabriel/Dropbox/zotero-library/Kumar et al_2015_Popular Scientometric Analysis, Mapping and Visualisation Softwares.pdf},
  keywords = {todo},
  language = {en}
}

@article{kumar2018,
  title = {Is ``{{Impact}}'' the ``{{Factor}}'' That Matters\ldots? ({{Part I}})},
  shorttitle = {Is ``{{Impact}}'' the ``{{Factor}}'' That Matters\ldots?},
  author = {Kumar, Ashish},
  year = {2018},
  month = apr,
  volume = {22},
  pages = {95--6},
  doi = {10.4103/jisp.jisp_195_18},
  journal = {Journal of Indian Society of Periodontology}
}

@article{labib2021,
  title = {Gender, Diversity, and the Responsible Assessment of Researchers},
  author = {Labib, Krishma and Evans, Natalie},
  year = {2021},
  month = apr,
  volume = {19},
  pages = {e3001036},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3001036},
  abstract = {In response to the Hong Kong Principles for assessing researchers, this Formal Comment argues that it is time to take gender and diversity considerations seriously in the pursuit of fostering research integrity; this requires acknowledging and reshaping the influence of research assessment criteria on researcher representation.},
  file = {/home/gabriel/Dropbox/zotero-library/Labib_Evans_2021_Gender, diversity, and the responsible assessment of researchers.pdf},
  journal = {PLOS Biology},
  keywords = {COVID 19,Peer review,Research and analysis methods,Research assessment,Research integrity,Research quality assessment,Science policy,United States},
  language = {en},
  number = {4}
}

@article{leite2011,
  title = {A New Indicator for International Visibility: Exploring {{Brazilian}} Scientific Community},
  shorttitle = {A New Indicator for International Visibility},
  author = {Leite, Paula and Mugnaini, Rog{\'e}rio and Leta, Jacqueline},
  year = {2011},
  month = apr,
  volume = {88},
  pages = {311--319},
  publisher = {{Akad\'emiai Kiad\'o, co-published with Springer Science+Business Media B.V., Formerly Kluwer Academic Publishers B.V.}},
  issn = {0138-9130, 1588-2861},
  doi = {10.1007/s11192-011-0379-9},
  abstract = {{$<$}section class="abstract"{$><$}h2 class="abstractTitle text-title my-1" id="d49e2"{$>$}Abstract{$<$}/h2{$><$}p{$>$}Brazilian science has increased fast during the last decades. An example is the increasing in the country's share in the world's scientific publication within the main international databases. But what is the actual weight of international publications to the whole Brazilian productivity? In order to respond this question, we have elaborated a new indicator, the International Publication Ratio (IPR). The data source was Lattes Database, a database organized by one of the main Brazilian S\&amp;T funding agency, which encompasses publication data from 1997 to 2004 of about 51,000 Brazilian researchers. Influences of distinct parameters, such as sectors, fields, career age and gender, are analyzed. We hope the data presented may help S\&amp;T managers and other S\&amp;T interests to better understand the complexity under the concept scientific productivity, especially in peripheral countries in science, such as Brazil.{$<$}/p{$><$}/section{$>$}},
  chapter = {Scientometrics},
  journal = {Scientometrics},
  language = {en\_US},
  number = {1}
}

@article{liao2018,
  title = {A {{Bibliometric Analysis}} and {{Visualization}} of {{Medical Big Data Research}}},
  author = {Liao, Huchang and Tang, Ming and Luo, Li and Li, Chunyang and Chiclana, Francisco and Zeng, Xiao-Jun},
  year = {2018},
  month = jan,
  volume = {10},
  pages = {166},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/su10010166},
  abstract = {With the rapid development of ``Internet plus'', medical care has entered the era of big data. However, there is little research on medical big data (MBD) from the perspectives of bibliometrics and visualization. The substantive research on the basic aspects of MBD itself is also rare. This study aims to explore the current status of medical big data through visualization analysis on the journal papers related to MBD. We analyze a total of 988 references which were downloaded from the Science Citation Index Expanded and the Social Science Citation Index databases from Web of Science and the time span was defined as ``all years''. The GraphPad Prism 5, VOSviewer and CiteSpace softwares are used for analysis. Many results concerning the annual trends, the top players in terms of journal and institute levels, the citations and H-index in terms of country level, the keywords distribution, the highly cited papers, the co-authorship status and the most influential journals and authors are presented in this paper. This study points out the development status and trends on MBD. It can help people in the medical profession to get comprehensive understanding on the state of the art of MBD. It also has reference values for the research and application of the MBD visualization methods.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/gabriel/Dropbox/zotero-library/Liao et al_2018_A Bibliometric Analysis and Visualization of Medical Big Data Research.pdf},
  journal = {Sustainability},
  keywords = {bibliometric analysis,co-authorship analysis,co-citation analysis,medical big data,visualization},
  language = {en},
  number = {1}
}

@article{lopes2012,
  title = {{A Bibliometria e a Avalia\c{c}\~ao da Produ\c{c}\~ao Cient\'ifica: indicadores e ferramentas}},
  shorttitle = {{A Bibliometria e a Avalia\c{c}\~ao da Produ\c{c}\~ao Cient\'ifica}},
  author = {Lopes, S{\'i}lvia and Costa, Maria Teresa and {Fern{\'a}ndez-Llim{\'o}s}, Fernando and Amante, Maria Jo{\~a}o and Lopes, Pedro Faria},
  year = {2012},
  month = oct,
  volume = {0},
  abstract = {A bibliometria \'e uma t\'ecnica quantitativa e estat\'istica para medir \'indices de produ\c{c}\~ao e dissemina\c{c}\~ao do conhecimento, bem como acompanhar o desenvolvimento de diversas \'areas cient\'ificas e os padr\~oes de autoria, publica\c{c}\~ao e uso dos resultados de investiga\c{c}\~ao. A avalia\c{c}\~ao da produ\c{c}\~ao cient\'ifica, importante para o reconhecimento dos investigadores junto da comunidade cient\'ifica, \'e feita atrav\'es da aplica\c{c}\~ao de diversos indicadores bibliom\'etricos, que se dividem em indicadores de qualidade, import\^ancia e impacto cient\'ificos. As limita\c{c}\~oes e controv\'ersias apontadas por v\'arios autores v\^em colocar d\'uvidas acerca da validade da aplica\c{c}\~ao dos mesmos. Como resultado das cr\'iticas levantadas sobre os principais indicadores bibliom\'etricos, nos \'ultimos anos t\^em surgido novos indicadores. Assim, numa primeira fase deste estudo, pretende-se caracterizar e comparar os principais indicadores bibliom\'etricos tendo em aten\c{c}\~ao as suas vantagens e limita\c{c}\~oes bem como campo de aplica\c{c}\~ao. Atualmente s\~ao v\'arias as bases de dados que utilizam indicadores bibliom\'etricos e disponibilizam resultados de an\'alise bibliom\'etrica, sendo a mais conhecida a Web of Science (WoS) da Thomson Reuteurs. At\'e recentemente, a WoS foi a principal ferramenta utilizada para a realiza\c{c}\~ao de an\'alise de cita\c{c}\~oes. Esta situa\c{c}\~ao, no entanto, j\'a n\~ao se verifica, uma vez se existem atualmente outras ferramentas que tamb\'em fornecem dados com base nas cita\c{c}\~oes. No presente estudo destacamos duas delas: a Scopus da Elsevier e o Google Scholar Metrics (GSM) sendo feita uma an\'alise e compara\c{c}\~ao ao n\'ivel das caracter\'isticas, vantagens e desvantagens destas tr\^es bases de dados com vista a perceber se s\~ao concorrentes ou complementares.},
  copyright = {Copyright (c)},
  file = {/home/gabriel/Dropbox/zotero-library/Lopes et al_2012_A Bibliometria e a Avaliação da Produção Científica.pdf},
  journal = {Actas do Congresso Nacional de Bibliotec\'arios, Arquivistas e Documentalistas},
  keywords = {Avaliação da produção científica,Bibliometria,Indicadores e ferramentas bibliométricos},
  language = {por},
  number = {11}
}

@article{lucas-dominguez2021,
  title = {The Sharing of Research Data Facing the {{COVID}}-19 Pandemic},
  author = {{Lucas-Dominguez}, Rut and {Alonso-Arroyo}, Adolfo and {Vidal-Infer}, Antonio and {Aleixandre-Benavent}, Rafael},
  year = {2021},
  month = apr,
  issn = {1588-2861},
  doi = {10.1007/s11192-021-03971-6},
  abstract = {During the previous Ebola and Zika outbreaks, researchers shared their data, allowing many published epidemiological studies to be produced only from open research data, to speed up investigations and control of these infections. This study aims to evaluate the dissemination of the COVID-19 research data underlying scientific publications. Analysis of COVID-19 publications from December 1, 2019, to April 30, 2020, was conducted through the PubMed Central repository to evaluate the research data available through its publication as supplementary material or deposited in repositories. The PubMed Central search generated 5,905 records, of which 804 papers included complementary research data, especially as supplementary material (77.4\%). The most productive journals were The New England Journal of Medicine, The Lancet and The Lancet Infectious Diseases, the most frequent keyword was pneumonia, and the most used repositories were GitHub and GenBank. An expected growth in the number of published articles following the course of the pandemics is confirmed in this work, while the underlying research data are only 13.6\%. It can be deduced that data sharing is not a common practice, even in health emergencies, such as the present one. High-impact generalist journals have accounted for a large share of global publishing. The topics most often covered are related to epidemiological and public health concepts, genetics, virology and respiratory diseases, such as pneumonia. However, it is essential to interpret these data with caution following the evolution of publications and their funding in the coming months.},
  file = {/home/gabriel/Dropbox/zotero-library/Lucas-Dominguez et al_2021_The sharing of research data facing the COVID-19 pandemic.pdf},
  journal = {Scientometrics},
  language = {en}
}

@article{lyu2021,
  title = {The Classification of Citing Motivations: A Meta-Synthesis},
  shorttitle = {The Classification of Citing Motivations},
  author = {Lyu, Dongqing and Ruan, Xuanmin and Xie, Juan and Cheng, Ying},
  year = {2021},
  month = apr,
  volume = {126},
  pages = {3243--3264},
  issn = {1588-2861},
  doi = {10.1007/s11192-021-03908-z},
  abstract = {Citation analysis has been a prevalent method in the field of information science, especially research on bibliometrics and evaluation, but its validity relies heavily on how the citations are treated. It is essential to study authors' citing motivations to identify citations with different values and significance. This study applied a meta-synthesis approach to establish a new holistic classification of citation motivations based on previous studies. First, we used a four-step search strategy to identify related articles on authors' citing motivations. Thirty-eight primary studies were included after the inclusion and exclusion criteria were applied and appraised using the Evidence-based Librarianship checklist. Next, we decoded and recoded the citing motivations found in the included studies, following the standard procedures of meta-synthesis. Thirty-five descriptive concepts of citation motivations emerged, which were then synthesized into 13 analytic themes. As a result, we proposed a comprehensive classification, including two main categories of citing reasons, i.e., ``scientific motivations'' and ``tactical motivations.'' Generally, the citations driven by scientific motivations serve as a rhetorical function, while tactical motivations are social or benefit-oriented and not easily captured through text-parsing. Our synthesis contributes to bibliometric and scientific evaluation theory. The synthesized classification also provides a comprehensive and unified annotation schema for citation classification and helps identify the useful mentions of a reference in a citing paper to optimize citation- based measurements.},
  file = {/home/gabriel/Dropbox/zotero-library/Lyu et al_2021_The classification of citing motivations.pdf},
  journal = {Scientometrics},
  language = {en},
  number = {4}
}

@article{machadojunior2016,
  title = {{As Leis da Bibliometria em Diferentes Bases de Dados Cient\'ificos}},
  author = {Machado Junior, Celso and de Souza, Maria Tereza Saraiva and Parisotto, Iara Regina dos Santos and Palmisano, Angelo},
  year = {2016},
  month = apr,
  pages = {111--123},
  issn = {2175-8077, 1516-3865},
  doi = {10.5007/2175-8077.2016v18n44p111},
  abstract = {O objetivo deste estudo \'e analisar a possibilidade de aplicar as Leis da Bibliometria para identificar padr\~oes nas estruturas de orienta\c{c}\~ao e de influ\^encia das Institui\c{c}\~oes de Ensino Superior na contrata\c{c}\~ao de egressos de Stricto Sensu como professores de programas. Para o atendimento do objetivo proposto, foi desenvolvido um levantamento de todas as teses e disserta\c{c}\~oes realizadas no Stricto Sensu em administra\c{c}\~ao, por um per\'iodo de quatro tri\^enios. Os dados obtidos apontam a possibilidade de aplica\c{c}\~ao de algumas das Leis da Bibliometria na an\'alise de identifica\c{c}\~ao de padr\~oes nas estruturas de produ\c{c}\~oes e arranjos acad\^emicos. Destarte, os dados mostram que os cinco pesquisadores mais prol\'ificos responderam pela orienta\c{c}\~ao de 15\% das pesquisas em sustentabilidade ambiental aproximando-se assim da Lei de Lotka. Os doutores formados pela Universidade de S\~ao Paulo e pela Funda\c{c}\~ao Get\'ulio Vargas de S\~ao Paulo se destacam na orienta\c{c}\~ao de novos pesquisadores em sustentabilidade ambiental no Stricto Sensu aproximando-se assim da Lei de Bradford.},
  file = {/home/gabriel/Zotero/storage/AGKUBHIN/Machado Junior et al. - 2016 - As Leis da Bibliometria em Diferentes Bases de Dad.pdf},
  journal = {Revista de Ci\^encias da Administra\c{c}\~ao},
  language = {pt}
}

@article{maricato2018,
  title = {The {{Potential}} for {{Altmetrics}} to {{Measure Other Types}} of {{Impact}} in {{Scientific Production}}: {{Academic}} and {{Social Impact Dynamics}} in {{Social Media}} and {{Networks}}},
  shorttitle = {The {{Potential}} for {{Altmetrics}} to {{Measure Other Types}} of {{Impact}} in {{Scientific Production}}},
  author = {Maricato, Jo{\~a}o de Melo and Vilan Filho, Jayme Leiro},
  year = {2018},
  month = mar,
  volume = {23},
  publisher = {{Thomas D}},
  issn = {1368-1613},
  abstract = {Introduction: Altmetrics is an area under construction, with a potential to study the impacts of academic products from social media data. It is believed that altmetrics can capture social and academic impacts, going beyond measures obtained using bibliometric and scientometric indicators. This research aimed to analyse aspects, characteristics and potentialities for the measuring of the social impact provided by altmetrics in social media. Method: 100 papers with higher altmetric scores were gathered from SciELO's database using the altmetric.com tool. Analysis: Profiles from individuals on Facebook and Twitter acting or reacting to the papers were analysed. These profiles were categorized as Social Impact and Academic Impact. Results: The results strongly indicate the impact measured using altmetrics greatly reproduces the scientist-to-scientist relation, as do bibliometrics and scientometrics. Conclusion: The social impact measured by actions and interactions on Facebook and Twitter reach a significant 36\%, attesting the potentiality of altmetrics for measurement, in addition to the academic impact and the impact of scientific results in society.},
  file = {/home/gabriel/Dropbox/zotero-library/Maricato_Vilan Filho_2018_The Potential for Altmetrics to Measure Other Types of Impact in Scientific.pdf},
  journal = {Information Research: An International Electronic Journal},
  keywords = {Communication (Thought Transfer),Information Dissemination,Measurement Techniques,Research Reports,Scholarship,Science and Society,Scientific Research,Social Media,Statistical Analysis},
  language = {en},
  number = {1}
}

@article{mattedi2017,
  title = {{A avalia\c{c}\~ao da produtividade cient\'ifica}},
  author = {Mattedi, Marcos Ant{\^o}nio and Spiess, Maiko Rafael},
  year = {2017},
  month = sep,
  volume = {24},
  pages = {623--643},
  issn = {0104-5970},
  doi = {10.1590/s0104-59702017000300005},
  abstract = {The paper examines the evaluation of scientific productivity. It analyzes the metrification of the evaluation of scientific production, as well as the historical construction, and current uses of scientific evaluation. It argues that this process contains a paradox: the more that metrics become impersonal, the less they are recognized by scientists. The study is divided into five sections: contextualization of the problematics of scientific evaluation; a description of the main stages in the institutionalization of metrification; an overview of the development of the main evaluation indexes; some examples of the application of these indexes; and analytical consequences and recommendations for the formulation of a new evaluation agenda.},
  file = {/home/gabriel/Dropbox/zotero-library/Mattedi_Spiess_2017_A avaliação da produtividade científica.pdf},
  journal = {Hist\'oria, Ci\^encias, Sa\'ude-Manguinhos},
  keywords = {fav,todo},
  language = {pt},
  number = {3}
}

@article{maurente2019,
  title = {{Neoliberalismo, \'etica e produtividade acad\^emica: subjetiva\c{c}\~ao e resist\^encia em programas de p\'os-gradua\c{c}\~ao brasileiros}},
  shorttitle = {{Neoliberalismo, \'etica e produtividade acad\^emica}},
  author = {Maurente, Vanessa Soares},
  year = {2019},
  month = aug,
  volume = {23},
  publisher = {{UNESP}},
  issn = {1414-3283, 1414-3283, 1807-5762},
  doi = {10.1590/Interface.180734},
  abstract = {A cultura da avalia\c{c}\~ao caracteriza-se como importante dispositivo de controle contempor\^aneo. Na educa\c{c}\~ao superior, a l\'ogica produtivista \'e apenas mais uma express\~ao da ubiquidade das pr\'aticas neoliberais, que engendram modos de subjetiva\c{c}\~ao e capturas em espa\c{c}os que deveriam resguardar possibilidades de resist\^encia. A partir da no\c{c}\~ao foucaultiana de \'etica, este artigo aborda experi\^encias de estudantes de p\'os-gradua\c{c}\~ao em rela\c{c}\~ao ao que chamamos de moral produtivista neoliberal no contexto acad\^emico. Apresentam-se fragmentos de uma pesquisa-interven\c{c}\~ao, que incluiu entrevistas semiestruturadas e oficinas de fotografia com dez estudantes de cinco programas de p\'os-gradua\c{c}\~ao de universidades brasileiras. Os resultados apontam para a sujei\c{c}\~ao a uma moral produtivista no contexto acad\^emico e para formas de questionamento e resist\^encia que se articulam nas rela\c{c}\~oes dos sujeitos consigo mesmos, deixando entrever tamb\'em o sofrimento dos p\'os-graduandos que, com altos n\'iveis de produtividade, s\~ao considerados cases de sucesso.},
  file = {/home/gabriel/Dropbox/zotero-library/Maurente_2019_Neoliberalismo, ética e produtividade acadêmica.pdf},
  journal = {Interface - Comunica\c{c}\~ao, Sa\'ude, Educa\c{c}\~ao},
  keywords = {Avaliação dda educação superior,Formação em pesquisa,Oficinas de fotografia,Produtivismo acadêmico},
  language = {pt}
}

@article{medeiros2015,
  title = {{A evolu\c{c}\~ao da bibliometria e sua interdisciplinaridade na produ\c{c}\~ao cient\'ifica brasileira}},
  author = {de Medeiros, Jos{\'e} Mauro Gouveia and Vitoriano, Maria Albeti Vieira},
  year = {2015},
  month = sep,
  volume = {13},
  pages = {491--503},
  issn = {1678-765X},
  doi = {10.20396/rdbci.v13i3.8635791},
  copyright = {Copyright (c)},
  file = {/home/gabriel/Dropbox/zotero-library/Medeiros_Vitoriano_2015_A evolução da bibliometria e sua interdisciplinaridade na produção científica.pdf},
  journal = {RDBCI: Revista Digital de Biblioteconomia e Ci\^encia da Informa\c{c}\~ao},
  keywords = {Bibliometria.  Comunicação científica brasileira. Interdisciplinaridade,todo},
  language = {pt},
  number = {3}
}

@article{meho2007,
  title = {The Rise and Rise of Citation Analysis},
  author = {Meho, Lokman I.},
  year = {2007},
  month = jan,
  volume = {20},
  pages = {32--36},
  publisher = {{IOP Publishing}},
  issn = {2058-7058},
  doi = {10.1088/2058-7058/20/1/33},
  abstract = {It is a sobering fact that some 90\% of papers that have been published in academic journals are never cited. Indeed, as many as 50\% of papers are never read by anyone other than their authors, referees and journal editors. We know this thanks to citation analysis, a branch of information science in which researchers study the way articles in a scholarly field are accessed and referenced by others.},
  file = {/home/gabriel/Dropbox/zotero-library/Meho_2007_The rise and rise of citation analysis.pdf},
  journal = {Physics World},
  language = {en},
  number = {1}
}

@article{merigo2017,
  title = {A Bibliometric Analysis of Operations Research and Management Science},
  author = {Merig{\'o}, Jos{\'e} M. and Yang, Jian-Bo},
  year = {2017},
  month = dec,
  volume = {73},
  pages = {37--48},
  issn = {03050483},
  doi = {10.1016/j.omega.2016.12.004},
  abstract = {Bibliometric analysis is the quantitative study of bibliographic material. It provides a general picture of a research field that can be classified by papers, authors and journals. This paper presents a bibliometric overview of research published in operations research and management science in recent decades. The main objective of this study is to identify some of the most relevant research in this field and some of the newest trends according to the information found in the Web of Science database. Several classifications are made, including an analysis of the most influential journals, the two hundred most cited papers of all time and the most productive and influential authors. The results obtained are in accordance with the common wisdom, although some variations are found.},
  file = {/home/gabriel/Dropbox/zotero-library/Merigó_Yang_2017_A bibliometric analysis of operations research and management science.pdf},
  journal = {Omega},
  language = {en}
}

@article{mingers2015,
  title = {A Review of Theory and Practice in Scientometrics},
  author = {Mingers, John and Leydesdorff, Loet},
  year = {2015},
  month = oct,
  volume = {246},
  pages = {1--19},
  issn = {0377-2217},
  doi = {10.1016/j.ejor.2015.04.002},
  abstract = {Scientometrics is the study of the quantitative aspects of the process of science as a communication system. It is centrally, but not only, concerned with the analysis of citations in the academic literature. In recent years it has come to play a major role in the measurement and evaluation of research performance. In this review we consider: the historical development of scientometrics, sources of citation data, citation metrics and the ``laws'' of scientometrics, normalisation, journal impact factors and other journal metrics, visualising and mapping science, evaluation and policy, and future developments.},
  file = {/home/gabriel/Dropbox/zotero-library/Mingers_Leydesdorff_2015_A review of theory and practice in scientometrics.pdf},
  journal = {European Journal of Operational Research},
  keywords = {Altmetrics,Citations,fav,H-index,Impact factor,Normalisation,top5},
  language = {en},
  number = {1}
}

@article{moed2002,
  title = {The Impact-Factors Debate: The {{ISI}}'s Uses and Limits},
  shorttitle = {The Impact-Factors Debate},
  author = {Moed, Henk F.},
  year = {2002},
  month = feb,
  volume = {415},
  pages = {731--732},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/415731a},
  file = {/home/gabriel/Dropbox/zotero-library/Moed_2002_The impact-factors debate.pdf},
  journal = {Nature},
  keywords = {todo},
  language = {en},
  number = {6873}
}

@book{moed2006,
  title = {Citation {{Analysis}} in {{Research Evaluation}}},
  author = {Moed, Henk F.},
  year = {2006},
  month = mar,
  publisher = {{Springer Science \& Business Media}},
  abstract = {This book is written for members of the scholarly research community, and for persons involved in research evaluation and research policy. More specifically, it is directed towards the following four main groups of readers: \textendash{} All scientists and scholars who have been or will be subjected to a quantitative assessment of research performance using citation analysis. \textendash{} Research policy makers and managers who wish to become conversant with the basic features of citation analysis, and about its potentialities and limitations. \textendash{} Members of peer review committees and other evaluators, who consider the use of citation analysis as a tool in their assessments. \textendash{} Practitioners and students in the field of quantitative science and technology studies, informetrics, and library and information science. Citation analysis involves the construction and application of a series of indicators of the `impact', `influence' or `quality' of scholarly work, derived from citation data, i.e. data on references cited in footnotes or bibliographies of scholarly research publications. Such indicators are applied both in the study of scholarly communication and in the assessment of research performance. The term `scholarly' comprises all domains of science and scholarship, including not only those fields that are normally denoted as science \textendash{} the natural and life sciences, mathematical and technical sciences \textendash{} but also social sciences and humanities.},
  file = {/home/gabriel/Dropbox/zotero-library/Moed_2006_Citation Analysis in Research Evaluation.pdf},
  googlebooks = {D9SaJ6awy4gC},
  isbn = {978-1-4020-3714-6},
  keywords = {Business \& Economics / Economics / General,Business \& Economics / General,Computers / Computer Science,Language Arts \& Disciplines / Library \& Information Science / General,Philosophy / General,Science / General,Social Science / General,Social Science / Research,Social Science / Statistics},
  language = {en}
}

@article{moed2007,
  title = {The Future of Research Evaluation Rests with an Intelligent Combination of Advanced Metrics and Transparent Peer Review},
  author = {Moed, Henk F},
  year = {2007},
  month = oct,
  volume = {34},
  pages = {575--583},
  issn = {0302-3427},
  doi = {10.3152/030234207X255179},
  abstract = {The paper discusses the strengths and limitations of `metrics' and peer review in large-scale evaluations of scholarly research performance. A real challenge is to combine the two methodologies in such a way that the strength of the first compensates for the limitations of the second, and vice versa. It underlines the need to systematically take into account the unintended effects of the use of metrics. It proposes a set of general criteria for the proper use of bibliometric indicators within peer-review processes, and applies these to a particular case: the UK Research Assessment Exercise (RAE).},
  file = {/home/gabriel/Dropbox/zotero-library/Moed_2007_The future of research evaluation rests with an intelligent combination of.pdf},
  journal = {Science and Public Policy},
  keywords = {fav},
  number = {8}
}

@article{moed2009,
  title = {New Developments in the Use of Citation Analysis in Research Evaluation},
  author = {Moed, Henk F.},
  year = {2009},
  month = feb,
  volume = {57},
  pages = {13},
  issn = {1661-4917},
  doi = {10.1007/s00005-009-0001-5},
  abstract = {This paper presents an overview of research assessment methodologies developed in the field of evaluative bibliometrics, a subfield of quantitative science and technology studies, aimed to construct indicators of research performance from a quantitative statistical analysis of scientific-scholarly documents. Citation analysis is one of its key methodologies. The paper illustrates the potentialities and limitations of the use of bibliometric indicators in research assessment. It discusses the relationship between metrics and peer review; databases used as sources of bibliometric analysis; the pros and cons of indicators often applied, including journal impact factors, Hirsch indices, and normalized indicators of citation impact; and approaches to the bibliometric measurement of institutional research performance.},
  file = {/home/gabriel/Dropbox/zotero-library/Moed_2009_New developments in the use of citation analysis in research evaluation.pdf},
  journal = {Archivum Immunologiae et Therapiae Experimentalis},
  language = {en},
  number = {1}
}

@book{moed2017,
  title = {Applied {{Evaluative Informetrics}}},
  author = {Moed, Henk F.},
  year = {2017},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-60522-7},
  file = {/home/gabriel/Dropbox/zotero-library/Moed_2017_Applied Evaluative Informetrics.pdf},
  isbn = {978-3-319-60521-0 978-3-319-60522-7},
  series = {Qualitative and {{Quantitative Analysis}} of {{Scientific}} and {{Scholarly Communication}}}
}

@article{moher2018,
  title = {Assessing Scientists for Hiring, Promotion, and Tenure},
  author = {Moher, David and Naudet, Florian and Cristea, Ioana A. and Miedema, Frank and Ioannidis, John P. A. and Goodman, Steven N.},
  year = {2018},
  month = mar,
  volume = {16},
  pages = {e2004089},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.2004089},
  abstract = {Assessment of researchers is necessary for decisions of hiring, promotion, and tenure. A burgeoning number of scientific leaders believe the current system of faculty incentives and rewards is misaligned with the needs of society and disconnected from the evidence about the causes of the reproducibility crisis and suboptimal quality of the scientific publication record. To address this issue, particularly for the clinical and life sciences, we convened a 22-member expert panel workshop in Washington, DC, in January 2017. Twenty-two academic leaders, funders, and scientists participated in the meeting. As background for the meeting, we completed a selective literature review of 22 key documents critiquing the current incentive system. From each document, we extracted how the authors perceived the problems of assessing science and scientists, the unintended consequences of maintaining the status quo for assessing scientists, and details of their proposed solutions. The resulting table was used as a seed for participant discussion. This resulted in six principles for assessing scientists and associated research and policy implications. We hope the content of this paper will serve as a basis for establishing best practices and redesigning the current approaches to assessing scientists by the many players involved in that process.},
  file = {/home/gabriel/Dropbox/zotero-library/Moher et al_2018_Assessing scientists for hiring, promotion, and tenure.pdf},
  journal = {PLOS Biology},
  keywords = {Bibliometrics,Citation analysis,Research assessment,Research design,Research quality assessment,Science policy,Scientific publishing,Scientists},
  language = {en},
  number = {3}
}

@article{moher2020,
  title = {The {{Hong Kong Principles}} for Assessing Researchers: {{Fostering}} Research Integrity},
  shorttitle = {The {{Hong Kong Principles}} for Assessing Researchers},
  author = {Moher, David and Bouter, Lex and Kleinert, Sabine and Glasziou, Paul and Sham, Mai Har and Barbour, Virginia and Coriat, Anne-Marie and Foeger, Nicole and Dirnagl, Ulrich},
  year = {2020},
  month = jul,
  volume = {18},
  pages = {e3000737},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3000737},
  abstract = {For knowledge to benefit research and society, it must be trustworthy. Trustworthy research is robust, rigorous, and transparent at all stages of design, execution, and reporting. Assessment of researchers still rarely includes considerations related to trustworthiness, rigor, and transparency. We have developed the Hong Kong Principles (HKPs) as part of the 6th World Conference on Research Integrity with a specific focus on the need to drive research improvement through ensuring that researchers are explicitly recognized and rewarded for behaviors that strengthen research integrity. We present five principles: responsible research practices; transparent reporting; open science (open research); valuing a diversity of types of research; and recognizing all contributions to research and scholarly activity. For each principle, we provide a rationale for its inclusion and provide examples where these principles are already being adopted.},
  file = {/home/gabriel/Dropbox/zotero-library/Moher et al_2020_The Hong Kong Principles for assessing researchers.pdf},
  journal = {PLOS Biology},
  keywords = {fav,todo},
  language = {en},
  number = {7}
}

@article{momeni2021,
  title = {What Happens When a Journal Converts to Open Access? {{A}} Bibliometric Analysis},
  shorttitle = {What Happens When a Journal Converts to Open Access?},
  author = {Momeni, Fakhri and Mayr, Philipp and Fraser, Nicholas and Peters, Isabella},
  year = {2021},
  month = apr,
  issn = {1588-2861},
  doi = {10.1007/s11192-021-03972-5},
  abstract = {In recent years, increased stakeholder pressure to transition research to Open Access has led to many journals converting, or `flipping', from a closed access (CA) to an open access (OA) publishing model. Changing the publishing model can influence the decision of authors to submit their papers to a journal, and increased article accessibility may influence citation behaviour. In this paper we aimed to understand how flipping a journal to an OA model influences the journal's future publication volumes and citation impact. We analysed two independent sets of journals that had flipped to an OA model, one from the Directory of Open Access Journals (DOAJ) and one from the Open Access Directory (OAD), and compared their development with two respective control groups of similar journals. For bibliometric analyses, journals were matched to the Scopus database. We assessed changes in the number of articles published over time, as well as two citation metrics at the journal and article level: the normalised impact factor (IF) and the average relative citations (ARC), respectively. Our results show that overall, journals that flipped to an OA model increased their publication output compared to journals that remained closed. Mean normalised IF and ARC also generally increased following the flip to an OA model, at a greater rate than was observed in the control groups. However, the changes appear to vary largely by scientific discipline. Overall, these results indicate that flipping to an OA publishing model can bring positive changes to a journal.},
  file = {/home/gabriel/Dropbox/zotero-library/Momeni et al_2021_What happens when a journal converts to open access.pdf},
  journal = {Scientometrics},
  language = {en}
}

@article{moraes2017,
  title = {{Produ\c{c}\~ao acad\^emica em avalia\c{c}\~ao do ensino superior no Brasil1}},
  author = {Moraes, M{\'a}rio Cesar Barreto and Amboni, N{\'e}rio and Kalnin, Guilherme Felipe},
  year = {2017-Sep-Dec},
  volume = {22},
  pages = {697--717},
  publisher = {{Publica\c{c}\~ao da Rede de Avalia\c{c}\~ao Institucional da Educa\c{c}\~ao Superior (RAIES), da Universidade Estadual de Campinas (UNICAMP) e da Universidade de Sorocaba (UNISO).}},
  issn = {1414-4077, 1414-4077, 1982-5765},
  doi = {10.1590/S1414-40772017000300007},
  abstract = {A avalia\c{c}\~ao do ensino superior no Brasil se mostra recorrente nas pesquisas na \'area de Educa\c{c}\~ao, sendo diversos os pesquisadores que a buscam compreender, pelo impacto que esta possui quanto as reformas educacionais. O objetivo geral da presente pesquisa consiste em investigar a distribui\c{c}\~ao da produ\c{c}\~ao acad\^emica relacionada ao tema ``Avalia\c{c}\~ao do Ensino Superior no Brasil'', no que tange caracter\'isticas como: autoria, v\'inculos institucionais, regionalidade, fator de impacto, palavras-chave e metodologias. Trata-se de um estudo quantitativo, caracterizado como pesquisa explorat\'oria e descritiva que se utiliza da bibliometria. Analisou-se 222 artigos publicados em doze peri\'odicos nacionais de Qualis A1 e A2 no quesito Educa\c{c}\~ao. Os resultados mostraram uma diminui\c{c}\~ao da produ\c{c}\~ao nos \'ultimos anos acerca do tema, o que evidencia que a produ\c{c}\~ao acompanha as mudan\c{c}as pol\'iticas e sociais do pa\'is. De forma mais pontual, verificou-se uma tend\^encia maior a coautorias, uma predomin\^ancia de trabalhos te\'oricos e uma alta concentra\c{c}\~ao de fator de impacto em poucos autores.},
  file = {/home/gabriel/Dropbox/zotero-library/Moraes et al_2017_Produção acadêmica em avaliação do ensino superior no Brasil1.pdf},
  journal = {Avalia\c{c}\~ao: Revista da Avalia\c{c}\~ao da Educa\c{c}\~ao Superior (Campinas)},
  keywords = {Avaliação do ensino superior,Avaliação institucional,Bibliometria,Educação. Ensino,Produção científica},
  language = {pt}
}

@article{moura2017,
  title = {Uses of {{Bibliometric Techniques}} in {{Public Health Research}}},
  author = {MOURA, Luana Kelle Batista and {de MESQUITA}, Rafael Fernandes and MOBIN, Mitra and MATOS, Francisca Tereza Coelho and MONTE, Thiago Lima and LAGO, Eliana Campelo and FALC{\~A}O, Carlos Alberto Monteiro and {de Ar{\^e}a Le{\~a}o FERRAZ}, Maria {\^A}ngela and SANTOS, Tanit Clementino and SOUSA, Laelson Rochelle Milan{\^e}s},
  year = {2017},
  month = oct,
  volume = {46},
  pages = {1435--1436},
  issn = {2251-6085},
  file = {/home/gabriel/Dropbox/zotero-library/MOURA et al_2017_Uses of Bibliometric Techniques in Public Health Research.pdf},
  journal = {Iranian Journal of Public Health},
  number = {10},
  pmcid = {PMC5750357},
  pmid = {29308389}
}

@article{mugnaini2004,
  title = {{Indicadores bibliom\'etricos da produ\c{c}\~ao cient\'ifica brasileira: uma an\'alise a partir da base Pascal}},
  shorttitle = {{Indicadores bibliom\'etricos da produ\c{c}\~ao cient\'ifica brasileira}},
  author = {Mugnaini, Rog{\'e}rio and Jannuzzi, Paulo de Martino and Quoniam, Luc},
  year = {2004},
  month = aug,
  volume = {33},
  pages = {123--131},
  publisher = {{Instituto Brasileiro de Informa\c{c}\~ao em{$<$}br{$>$}Ci\^encia e Tecnologia - IBICT}},
  issn = {0100-1965},
  doi = {10.1590/S0100-19652004000200013},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini et al_2004_Indicadores bibliométricos da produção científica brasileira.pdf},
  journal = {Ci\^encia da Informa\c{c}\~ao},
  language = {pt},
  number = {2}
}

@phdthesis{mugnaini2006,
  title = {{Caminhos para adequa\c{c}\~ao da avalia\c{c}\~ao da produ\c{c}\~ao cient\'ifica brasileira: impacto nacional versus internacional}},
  shorttitle = {{Caminhos para adequa\c{c}\~ao da avalia\c{c}\~ao da produ\c{c}\~ao cient\'ifica brasileira}},
  author = {Mugnaini, Rog{\'e}rio},
  year = {2006},
  month = nov,
  doi = {10.11606/T.27.2006.tde-11052007-091052},
  abstract = {Diversos indicadores bibliom\'etricos t\^em sido empregados na avalia\c{c}\~ao de desempenho de pesquisadores, universidades e pa\'ises. Indicadores de impacto, calculados a partir das cita\c{c}\~oes recebidas pelos artigos, t\^em sido objeto de muitos estudos constantes da pesquisa document\'aria. Dessa maneira, almeja-se apontar poss\'iveis formas de adequa\c{c}\~ao da an\'alise do impacto de revistas brasileiras com vistas ao aprimoramento dos crit\'erios de avalia\c{c}\~ao de produ\c{c}\~ao cient\'ifica no Brasil. Objetivos. A pesquisa foi conduzida de acordo com tr\^es objetivos: (1) Verificar se o uso exclusivo de indicadores internacionais deixa a pol\'itica cient\'ifica brasileira fora do contexto de sua realidade local, e se o acesso \`as revistas indexadas nas bases do ISI (Thomson Scientific) tem se justificado pelo uso ? o acesso gratuito aos textos completos \'e oferecido \`a comunidade cient\'ifica pela Capes (Coordena\c{c}\~ao de Aperfei\c{c}oamento de Pessoal de N\'ivel Superior). (2) Investigar se a base SciELO pode oferecer indicadores de impacto da produ\c{c}\~ao cient\'ifica brasileira com vistas ao aprimoramento da avalia\c{c}\~ao cient\'ifica nacional. (3) Buscar propor metodologias de indicadores mais adequadas \`a realidade da ci\^encia brasileira. Metodologia. Foi conduzido um estudo explorat\'orio quantitativo, baseados em caracter\'isticas qualitativas e quantitativas de revistas cient\'ificas provenientes de tr\^es fontes: revistas classificadas pela Avalia\c{c}\~ao Qualis (tri\^enio 2001/2003), revistas do Portal de Peri\'odicos da Capes e revistas indexadas na base SciELO (Scientific Electronic Library). Uma compara\c{c}\~ao do impacto nacional e internacional de um conjunto de revistas brasileiras indexadas na base SciELO foi realizada a partir das cita\c{c}\~oes recebidas pelas revistas em cada contexto (base SciELO e as bases do ISI). Uma metodologia de an\'alise de revistas foi apresentada aplicando-se t\'ecnicas de an\'alise estat\'istica multivariada a um conjunto de 42 indicadores. Resultados. A an\'alise da Avalia\c{c}\~ao Qualis mostrou que os crit\'erios definidos favorecem principalmente a publica\c{c}\~ao em revistas internacionais e fazem uso do Fator de Impacto do ISI. O Impacto P\'os-Portal, como foi denominado, indicou um efeito positivo, notado pelo aumento da m\'edia de cita\c{c}\~oes recebidas na SciELO, por aproximadamente 70\% das revistas da amostra (Ci\^encias da Vida), ap\'os o ano de publica\c{c}\~ao no Portal. A compara\c{c}\~ao do impacto nacional versus internacional das revistas SciELO mostrou que revistas indexadas tamb\'em no ISI s\~ao citadas com mais freq\"u\^encia naquela base, al\'em de receberem aproximadamente 72\% das cita\c{c}\~oes de revistas ISI de autores estrangeiros e terem os artigos em colabora\c{c}\~ao (nacional e internacional) mais citados que aqueles em autoria \'unica. Em rela\c{c}\~ao \`as revistas publicadas somente na SciELO, verificou-se que s\~ao citadas em quantidades similares naquela base e nas bases do ISI, recebem 68\% das cita\c{c}\~oes de revistas ISI de autores estrangeiros e t\^em seus artigos de autoria \'unica mais citados, seguidos daqueles em colabora\c{c}\~ao nacional. A an\'alise multivariada dos indicadores das revistas SciELO permitiu a identifica\c{c}\~ao de diferentes grupos de revistas, discriminados de acordo com as diferentes pr\'aticas de comunica\c{c}\~ao cient\'ifica. Conclus\~oes. A adequa\c{c}\~ao dos crit\'erios utilizados na avalia\c{c}\~ao da produ\c{c}\~ao cient\'ifica nacional pode ser conseguida considerando-se indicadores de impacto mensurados a partir de cita\c{c}\~oes provenientes das revistas nacionais, definindo crit\'erios que valorizem a publica\c{c}\~ao em revistas nacionais de qualidade reconhecida, o que permitir\'a a publica\c{c}\~ao de trabalhos importantes na l\'ingua portuguesa, e estimular\'a o processo de melhoria de qualidade das revistas nacionais.},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini_2006_Caminhos para adequação da avaliação da produção científica brasileira.pdf},
  language = {pt-br},
  school = {Universidade de S\~ao Paulo},
  type = {{text}}
}

@article{mugnaini2010,
  title = {Multidisciplinaridade e Especificidade Na Comunica\c{c}\~ao Cient\'ifica: Discuss\~ao Do Impacto Na Avalia\c{c}\~ao de Diferentes \'Areas},
  shorttitle = {Multidisciplinaridade e Especificidade Na Comunica\c{c}\~ao Cient\'ifica},
  author = {Mugnaini, Rog{\'e}rio and Poblaci{\'o}n, Dinah Apparecida de Melo Aguiar},
  year = {2010},
  volume = {4},
  issn = {1981-6278},
  doi = {10.3395/reciis.v4i5.533},
  abstract = {As refer\^encias bibliogr\'aficas podem revelar o perfil da ci\^encia publicada, oferecendo importantes informa\c{c}\~oes sobre a hist\'oria de uma revista. Ao identificar o impacto dos diferentes tipos de documentos citados por cinco revistas cient\'ificas de \'areas diversas, constatou-se que o livro \'e consideravelmente mais citado numa revista de Ci\^encias Sociais Aplicadas, enquanto a \'area de Sa\'ude Coletiva faz uso deste tipo de documento em propor\c{c}\~oes equipar\'aveis com os artigos cient\'ificos. Nas revistas de F\'isica e Medicina as cita\c{c}\~oes a revistas internacionais s\~ao muito mais prevalentes. E na revista de Veterin\'aria e de Ci\^encia da Informa\c{c}\~ao, destacam-se os anais e teses. Estas constata\c{c}\~oes s\~ao importantes para entender as culturas de comunica\c{c}\~ao cient\'ifica das \'areas, o que p\^ode ser observado tamb\'em ao analisar, tanto as classifica\c{c}\~oes das revistas no Qualis, quanto os crit\'erios constantes dos documentos de \'area. Indicadores bibliom\'etricos n\~ao restritos a um \'indice s\~ao capazes de oferecer par\^ametros para cooperar na defini\c{c}\~ao de crit\'erios para avalia\c{c}\~ao da produ\c{c}\~ao cient\'ifica brasileira, segundo as caracter\'isticas das diferentes \'areas do conhecimento.},
  copyright = {Direitos autorais},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini_Población_2010_Multidisciplinaridade e especificidade na comunicação científica.pdf},
  journal = {Revista Eletr\^onica de Comunica\c{c}\~ao, Informa\c{c}\~ao e Inova\c{c}\~ao em Sa\'ude},
  keywords = {Assessment,Avaliação,Bases de dados,Bibliometric indicators,Citação.,Citation,Comunicação científica,Database,Indicadores bibliométricos,Scientific publication},
  language = {en},
  number = {5}
}

@incollection{mugnaini2013,
  title = {40 Anos de {{Bibliometria}} No {{Brasil}}: Da Bibliografia Estat\'istica \`a Avalia\c{c}\~ao Da Produ\c{c}\~ao Cient\'ifica Nacional},
  shorttitle = {40 Anos de {{Bibliometria}} No {{Brasil}}},
  author = {Mugnaini, Rogerio},
  year = {2013},
  month = jan,
  pages = {37--58},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini_2013_40 anos de Bibliometria no Brasil.pdf},
  isbn = {978-85-7993-117-8},
  keywords = {done}
}

@article{mugnaini2014,
  title = {{Comunica\c{c}\~ao cient\'ifica no Brasil (1998-2012): indexa\c{c}\~ao, crescimento, fluxo e dispers\~ao}},
  shorttitle = {{Comunica\c{c}\~ao cient\'ifica no Brasil (1998-2012)}},
  author = {Mugnaini, Rog{\'e}rio and Digiampetri, Luciano Antonio and {Mena-Chalco}, Jes{\'u}s Pascual and Mugnaini, Rog{\'e}rio and Digiampetri, Luciano Antonio and {Mena-Chalco}, Jes{\'u}s Pascual},
  year = {2014},
  month = dec,
  volume = {26},
  pages = {239--252},
  publisher = {{Pontif\'icia Universidade Cat\'olica de Campinas}},
  issn = {0103-3786},
  doi = {10.1590/0103-3786201400030002},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini et al_2014_Comunicação científica no Brasil (1998-2012).pdf},
  journal = {Transinforma\c{c}\~ao},
  keywords = {done},
  language = {pt},
  number = {3}
}

@article{mugnaini2017,
  title = {{Ciclo avaliativo de peri\'odicos no Brasil: caminho virtuoso ou colcha de retalhos?}},
  shorttitle = {{Ciclo avaliativo de peri\'odicos no Brasil}},
  author = {Mugnaini, Rogerio},
  year = {2017},
  month = mar,
  abstract = {This study investigated factors influencing the scholarly communication process, from the analysis of the quality criteria proposed between thematic areas in the exercise of evaluation ofscientific production in Brazil. Therefore, provided an overview based on the types of assessment criteria adopted in the Qualis-Peri\'odicos for the definition of strata A1, A2 and B1, from the documents of 2010-2012 period. It found that most hard sciences areas presents evaluation profile strictly based on bibliometric indicators, mainly JCR impact factor and in some cases, the h-index. Humanities, Social and Language, Literature and Arts areas, serve themselves believing at the selection process carried out by the databases, especially the citation indexes (Web of Science, Scopus and SciELO), and also in other databases as RedALyC and Latindex when defining criteria of journal indexing. Finally, periodic characteristics are primarily institutional diversity of authors and authors from foreign institutions, followed by journal periodicity and diversity of the editorial board. Thus configures itself an evaluation cycle, whose result appears to contribute to the improvement of the journals. On the other hand, although mounted, the process needs review, so that one can assess their effects on the scientific communication process.},
  annotation = {Accepted: 2017-03-06T20:28:32Z},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini_2017_Ciclo avaliativo de periódicos no Brasil.pdf},
  keywords = {todo,top5},
  language = {pt\_BR}
}

@book{mugnaini2017a,
  title = {Bibliometria e Cientometria No {{Brasil}}: Infraestrutura Para Avalia\c{c}\~ao Da Pesquisa Cient\'ifica Na Era Do {{Big Data}} / {{Bibliometrics}} and Scientometrics in {{Brazil}}: Scientific Research Assessment Infrastructure in the Era of {{Big Data}}},
  shorttitle = {Bibliometria e Cientometria No {{Brasil}}},
  author = {Mugnaini, Rogerio and Fujino, Asa and Kobashi, Nair},
  year = {2017},
  month = mar,
  doi = {10.11606/9788572051705},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini et al_2017_Bibliometria e cientometria no Brasil.pdf},
  isbn = {978-85-7205-170-5},
  keywords = {fav,top5}
}

@article{mugnaini2019,
  title = {{Panorama da produ\c{c}\~ao cient\'ifi ca do Brasil al\'em da indexa\c{c}\~ao: uma an\'alise explorat\'oria da comunica\c{c}\~ao em peri\'odicos}},
  shorttitle = {{Panorama da produ\c{c}\~ao cient\'ifi ca do Brasil al\'em da indexa\c{c}\~ao}},
  author = {Mugnaini, Rog{\'e}rio and Damaceno, Rafael Jeferson Pezzuto and Digiampietri, Luciano Antonio and {Mena-Chalco}, Jes{\'u}s Pascual},
  year = {2019},
  month = nov,
  volume = {31},
  publisher = {{Pontif\'icia Universidade Cat\'olica de Campinas}},
  issn = {0103-3786, 0103-3786, 2318-0889},
  doi = {10.1590/2318-0889201931e190033},
  abstract = {Resumo Indicadores de produ\c{c}\~ao cient\'ifica s\~ao usualmente utilizados para a avalia\c{c}\~ao da comunidade acad\^emica. Como par\^ametro de qualidade, as bases de dados bibliogr\'aficas s\~ao empregadas para a sele\c{c}\~ao dos peri\'odicos mais importantes, o que as confere um papel significativo no processo avaliativo. Por outro lado, ao se restringir as an\'alises \`a produ\c{c}\~ao indexada, abre-se m\~ao do todo, correndo-se o risco de desqualificar a produ\c{c}\~ao em peri\'odicos n\~ao indexados. O Qualis busca contornar esse problema, ao possibilitar que as \'areas valorizem os peri\'odicos n\~ao indexados, mas nem sempre consideram o volume de artigos publicados neles. Este trabalho apresenta uma an\'alise explorat\'oria da dispers\~ao da produ\c{c}\~ao cient\'ifica dos 260.663 pesquisadores, no n\'ivel de doutorado, registrados na Plataforma Lattes. Para a determina\c{c}\~ao do panorama nacional, foram considerados todos os artigos completos publicados em peri\'odicos por esses pesquisadores entre os anos de 1998 e 2016. Esse panorama contempla an\'alises discriminadas por grande \'area de atua\c{c}\~ao dos pesquisadores, o pa\'is de publica\c{c}\~ao e a indexa\c{c}\~ao das publica\c{c}\~oes nos diferentes peri\'odicos. Observaram-se tend\^encias de internacionaliza\c{c}\~ao, assim como a import\^ancia de peri\'odicos nacionais como ve\'iculos de publica\c{c}\~ao de parte significativa da produ\c{c}\~ao cient\'ifica de algumas \'areas. Finalmente, ficou evidenciada a potencial limita\c{c}\~ao de estudos que n\~ao considerem a produ\c{c}\~ao cient\'ifica em peri\'odicos n\~ao indexados, ou estudos restritos \`as bases Scopus e/ou Web of Science, ignorando a Scientific Electronic Library Online.},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini et al_2019_Panorama da produção científi ca do Brasil além da indexação.pdf},
  journal = {Transinforma\c{c}\~ao},
  keywords = {Bases bibliográfi cas,Bibliometria,Periódicos científi cos,Produção,todo},
  language = {pt}
}

@article{mugnaini2021,
  title = {Openness Trends in {{Brazilian}} Citation Data: Factors Related to the Use of {{DOIs}}},
  shorttitle = {Openness Trends in {{Brazilian}} Citation Data},
  author = {Mugnaini, Rog{\'e}rio and Fraumann, Grischa and Tuesta, Esteban F. and Packer, Abel L.},
  year = {2021},
  month = mar,
  volume = {126},
  pages = {2523--2556},
  issn = {1588-2861},
  doi = {10.1007/s11192-020-03663-7},
  abstract = {Digital object identifiers (DOIs) are important metadata elements for indexing and interoperability, as well as for bibliometric studies in times of openness. This study analyses the use of DOIs in the cited references of articles by authors from Brazilian institutions, their possible influencing factors and differences among areas of knowledge. It measures the extent to which the citation datasets are open for reuse by others in terms of the availability of DOIs. 226,491 articles were retrieved from Web of Science (2012\textendash 2016), making a total of 8,707,120 cited references, 68\% of which include DOIs. The results showed that the hard sciences have higher percentages of DOIs in their cited references. The factor type of collaboration showed higher percentages when there is international collaboration, being significantly different from the other categories. However, when the analysis was conducted inside the areas, the international collaboration was found to be different particularly in the soft sciences and a couple of other areas. The articles with DOI attributed, as well as those with mention of research funding, had a significantly higher percentage, even in the interaction with the areas of knowledge. Among the open access routes the green routes showed the highest percentages, followed by golden (DOAJ and other) and Bronze, but green routes articles proved to be not significantly different from those not openly accessible. Finally, the principal collaborating countries also showed the greatest influence on the DOI attribution, with the exception of Peru and South Africa. Our findings provide evidence that studies on the availability and usability of DOIs can assist researchers, by underlining the importance of making greater use of this persistent identifier, as well as to provide consistency to citation analysis.},
  file = {/home/gabriel/Dropbox/zotero-library/Mugnaini et al_2021_Openness trends in Brazilian citation data.pdf},
  journal = {Scientometrics},
  language = {en},
  number = {3}
}

@article{muller2017,
  title = {Thinking with Indicators. {{Exploring}} the Epistemic Impacts of Academic Performance Indicators in the Life Sciences},
  author = {M{\"u}ller, Ruth and {de Rijcke}, Sarah},
  year = {2017},
  month = jul,
  volume = {26},
  pages = {157--168},
  issn = {0958-2029},
  doi = {10.1093/reseval/rvx023},
  abstract = {While quantitative performance indicators are widely used by organizations and individuals for evaluative purposes, little is known about their impacts on the epistemic processes of academic knowledge production. In this article we bring together three qualitative research projects undertaken in the Netherlands and Austria to contribute to filling this gap. The projects explored the role of performance metrics in the life sciences, and the interactions between institutional and disciplinary cultures of evaluating research in these fields. Our analytic perspective is focused on understanding how researchers themselves give value to research, and in how far these practices are related to performance metrics. The article zooms in on three key moments in research processes to show how `thinking with indicators' is becoming a central aspect of research activities themselves: (1) the planning and conception of research projects, (2) the social organization of research processes, and (3) determining the endpoints of research processes. Our findings demonstrate how the worth of research activities becomes increasingly assessed and defined by their potential to yield high value in quantitative terms. The analysis makes visible how certain norms and values related to performance metrics are stabilized as they become integrated into routine practices of knowledge production. Other norms and criteria for scientific quality, e.g. epistemic originality, long-term scientific progress, societal relevance, and social responsibility, receive less attention or become redefined through their relations to quantitative indicators. We understand this trend to be in tension with policy goals that seek to encourage innovative, societally relevant, and responsible research.},
  journal = {Research Evaluation},
  number = {3}
}

@article{oh2009,
  title = {Is the Journal Impact Factor a Valid Indicator of Scientific Value?},
  author = {Oh, H. C. and Lim, J. F.},
  year = {2009},
  month = aug,
  volume = {50},
  pages = {749--751},
  issn = {0037-5675},
  file = {/home/gabriel/Dropbox/zotero-library/Oh_Lim_2009_Is the journal impact factor a valid indicator of scientific value.pdf},
  journal = {Singapore Medical Journal},
  keywords = {Bibliometrics,Biomedical Research,Databases; Bibliographic,Journal Impact Factor,Periodicals as Topic,Publishing,todo},
  language = {eng},
  number = {8},
  pmid = {19710968}
}

@article{oliveira2015,
  title = {{A epidemia de m\'as condutas na ci\^encia: o fracasso do tratamento moralizador}},
  shorttitle = {{A epidemia de m\'as condutas na ci\^encia}},
  author = {Oliveira, Marcos BARBOSA DE},
  year = {2015-Oct-Dec},
  volume = {13},
  pages = {867--897},
  publisher = {{Universidade de S\~ao Paulo, Departamento de Filosofia}},
  issn = {1678-3166, 1678-3166, 2316-8994},
  doi = {10.1590/S1678-31662015000400007},
  abstract = {RESUMO O tema do artigo \'e a prolifera\c{c}\~ao de m\'as condutas na ci\^encia que vem ocorrendo nas \'ultimas d\'ecadas, designada ao longo do texto pelo termo "a epidemia". As m\'as condutas s\~ao viola\c{c}\~oes de normas \'eticas da ci\^encia, sendo os tipos mais importantes as v\'arias modalidades de fraude (principalmente a fabrica\c{c}\~ao e a falsifica\c{c}\~ao de dados emp\'iricos), e de falsidades autorais (pl\'agio, autopl\'agio etc.). O artigo divide-se em seis se\c{c}\~oes. Na primeira, apresenta-se o tema e alguns esclarecimentos terminol\'ogicos. Na segunda, s\~ao expostas as evid\^encias que corroboram a exist\^encia da epidemia. A terceira versa sobre a rea\c{c}\~ao \`a epidemia, caracterizando sua din\^amica, marcada pelo conflito entre duas posi\c{c}\~oes: a moralizadora, que aplica o tratamento moralizador no combate \`a epidemia; e a negacionista, que tende a negar a exist\^encia da epidemia e que resiste \`as medidas moralizadoras. A quarta se\c{c}\~ao versa sobre as causas da epidemia, introduz uma distin\c{c}\~ao entre produtivismo e producionismo e prop\~oe uma an\'alise das formas como o produtivismo fomenta as m\'as condutas. A quinta consiste em uma cr\'itica ao tratamento moralizador, fundamentada em suas inadequa\c{c}\~oes, principalmente sua inefic\'acia. Na conclus\~ao, procura-se dar uma ideia de qual seria uma alternativa satisfat\'oria ao tratamento moralizador.},
  file = {/home/gabriel/Dropbox/zotero-library/Oliveira_2015_A epidemia de más condutas na ciência.pdf},
  journal = {Scientiae Studia},
  keywords = {Código de ética,Despublicação,Fraude,Integridade da pesquisa,Judicialização,Má conduta,Plágio,Produtivismo,Steneck},
  language = {pt}
}

@article{osterloh2015,
  title = {Ranking {{Games}}},
  author = {Osterloh, Margit and Frey, Bruno S.},
  year = {2015},
  month = feb,
  volume = {39},
  pages = {102--129},
  publisher = {{SAGE Publications Inc}},
  issn = {0193-841X},
  doi = {10.1177/0193841X14524957},
  abstract = {Background:Research rankings based on bibliometrics today dominate governance in academia and determine careers in universities.Method:Analytical approach to capture the incentives by users of rankings and by suppliers of rankings, both on an individual and an aggregate level.Result:Rankings may produce unintended negative side effects. In particular, rankings substitute the ?taste for science? by a ?taste for publication.? We show that the usefulness of rankings rests on several important assumptions challenged by recent research.Conclusion:We suggest as alternatives careful socialization and selection of scholars, supplemented by periodic self-evaluations and awards. The aim is to encourage controversial discourses in order to contribute meaningful to the advancement of science.},
  file = {/home/gabriel/Dropbox/zotero-library/Osterloh_Frey_2015_Ranking Games.pdf},
  journal = {Evaluation Review},
  keywords = {academic governance,motivation,rankings,selection,socialization,todo},
  language = {en},
  number = {1}
}

@article{osterloh2020,
  title = {How to Avoid Borrowed Plumes in Academia},
  author = {Osterloh, Margit and Frey, Bruno S.},
  year = {2020},
  month = feb,
  volume = {49},
  pages = {103831},
  issn = {0048-7333},
  doi = {10.1016/j.respol.2019.103831},
  abstract = {Publications in top journals today have a powerful influence on academic careers although there is much criticism of using journal rankings to evaluate individual articles. We ask why this practice of performance evaluation is still so influential. We suggest this is the case because a majority of authors benefit from the present system due to the extreme skewness of citation distributions. ``Performance paradox'' effects aggravate the problem. Three extant suggestions for reforming performance management are critically discussed. We advance a new proposal based on the insight that fundamental uncertainty is symptomatic for scholarly work. It suggests focal randomization using a rationally founded and well-orchestrated procedure.},
  file = {/home/gabriel/Dropbox/zotero-library/Osterloh_Frey_2020_How to avoid borrowed plumes in academia.pdf},
  journal = {Research Policy},
  keywords = {fav,Focal random selection,Impact factor,Journal quality lists,Journal rankings,Skewed citation distribution},
  language = {en},
  number = {1}
}

@article{packer1998,
  title = {{SciELO: uma metodologia para publica\c{c}\~ao eletr\^onica}},
  shorttitle = {{SciELO}},
  author = {Packer, Abel Laerte and Biojone, Mariana Rocha and Antonio, Irati and Takenaka, Roberta Mayumi and Garc{\'i}a, Alberto Pedroso and da Silva, Asael Costa and Murasaki, Renato Toshiyuki and Mylek, Cristina and Reis, Odila Carvalho and Delbucio, H{\'a}lida Cristina Rocha F.},
  year = {1998},
  volume = {27},
  pages = {nd-nd},
  issn = {1518-8353, 0100-1965},
  doi = {10.1590/S0100-19651998000200001},
  abstract = {Descreve a Metodologia SciELO - Scientific Electronic Library Online para a publica\c{c}\~ao eletr\^onica de peri\'odicos cient\'ificos, abordando temas como a transi\c{c}\~ao da publica\c{c}\~ao impressa em papel para a publica\c{c}\~ao eletr\^onica, o processo de comunica\c{c}\~ao cient\'ifica, os princ\'ipios que nortearam o desenvolvimento da metodologia, sua aplica\c{c}\~ao no site SciELO, seus m\'odulos e componentes, os instrumentos nos quais est\'a baseada etc. O artigo discute, tamb\'em, as potencialidades e tend\^encias para a \'area no Brasil e Am\'erica Latina, apontando quest\~oes e propostas que dever\~ao ser abordadas e solucionadas pela metodologia. Conclui que a Metodologia SciELO \'e uma solu\c{c}\~ao eficiente, flex\'ivel e ampla para a publica\c{c}\~ao cient\'ifica eletr\^onica.           ,              It describes the SciELO Methodology - Scientific Electronic Library Online for electronic publishing of scientific periodicals, examining issues such as the transition from traditonal printed publication to electronic publishing, the scientific communication process, the principles which founded the methodology development, its application in the building of the SciELO site, its modules and components, the tools used for its construction etc. The article also discusses the potentialities and trends for the area in Brazil and Latin America, pointing out questions and proposals which should be investigated and solved by the methodology. It concludes that the SciELO Methodology is an efficient, flexible and wide solution for the scientific electronic publishing.},
  file = {/home/gabriel/Zotero/storage/3S8NJ7DQ/Packer et al. - 1998 - SciELO uma metodologia para publicação eletrônica.pdf},
  journal = {Ci\^encia da Informa\c{c}\~ao},
  language = {pt},
  number = {2}
}

@article{packer2009,
  title = {The {{SciELO Open Access}}: {{A Gold Way}} from the {{South}}},
  shorttitle = {The {{SciELO Open Access}}},
  author = {Packer, Abel L.},
  year = {2009},
  volume = {39},
  pages = {111--126},
  publisher = {{Canadian Society for the Study of Higher Education}},
  issn = {0316-1218},
  abstract = {Open access has long emphasized access to scholarly materials. However, open access can also mean access to the means of producing visible and recognized journals. This issue is particularly important in developing and emergent countries. The SciELO (Scientific Electronic Library On-line) project, first started in Brazil and, shortly afterward, in Chile, offers a prime example of how this form of access to publishing was achieved and how open access in the traditional sense was incorporated within it. Open access has allowed more visibility, transparency, and credibility for the SciELO journals that now span over a dozen countries, three continents, and more than 600 titles. Conversely, SciELO incarnates the most successful and impressive example of "gold OA," that is, open access based on publishing rather than self-archiving; at the same time, its database acts like an open-access depository.},
  file = {/home/gabriel/Dropbox/zotero-library/Packer_2009_The SciELO Open Access.pdf},
  journal = {Canadian Journal of Higher Education},
  keywords = {Access to Information,Electronic Journals,Electronic Libraries,Electronic Publishing,Foreign Countries,Global Approach,Open Source Technology,Scholarship},
  language = {en},
  number = {3}
}

@article{pagano2014,
  title = {The Crisis of Intellectual Monopoly Capitalism},
  author = {Pagano, Ugo},
  year = {2014},
  month = nov,
  volume = {38},
  pages = {1409--1429},
  issn = {0309-166X},
  doi = {10.1093/cje/beu025},
  abstract = {The last three decades have witnessed the emergence of a new species of capitalism. In spite of marked differences between its national varieties, a common characteristic of this species can be found in the global monopolisation of knowledge. This monopolisation involves hierarchical relations among firms and between capital and labour, because the capital of some firms includes the exclusive ownership of much of the knowledge used in production. Since the 1994 Trade-Related Aspects of Intellectual Property Rights agreements, the growing commoditisation of knowledge has extended the role of closed science and closed markets at the expense of open science and open markets. The intrinsic long-term dynamics of this species of capitalism is increasingly characterised by financialisation, inequality and stagnation. In order to exit from the current crisis, we must change many features of intellectual monopoly capitalism and rely on an eclectic approach that draws insights from liberal, Keynesian and Marxian traditions.},
  file = {/home/gabriel/Dropbox/zotero-library/Pagano_2014_The crisis of intellectual monopoly capitalism.pdf},
  journal = {Cambridge Journal of Economics},
  keywords = {todo},
  number = {6}
}

@article{pan2018,
  title = {Examining the Usage, Citation, and Diffusion Patterns of Bibliometric Mapping Software: {{A}} Comparative Study of Three Tools},
  shorttitle = {Examining the Usage, Citation, and Diffusion Patterns of Bibliometric Mapping Software},
  author = {Pan, Xuelian and Yan, Erjia and Cui, Ming and Hua, Weina},
  year = {2018},
  month = may,
  volume = {12},
  pages = {481--493},
  issn = {1751-1577},
  doi = {10.1016/j.joi.2018.03.005},
  abstract = {This study investigates the use, citation and diffusion of three bibliometric mapping software tools (CiteSpace, HistCite and VOSviewer) in scientific papers. We first conduct a content analysis of a sample of 481 English core journal papers\textemdash i.e., papers from journals deemed central to their respective disciplines\textemdash in which at least one of these tools is mentioned. This allows us to understand the predominant mention and citation practices surrounding these tools. We then employ several diffusion indicators to gain insight into the diffusion patterns of the three software tools. Overall, we find that researchers mention and cite the tools in diverse ways, many of which fall short of a traditional formal citation. Our results further indicate a clear upward trend in the use of all three tools, though VOSviewer is more frequently used than CiteSpace or HistCite. We also find that these three software tools have seen the fastest and most widespread adoption in library and information science research, where the tools originated. They have since been gradually adopted in other areas of study, initially at a lower diffusion speed but afterward at a rapidly growing rate.},
  file = {/home/gabriel/Dropbox/zotero-library/Pan et al_2018_Examining the usage, citation, and diffusion patterns of bibliometric mapping.pdf},
  journal = {Journal of Informetrics},
  keywords = {Bibliometric mapping software,Bibliometrics,Knowledge diffusion,Scholarly communication,Software citation},
  language = {en},
  number = {2}
}

@article{pendlebury2009,
  title = {The Use and Misuse of Journal Metrics and Other Citation Indicators},
  author = {Pendlebury, David A.},
  year = {2009},
  month = feb,
  volume = {57},
  pages = {1--11},
  issn = {0004-069X, 1661-4917},
  doi = {10.1007/s00005-009-0008-y},
  abstract = {This article reviews the nature and use of the journal impact factor and other common bibliometric measures for assessing research in the sciences and social sciences based on data compiled by Thomson Reuters. Journal impact factors are frequently misused to assess the influence of individual papers and authors, but such uses were never intended. Thomson Reuters also employs other measures of journal influence, which are contrasted with the impact factor. Finally, the author comments on the proper use of citation data in general, often as a supplement to peer review. This review may help government policymakers, university administrators, and individual researchers become better acquainted with the potential benefits and limitations of bibliometrics in the evaluation of research.},
  file = {/home/gabriel/Dropbox/zotero-library/Pendlebury_2009_The use and misuse of journal metrics and other citation indicators.pdf},
  journal = {Archivum Immunologiae et Therapiae Experimentalis},
  keywords = {fav,top5},
  language = {en},
  number = {1}
}

@article{peoples2016,
  title = {Twitter {{Predicts Citation Rates}} of {{Ecological Research}}},
  author = {Peoples, Brandon K. and Midway, Stephen R. and Sackett, Dana and Lynch, Abigail and Cooney, Patrick B.},
  year = {2016},
  month = nov,
  volume = {11},
  pages = {e0166570},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0166570},
  abstract = {The relationship between traditional metrics of research impact (e.g., number of citations) and alternative metrics (altmetrics) such as Twitter activity are of great interest, but remain imprecisely quantified. We used generalized linear mixed modeling to estimate the relative effects of Twitter activity, journal impact factor, and time since publication on Web of Science citation rates of 1,599 primary research articles from 20 ecology journals published from 2012\textendash 2014. We found a strong positive relationship between Twitter activity (i.e., the number of unique tweets about an article) and number of citations. Twitter activity was a more important predictor of citation rates than 5-year journal impact factor. Moreover, Twitter activity was not driven by journal impact factor; the `highest-impact' journals were not necessarily the most discussed online. The effect of Twitter activity was only about a fifth as strong as time since publication; accounting for this confounding factor was critical for estimating the true effects of Twitter use. Articles in impactful journals can become heavily cited, but articles in journals with lower impact factors can generate considerable Twitter activity and also become heavily cited. Authors may benefit from establishing a strong social media presence, but should not expect research to become highly cited solely through social media promotion. Our research demonstrates that altmetrics and traditional metrics can be closely related, but not identical. We suggest that both altmetrics and traditional citation rates can be useful metrics of research impact.},
  file = {/home/gabriel/Dropbox/zotero-library/Peoples et al_2016_Twitter Predicts Citation Rates of Ecological Research.pdf},
  journal = {PLOS ONE},
  keywords = {Altmetrics,Bibliometrics,Citation analysis,Conservation science,Ecology,Scientific publishing,Social media,Twitter},
  language = {en},
  number = {11}
}

@article{ponce2017,
  title = {{Sobre a melhoria da produ\c{c}\~ao e da avalia\c{c}\~ao de peri\'odicos cient\'ificos no Brasil}},
  author = {Ponce, Branca Jurema and de Almeida, Maria Elizabeth Biaconcini and Freitas, Silvana Alves and da Silva, C{\'i}cero Barbosa and Anjos, Daniela and de Pietri, Emerson and Prieto, Ros{\^a}ngela Gavioli and Dias, {\'E}rika S. de Almeida C. and Camargo, Evani and Branco, Jordanna Castelo and Souza, Jos{\'e} dos Santos and Bizelli, Jos{\'e} Lu{\'i}s and Siman, Lana Mara de Castro and Muzzeti, Luci Regina and dos Reis, Magali and Martins, Edna and Rosito, Margar{\'e}te May Benkenbrock and Bissoto, Maria Luisa and de Castro, Monica Rabelo and Gimenes, Nelson and Gualtieri, Regina and Silva, Regis and Ribeiro, Ricardo and Lemes, Sebasti{\~a}o de Souza},
  year = {2017-Oct-Dec},
  volume = {25},
  pages = {1032--1044},
  publisher = {{Funda\c{c}\~ao CESGRANRIO}},
  issn = {0104-4036, 0104-4036, 1809-4465},
  doi = {10.1590/S0104-40362017002501032},
  abstract = {Resumo O documento que apresentamos \'e fruto da reflex\~ao de Editores de Peri\'odico Cient\'ificos ligados ao FEPAE Sudeste \textendash{} F\'orum de Editores de Peri\'odicos da \'Area de Educa\c{c}\~ao Sudeste \textendash{} e expressa preocupa\c{c}\~oes concretas sobre as condi\c{c}\~oes materiais para a realiza\c{c}\~ao de seu trabalho, assim como, sobre os crit\'erios de avalia\c{c}\~ao que v\^em sendo utilizados para qualificar suas revistas. Or\c{c}amentos mais enxutos, o desmonte de estruturas universit\'arias que sustentavam muitas revistas acad\^emicas e indexadores que cada vez mais complicam os procedimentos operacionais envolvidos na produ\c{c}\~ao editorial, fragilizam as revistas nacionais. Falta de visibilidade sobre os processos de avalia\c{c}\~ao, aus\^encia de di\'alogo sobre resultados e quest\~oes ligadas \`a periodicidade do QUALIS trazem uma inseguran\c{c}a para os autores que t\^em nos peri\'odicos o ve\'iculo de divulga\c{c}\~ao de suas pr\'aticas e teorias. Queremos, assim, adensar a discuss\~ao com a comunidade cient\'ifica e a Ag\^encia Reguladora Governamental, sobre os destinos que estar\~ao reservados aos Peri\'odicos Cient\'ificos brasileiros.},
  file = {/home/gabriel/Dropbox/zotero-library/Ponce et al_2017_Sobre a melhoria da produção e da avaliação de periódicos científicos no Brasil.pdf},
  journal = {Ensaio: Avalia\c{c}\~ao e Pol\'iticas P\'ublicas em Educa\c{c}\~ao},
  keywords = {avaliação,CAPES,periódicos acadêmicos,processo editorial,Qualis},
  language = {pt}
}

@article{pulverer2015,
  title = {Dora the {{Brave}}},
  author = {Pulverer, Bernd},
  year = {2015},
  month = jun,
  volume = {34},
  pages = {1601--1602},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0261-4189},
  doi = {10.15252/embj.201570010},
  abstract = {The San Francisco Declaration on Research Assessment (DORA) points out that using the Journal Impact Factor as a proxy measure for the value or quality of specific research and individual scientists leads to biased research assessment. How can we resist misusing metrics?},
  file = {/home/gabriel/Dropbox/zotero-library/Pulverer_2015_Dora the Brave.pdf},
  journal = {The EMBO Journal},
  number = {12}
}

@article{reategui2020,
  title = {Evaluation of {{Brazilian}} Research Output in Education: Confronting International and National Contexts},
  shorttitle = {Evaluation of {{Brazilian}} Research Output in Education},
  author = {Reategui, Eliseo and Pires, Alause and Carniato, Michel and Franco, Sergio Roberto Kieling},
  year = {2020},
  month = oct,
  volume = {125},
  pages = {427--444},
  issn = {1588-2861},
  doi = {10.1007/s11192-020-03617-z},
  abstract = {Scientific production has increased considerably in the last two decades in Brazil, placing the country as an emerging scientific power. In the field of Education, the same can be observed, with a significant growth in the number of articles published by Brazilian researchers in the recent past. In this article we evaluate Brazilian research output in Education from 2007 to 2016, with the intent to understand how national evaluation standards compare with international parameters dictated by bibliometric indicators. We confront the citation impact of Brazilian publications in the period with their classification in an expert-based journal evaluation system called QUALIS. We used Scopus' SNIP bibliometric indicator for this analysis. The study was carried out using data about 40,825 articles published in 2719 different journals. Results showed that only a small percentage of these articles featured in Scopus indexed journals (13.28\%), and most of these journals were published in Brazil (66\%). The citation impact of the Scopus indexed publications had a significant growth in the period, but journals with dissimilar citation impact were not distinctively distributed in separate QUALIS categories. These findings show a certain publishing pattern that is likely to be related to the association of the Brazilian research evaluation and funding systems. In addition, they raise questions about how the establishment of evaluation criteria that is mainly subjective and does not include specific metrics may hinder the visibility of research output from a global perspective.},
  journal = {Scientometrics},
  language = {en},
  number = {1}
}

@article{rego2014,
  title = {{Produtivismo, pesquisa e comunica\c{c}\~ao cient\'ifica: entre o veneno e o rem\'edio}},
  shorttitle = {{Produtivismo, pesquisa e comunica\c{c}\~ao cient\'ifica}},
  author = {Rego, Teresa Cristina},
  year = {2014},
  month = jun,
  volume = {40},
  pages = {325--346},
  publisher = {{Faculdade de Educa\c{c}\~ao da Universidade de S\~ao Paulo}},
  issn = {1517-9702, 1517-9702, 1678-4634},
  doi = {10.1590/S1517-97022014061843},
  abstract = {Este ensaio trata de temas relacionados \`a produ\c{c}\~ao e publica\c{c}\~ao cient\'ifica na contemporaneidade. As an\'alises est\~ao voltadas especialmente para os reflexos de um processo perverso que tem afetado os pesquisadores, as universidades e as revistas do Brasil (assim como j\'a ocorreu ou vem ocorrendo em diferentes partes do mundo), devido ao chamado produtivismo acad\^emico (entendido como a obriga\c{c}\~ao de publicar em peri\'odicos, como indicador praticamente exclusivo para a avalia\c{c}\~ao da produ\c{c}\~ao cient\'ifica e da qualidade do pesquisador), bem como para o conjunto de desdobramentos negativos que esse processo provoca. Tomando como pressuposto a impossibilidade de tratar o tema da comunica\c{c}\~ao cient\'ifica separadamente da estrutura da produ\c{c}\~ao cient\'ifica da qual o universo das revistas indexadas faz parte, o texto procurar\'a problematizar as seguintes quest\~oes: quais s\~ao as principais distor\c{c}\~oes que a ado\c{c}\~ao de crit\'erios majoritariamente quantitativos para avaliar, promover e financiar pesquisadores, peri\'odicos e programas de p\'os-gradua\c{c}\~ao tem provocado? Como se caracteriza o ciclo perverso do produtivismo que hoje contamina o nosso contexto acad\^emico? Como ele afeta nossas produ\c{c}\~oes e publica\c{c}\~oes? De que modo aquilo que foi planejado para melhorar a tarefa investigativa acaba por prejudic\'a-la? Alguns tra\c{c}os podem ser identificados e extra\'idos do conjunto dos mecanismos acima, sem que se pretenda, evidentemente, esgotar a complexidade do processo envolvido. Ser\~ao expostos tamb\'em alguns argumentos advogando a favor da necessidade de uma a\c{c}\~ao coletiva entre os editores das revistas cient\'ificas (especialmente da \'area de humanidades), visando ao desenvolvimento de uma atua\c{c}\~ao pol\'itica capaz de combater as mazelas do sistema hoje vigente de produ\c{c}\~ao, avalia\c{c}\~ao e comunica\c{c}\~ao da ci\^encia.},
  file = {/home/gabriel/Dropbox/zotero-library/Rego_2014_Produtivismo, pesquisa e comunicação científica.pdf},
  journal = {Educa\c{c}\~ao e Pesquisa},
  keywords = {Fator de impacto,Periódicos científicos,Política editorial,Produção e comunicação científica nas humanidades,Produtivismo acadêmico,todo},
  language = {pt}
}

@article{rijcke2016,
  title = {Evaluation Practices and Effects of Indicator Use\textemdash a Literature Review},
  author = {de Rijcke, Sarah and Wouters, Paul F. and Rushforth, Alex D. and Franssen, Thomas P. and Hammarfelt, Bj{\"o}rn},
  year = {2016},
  month = apr,
  volume = {25},
  pages = {161--169},
  issn = {0958-2029},
  doi = {10.1093/reseval/rvv038},
  abstract = {This review of the international literature on evaluation systems, evaluation practices, and metrics (mis)uses was written as part of a larger review commissioned by the Higher Education Funding Council for England (HEFCE) to inform their independent assessment of the role of metrics in research evaluation (2014\textendash 5). The literature on evaluation systems, practices, and effects of indicator uses is extremely heterogeneous: it comprises hundreds of sources published in different media, spread over disciplines, and with considerable variation in the nature of the evidence. A condensation of the state-of-the-art in relevant research is therefore highly timely. Our review presents the main strands in the literature, with a focus on empirical materials about possible effects of evaluation exercises, `gaming' of indicators, and strategic responses by scientific communities and others to requirements in research assessments. In order to increase visibility and availability, an adapted and updated review is presented here as a stand-alone\textemdash after authorization by HEFCE.},
  file = {/home/gabriel/Dropbox/zotero-library/Rijcke et al_2016_Evaluation practices and effects of indicator use—a literature review.pdf},
  journal = {Research Evaluation},
  keywords = {todo},
  number = {2}
}

@article{robinson-garcia2019,
  title = {The Many Faces of Mobility: {{Using}} Bibliometric Data to Measure the Movement of Scientists},
  shorttitle = {The Many Faces of Mobility},
  author = {{Robinson-Garcia}, Nicol{\'a}s and Sugimoto, Cassidy R. and Murray, Dakota and {Yegros-Yegros}, Alfredo and Larivi{\`e}re, Vincent and Costas, Rodrigo},
  year = {2019},
  month = feb,
  volume = {13},
  pages = {50--63},
  issn = {1751-1577},
  doi = {10.1016/j.joi.2018.11.002},
  abstract = {This paper presents a methodological framework for developing scientific mobility indicators based on bibliometric data. We identify nearly 16 million individual authors from publications covered in the Web of Science for the 2008\textendash 2015 period. Based on the information provided across individuals' publication records, we propose a general classification for analyzing scientific mobility using institutional affiliation changes. We distinguish between migrants--authors who have ruptures with their country of origin--and travelers--authors who gain additional affiliations while maintaining affiliation with their country of origin. We find that 3.7\% of researchers who have published at least one paper over the period are mobile. Travelers represent 72.7\% of all mobile scholars, but migrants have higher scientific impact. We apply this classification at the country level, expanding the classification to incorporate the directionality of scientists' mobility (i.e., incoming and outgoing). We provide a brief analysis to highlight the utility of the proposed taxonomy to study scholarly mobility and discuss the implications for science policy.},
  file = {/home/gabriel/Dropbox/zotero-library/Robinson-Garcia et al_2019_The many faces of mobility.pdf},
  journal = {Journal of Informetrics},
  keywords = {Bibliometrics,Brain circulation,Brain drain,International mobility,Science policy,Scientific mobility},
  language = {en},
  number = {1}
}

@article{rocha-e-silva2009,
  title = {{O novo Qualis, ou a trag\'edia anunciada}},
  author = {{Rocha-e-Silva}, Mauricio},
  year = {2009},
  month = jan,
  volume = {64},
  pages = {1--4},
  publisher = {{Faculdade de Medicina / USP}},
  issn = {1807-5932, 1807-5932, 1980-5322},
  doi = {10.1590/S1807-59322009000100001},
  file = {/home/gabriel/Dropbox/zotero-library/Rocha-e-Silva_2009_O novo Qualis, ou a tragédia anunciada.pdf},
  journal = {Clinics},
  language = {pt}
}

@article{roldan-valadez2019,
  title = {Current Concepts on Bibliometrics: A Brief Review about Impact Factor, {{Eigenfactor}} Score, {{CiteScore}}, {{SCImago Journal Rank}}, {{Source}}-{{Normalised Impact}} per {{Paper}}, {{H}}-Index, and Alternative Metrics},
  shorttitle = {Current Concepts on Bibliometrics},
  author = {{Roldan-Valadez}, Ernesto and {Salazar-Ruiz}, Shirley Yoselin and {Ibarra-Contreras}, Rafael and Rios, Camilo},
  year = {2019},
  month = aug,
  volume = {188},
  pages = {939--951},
  issn = {0021-1265, 1863-4362},
  doi = {10.1007/s11845-018-1936-5},
  abstract = {Background Understanding the impact of a publication by using bibliometric indices becomes an essential activity not only for universities and research institutes but also for individual academicians. This paper aims to provide a brief review of the current bibliometric tools used by authors and editors and proposes an algorithm to assess the relevance of the most common bibliometric tools to help the researchers select the fittest journal and know the trends of published submissions by using self-evaluation. Methods We present a narrative review answering at least two related consecutive questions triggered by the topics mentioned above. How prestigious is a journal based on its most recent bibliometrics, so authors may choose it to submit their next manuscript? And, how can they self-evaluate/understand the impact of their whole publishing scientific life? Results We presented the main relevant definitions of each bibliometrics and grouped them in those oriented to evaluated journals or individuals. Also, we share with our readers our algorithm to assess journals before manuscript submission. Conclusions Since there is a journal performance market and an article performance market, each one with its patterns, an integrative use of these metrics, rather than just the impact factor alone, might represent the fairest and most legitimate approach to assess the influence and importance of an acceptable research issue, and not only a sound journal in their respective disciplines.},
  file = {/home/gabriel/Dropbox/zotero-library/Roldan-Valadez et al_2019_Current concepts on bibliometrics.pdf},
  journal = {Irish Journal of Medical Science (1971 -)},
  keywords = {fav,top5},
  language = {en},
  number = {3}
}

@book{rousseau2018,
  title = {Becoming {{Metric}}-{{Wise}}: {{A Bibliometric Guide}} for {{Researchers}}},
  shorttitle = {Becoming {{Metric}}-{{Wise}}},
  author = {Rousseau, Ronald and Egghe, Leo and Guns, Raf},
  year = {2018},
  month = jan,
  publisher = {{Chandos Publishing}},
  abstract = {Becoming Metric-Wise: A Bibliometric Guide for Researchers aims to inform researchers about metrics so that they become aware of the evaluative techniques being applied to their scientific output. Understanding these concepts will help them during their funding initiatives, and in hiring and tenure. The book not only describes what indicators do (or are designed to do, which is not always the same thing), but also gives precise mathematical formulae so that indicators can be properly understood and evaluated. Metrics have become a critical issue in science, with widespread international discussion taking place on the subject across scientific journals and organizations.  As researchers should know the publication-citation context, the mathematical formulae of indicators being used by evaluating committees and their consequences, and how such indicators might be misused, this book provides an ideal tome on the topic.Provides researchers with a detailed understanding of bibliometric indicators and their applicationsEmpowers researchers looking to understand the indicators relevant to their work and careersPresents an informed and rounded picture of bibliometrics, including the strengths and shortcomings of particular indicatorsSupplies the mathematics behind bibliometric indicators so they can be properly understoodWritten by authors with longstanding expertise who are considered global leaders in the field of bibliometrics},
  file = {/home/gabriel/Dropbox/zotero-library/Rousseau et al_2018_Becoming Metric-Wise.pdf},
  googlebooks = {AissDwAAQBAJ},
  isbn = {978-0-08-102475-1},
  keywords = {Language Arts \& Disciplines / Library \& Information Science / Administration \& Management,Language Arts \& Disciplines / Library \& Information Science / General},
  language = {en}
}

@article{salager-meyer2008,
  title = {Scientific Publishing in Developing Countries: {{Challenges}} for the Future},
  shorttitle = {Scientific Publishing in Developing Countries},
  author = {{Salager-Meyer}, Fran{\c c}oise},
  year = {2008},
  month = apr,
  volume = {7},
  pages = {121--132},
  issn = {1475-1585},
  doi = {10.1016/j.jeap.2008.03.009},
  abstract = {In this paper, I first refer to the center-periphery dichotomy in terms of scientific output, placing emphasis upon the relation that exists between science and technology development, on the one hand, and social and economic development, on the other. I then analyze the main problems faced by most peripheral journals and the role nation states play in scientific activities in developing countries. I then address issues such as the world power structures, the social organization of developing countries, growing North/South disparities and the question of collaborative research. The discursive (i.e., language related) and non-discursive problems faced by researchers in periphery countries and the main initiatives that have recently been taken to try to solve the stark disparities that exist in the world of scholarly publishing are also discussed. I finally present a proposal, the aim of which is to suggest ways that could help scientists in periphery countries become fully integrated members of the worldwide network of science and would also contribute to the promotion of scientific multilingualism, a means for science to be truly universal, as it should be. I~conclude by arguing that science, technology and publication form a triad which is essential for the survival of developing nations, and that, although the complete elimination of inequities in the world of scholarship is unlikely, progress could be achieved if there were a universal will (i.e., a worldwide will at the institutional, governmental and intergovernmental levels) to redress the current North/South imbalance.},
  file = {/home/gabriel/Dropbox/zotero-library/Salager-Meyer_2008_Scientific publishing in developing countries.pdf},
  journal = {Journal of English for Academic Purposes},
  keywords = {Linguistic imperialism,Local/small journals,NNES scientists,Periphery,Research,Scientific multilingualism,todo},
  language = {en},
  number = {2},
  series = {English for {{Research Publication Purposes}}}
}

@misc{santos2009,
  title = {{Bibliometria, cientometria, infometria: conceitos e aplica\c{c}\~oes}},
  shorttitle = {{Bibliometria, cientometria, infometria}},
  author = {dos Santos, Raimundo Nonato Macedo and Kobashi, Nair Yumiko},
  year = {2009},
  month = jan,
  publisher = {{Tend\^encias da Pesquisa Brasileira em Ci\^encia da Informa\c{c}\~ao}},
  abstract = {An\'alise da constitui\c{c}\~ao e institucionaliza\c{c}\~ao da bibliometria, da cientometria e da infometria. O estudo teve como objetivos principais identificar os conceitos-chave dessas disciplinas, suas semelhan\c{c}as e diferen\c{c}as, suas potencialidades e limites e as tend\^encias contempor\^aneas da pesquisa. De natureza explorat\'oria, o estudo se apoiou em literatura cl\'assica e recente da \'area. Observou-se que, num primeiro momento, com o nome de bibliometria, os estudos procuravam quantificar os produtos da atividade cient\'ifica (livros, artigos e revistas) para fins de gest\~ao de bibliotecas e bases de dados; a cientometria, por sua vez, se constituiu como modelo que se preocupa com a interpreta\c{c}\~ao dos dados quantitativos, \`a luz das teorias constru\'idas no \^ambito das ci\^encias humanas e sociais (CHS). Seu objetivo principal \'e fornecer insumos para o planejamento e a avalia\c{c}\~ao de pol\'iticas cient\'ificas. A infometria, modelo mais recente, se apropria dos m\'etodos bibliom\'etricos e cientom\'etricos para apreender os aspectos cognitivos da atividade cient\'ifica. Nesse sentido, tem como preocupa\c{c}\~ao central conhecer o estado-da-arte dos diferentes dom\'inios do conhecimento. Observou-se, tamb\'em, interesse crescente por t\'ecnicas de visualiza\c{c}\~ao da informa\c{c}\~ao, com a finalidade de elaborar mapas que possam representar adequadamente os aspectos quantitativos e cognitivos da ci\^encia. Conclui-se que os estudos m\'etricos da informa\c{c}\~ao se aproximam, desde Price, das CHS em busca de teorias e modelos que sustentem a interpreta\c{c}\~ao dos dados quantitativos. Nesse sentido, os estudos m\'etricos da informa\c{c}\~ao, em sua configura\c{c}\~ao contempor\^anea, se configuram como campo interdisciplinar que se fertiliza entrecruzando as teorias e os m\'etodos de quantifica\c{c}\~ao com as teorias sociais.},
  annotation = {Accepted: 2015-01-12T16:49:31Z},
  file = {/home/gabriel/Dropbox/zotero-library/Santos_Kobashi_2009_Bibliometria, cientometria, infometria.pdf},
  howpublished = {https://repositorio.ufpe.br/handle/123456789/10089},
  keywords = {todo},
  language = {pt-br},
  type = {{Article}}
}

@article{sarabipour2019,
  title = {On the Value of Preprints: {{An}} Early Career Researcher Perspective},
  shorttitle = {On the Value of Preprints},
  author = {Sarabipour, Sarvenaz and Debat, Humberto J. and Emmott, Edward and Burgess, Steven J. and Schwessinger, Benjamin and Hensel, Zach},
  year = {2019},
  month = feb,
  volume = {17},
  pages = {e3000151},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3000151},
  abstract = {Peer-reviewed journal publication is the main means for academic researchers in the life sciences to create a permanent public record of their work. These publications are also the de facto currency for career progress, with a strong link between journal brand recognition and perceived value. The current peer-review process can lead to long delays between submission and publication, with cycles of rejection, revision, and resubmission causing redundant peer review. This situation creates unique challenges for early career researchers (ECRs), who rely heavily on timely publication of their work to gain recognition for their efforts. Today, ECRs face a changing academic landscape, including the increased interdisciplinarity of life sciences research, expansion of the researcher population, and consequent shifts in employer and funding demands. The publication of preprints, publicly available scientific manuscripts posted on dedicated preprint servers prior to journal-managed peer review, can play a key role in addressing these ECR challenges. Preprinting benefits include rapid dissemination of academic work, open access, establishing priority or concurrence, receiving feedback, and facilitating collaborations. Although there is a growing appreciation for and adoption of preprints, a minority of all articles in life sciences and medicine are preprinted. The current low rate of preprint submissions in life sciences and ECR concerns regarding preprinting need to be addressed. We provide a perspective from an interdisciplinary group of ECRs on the value of preprints and advocate their wide adoption to advance knowledge and facilitate career development.},
  file = {/home/gabriel/Dropbox/zotero-library/Sarabipour et al_2019_On the value of preprints.pdf},
  journal = {PLOS Biology},
  keywords = {Careers,Clinical trials,Medical journals,Medicine and health sciences,Open access medical journals,Peer review,Scientific publishing,Scientists,todo},
  language = {en},
  number = {2}
}

@article{sayao2021,
  title = {Invisible Science: Publication of Negative Research Results},
  shorttitle = {Invisible Science},
  author = {Say{\~a}o, Luis Fernando and Sales, Luana Farias and Felipe, Carla Beatriz Marques},
  year = {2021},
  month = feb,
  volume = {33},
  publisher = {{Pontif\'icia Universidade Cat\'olica de Campinas}},
  issn = {0103-3786, 0103-3786, 2318-0889},
  doi = {10.1590/2318-0889202133e200009},
  abstract = {Abstract An important part of scientific research activities yield negative results \textendash{} non-confirmatory and null data, inconclusive experiments, unexpected data. These results permeate the entire research cycle and constitute an important part of the full scientific knowledge flow generation. However, despite the acknowledgment that it is the non-confirmatory findings that result in the rejection of consolidated hypotheses that drive the progress of science, most of these investigation routes are not documented. Growing competition for resources, tenure, and impact publications induces researchers to produce ``positive'' results that are more likely to be published, interfering with the principles of science reproducibility and self-correction and in the scientific communication cycle. This study aims to review negative results incorporation in the traditional academic publication cycle. It also seeks to identify and systematize the main barriers that prevent researchers from publishing negative results. This exploratory study is based methodologically on the scarce literature on the subject. It confirms the initial assumption that few scientific journals accept, edit special issues or are dedicated to the publication of negative results.},
  file = {/home/gabriel/Dropbox/zotero-library/Sayão et al_2021_Invisible science.pdf},
  journal = {Transinforma\c{c}\~ao},
  keywords = {Negative results,Negative results journals.,Scientific communication},
  language = {en}
}

@article{schmid2017,
  title = {Five Years Post-{{DORA}}: Promoting Best Practices for Research Assessment},
  shorttitle = {Five Years Post-{{DORA}}},
  author = {Schmid, Sandra L.},
  year = {2017},
  month = nov,
  volume = {28},
  pages = {2941--2944},
  publisher = {{American Society for Cell Biology (mboc)}},
  issn = {1059-1524},
  doi = {10.1091/mbc.e17-08-0534},
  abstract = {The San Francisco Declaration on Research Assessment (DORA) was penned 5 years ago to articulate best practices for how we communicate and judge our scientific contributions. In particular, it adamantly declared that Journal Impact Factor (JIF) should never be used as a surrogate measure of the quality of individual research contributions, or for hiring, promotion, or funding decisions. Since then, a heightened awareness of the damaging practice of using JIFs as a proxy for the quality of individual papers, and to assess an individual's or institution's accomplishments has led to changes in policy and the design and application of best practices to more accurately assess the quality and impact of our research. Herein I summarize the considerable progress made and remaining challenges that must be met to ensure a fair and meritocratic approach to research assessment and the advancement of research.},
  file = {/home/gabriel/Dropbox/zotero-library/Schmid_2017_Five years post-DORA.pdf},
  journal = {Molecular Biology of the Cell},
  keywords = {fav,todo},
  number = {22}
}

@article{schmidt2011,
  title = {{Avalia\c{c}\~ao acad\^emica, ideologia e poder}},
  author = {Schmidt, Maria Luisa Sandoval},
  year = {2011},
  month = jun,
  volume = {22},
  pages = {315--334},
  publisher = {{Instituto de Psicologia da Universidade de S\~ao Paulo}},
  issn = {0103-6564, 0103-6564, 1678-5177},
  doi = {10.1590/S0103-65642011005000017},
  abstract = {O artigo discute a avalia\c{c}\~ao acad\^emica no contexto caracterizado pelo produtivismo. Como introdu\c{c}\~ao, analisa o epis\'odio da lista dos improdutivos, ocorrido em 1988 na USP, procurando apontar algumas tend\^encias do debate sobre avalia\c{c}\~ao \`a \'epoca. Em seguida, apresenta, em linhas gerais, ideias que constituem a ideologia produtivista e examina seus desdobramentos na constru\c{c}\~ao de um sistema nacional de avalia\c{c}\~ao no Brasil. Por \'ultimo, considera os efeitos desse sistema no trabalho acad\^emico, tomando como refer\^encia o lugar das exig\^encias de publica\c{c}\~ao no processo de avalia\c{c}\~ao.},
  file = {/home/gabriel/Dropbox/zotero-library/Schmidt_2011_Avaliação acadêmica, ideologia e poder.pdf},
  journal = {Psicologia USP},
  keywords = {Avaliação acadêmica,Ideologia,Política científica,Produtivismo,todo},
  language = {pt}
}

@article{shelton2012,
  title = {Publish or Patent: {{Bibliometric}} Evidence for Empirical Trade-Offs in National Funding Strategies},
  shorttitle = {Publish or Patent},
  author = {Shelton, R. D. and Leydesdorff, Loet},
  year = {2012},
  volume = {63},
  pages = {498--511},
  issn = {1532-2890},
  doi = {10.1002/asi.21677},
  abstract = {Multivariate linear regression models suggest a trade-off in allocations of national research and development (R\&D). Government funding and spending in the higher education sector encourage publications as a long-term research benefit. Conversely, other components such as industrial funding and spending in the business sector encourage patenting. Our results help explain why the United States trails the European Union in publications: The focus in the United States is on industrial funding\textemdash some 70\% of its total R\&D investment. Likewise, our results also help explain why the European Union trails the United States in patenting, since its focus on government funding is less effective than industrial funding in predicting triadic patenting. Government funding contributes negatively to patenting in a multiple regression, and this relationship is significant in the case of triadic patenting. We provide new forecasts about the relationships of the United States, the European Union, and China for publishing; these results suggest much later dates for changes than previous forecasts because Chinese growth has been slowing down since 2003. Models for individual countries might be more successful than regression models whose parameters are averaged over a set of countries because nations can be expected to differ historically in terms of the institutional arrangements and funding schemes.},
  annotation = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21677},
  file = {/home/gabriel/Dropbox/zotero-library/Shelton_Leydesdorff_2012_Publish or patent.pdf},
  journal = {Journal of the American Society for Information Science and Technology},
  language = {en},
  number = {3}
}

@article{silva2009,
  title = {{A sua revista tem Qualis?}},
  author = {da Silva, Antonio Oza{\'i}},
  year = {2009},
  month = jul,
  volume = {14},
  pages = {117--124},
  issn = {2176-6665},
  doi = {10.5433/2176-6665.2009v14n1p117},
  abstract = {Neste artigo o autor examina criticamente o sistema de avalia\c{c}\~ao Qualis. O que est\'a em jogo? Ser\'a mesmo poss\'ivel avaliar a qualidade do que \'e publicado no campo acad\^emico? Ou trata-se apenas de um meio de controle? Observa que pressionados pela exig\^encia de mais e mais produtividade, os docentes perdem o senso cr\'itico, reproduzem o servilismo e mutilam-se para atender \`as normas e regras burocr\'aticas decididas por um grupo seleto de indiv\'iduos.},
  copyright = {Direitos autorais},
  file = {/home/gabriel/Dropbox/zotero-library/Silva_2009_A sua revista tem Qualis.pdf},
  journal = {Media\c{c}\~oes - Revista de Ci\^encias Sociais},
  keywords = {Academe.,Academia.,Avaliação,Evaluation,Qualis},
  language = {pt},
  number = {1}
}

@article{silva2010,
  title = {{Qualis 2011-2013: os tr\^es erres}},
  shorttitle = {{Qualis 2011-2013}},
  author = {e Silva, Maur{\'i}cio Rocha},
  year = {2010},
  month = dec,
  volume = {25},
  pages = {VIII-IX},
  publisher = {{Sociedade Brasileira de Cirurgia Cardiovascular}},
  issn = {0102-7638, 0102-7638, 1678-9741},
  doi = {10.1590/S0102-76382010000400004},
  file = {/home/gabriel/Dropbox/zotero-library/Silva_2010_Qualis 2011-2013.pdf},
  journal = {Brazilian Journal of Cardiovascular Surgery},
  language = {pt}
}

@article{silva2011,
  title = {{An\'alise bibliom\'etrica e cientom\'etrica: desafios para especialistas que atuam no campo}},
  shorttitle = {{An\'alise bibliom\'etrica e cientom\'etrica}},
  author = {da Silva, M{\'a}rcia Regina and Hayashi, Carlos Roberto Massao and Hayashi, Maria Cristina Piumbato Innocentini},
  year = {2011},
  month = jun,
  volume = {2},
  pages = {110--129},
  issn = {2178-2075},
  doi = {10.11606/issn.2178-2075.v2i1p110-129},
  copyright = {Copyright (c)},
  file = {/home/gabriel/Dropbox/zotero-library/Silva et al_2011_Análise bibliométrica e cientométrica.pdf},
  journal = {InCID: Revista de Ci\^encia da Informa\c{c}\~ao e Documenta\c{c}\~ao},
  keywords = {Profissionais da Informação,todo},
  language = {pt},
  number = {1}
}

@article{smit2021,
  title = {The Production of Scientific and Societal Value in Research Evaluation: A Review of Societal Impact Assessment Methods},
  shorttitle = {The Production of Scientific and Societal Value in Research Evaluation},
  author = {Smit, Jorrit P and Hessels, Laurens K},
  year = {2021},
  month = apr,
  issn = {0958-2029},
  doi = {10.1093/reseval/rvab002},
  abstract = {Over the past two decades, several methods have been developed to evaluate the societal impact of research. Compared to the practical development of the field, the conceptual development is relatively weak. This review article contributes to the latter by elucidating the theoretical aspects of the dominant methods for evaluating societal impact of research, in particular, their presuppositions about the relationship between scientific and societal value of research. We analyse 10 approaches to the assessment of the societal impact of research from a constructivist perspective. The methods represent different understandings of knowledge exchange, which can be understood in terms of linear, cyclical, and co-production models. In addition, the evaluation methods use a variety of concepts for the societal value of research, which suggest different relationships with scientific value. While some methods rely on a clear and explicit distinction between the two types of value, other methods, in particular Evaluative Inquiry, ASIRPA, Contribution Mapping, Public Value Mapping, and SIAMPI, consider the mechanisms for producing societal value integral to the research process. We conclude that evaluation methods must balance between demarcating societal value as a separate performance indicator for practical purposes and doing justice to the (constructivist) science studies' findings about the integration of scientific and societal value of research. Our analytic comparison of assessment methods can assist research evaluators in the conscious and responsible selection of an approach that fits with the object under evaluation. As evaluation actively shapes knowledge production, it is important not to use oversimplified concepts of societal value.},
  file = {/home/gabriel/Dropbox/zotero-library/Smit_Hessels_2021_The production of scientific and societal value in research evaluation.pdf},
  journal = {Research Evaluation},
  keywords = {todo},
  number = {rvab002}
}

@article{stavale2019,
  title = {Research Misconduct in Health and Life Sciences Research: {{A}} Systematic Review of Retracted Literature from {{Brazilian}} Institutions},
  shorttitle = {Research Misconduct in Health and Life Sciences Research},
  author = {Stavale, Rafaelly and Ferreira, Graziani Izidoro and Galv{\~a}o, Jo{\~a}o Ant{\^o}nio Martins and Zicker, F{\'a}bio and Novaes, Maria Rita Carvalho Garbi and de Oliveira, C{\'e}sar Messias and Guilhem, Dirce},
  year = {2019},
  month = apr,
  volume = {14},
  pages = {e0214272},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0214272},
  abstract = {Background Measures to ensure research integrity have been widely discussed due to the social, economic and scientific impact of research integrity. In the past few years, financial support for health research in emerging countries has steadily increased, resulting in a growing number of scientific publications. These achievements, however, have been accompanied by a rise in retracted publications followed by concerns about the quality and reliability of such publications. Objective This systematic review aimed to investigate the profile of medical and life sciences research retractions from authors affiliated with Brazilian academic institutions. The chronological trend between publication and retraction date, reasons for the retraction, citation of the article after the retraction, study design, and the number of retracted publications by author and affiliation were assessed. Additionally, the quality, availability and accessibility of data regarding retracted papers from the publishers are described. Methods Two independent reviewers searched for articles that had been retracted since 2004 via PubMed, Web of Science, Biblioteca Virtual em Sa\'ude (BVS) and Google Scholar databases. Indexed keywords from Medical Subject Headings (MeSH) and Descritores em Ci\^encias da Sa\'ude (DeCS) in Portuguese, English or Spanish were used. Data were also collected from the Retraction Watch website (www.retractionwatch.com). This study was registered with the PROSPERO systematic review database (CRD42017071647). Results A final sample of 65 articles was retrieved from 55 different journals with reported impact factors ranging from 0 to 32.86, with a median value of 4.40 and a mean of 4.69. The types of documents found were erratum (1), retracted articles (3), retracted articles with a retraction notice (5), retraction notices with erratum (3), and retraction notices (45). The assessment of the Retraction Watch website added 8 articles that were not identified by the search strategy using the bibliographic databases. The retracted publications covered a wide range of study designs. Experimental studies (40) and literature reviews (15) accounted for 84.6\% of the retracted articles. Within the field of health and life sciences, medical science was the field with the largest number of retractions (34), followed by biological sciences (17). Some articles were retracted for at least two distinct reasons (13). Among the retrieved articles, plagiarism was the main reason for retraction (60\%). Missing data were found in 57\% of the retraction notices, which was a limitation to this review. In addition, 63\% of the articles were cited after their retraction. Conclusion Publications are not retracted solely for research misconduct but also for honest error. Nevertheless, considering authors affiliated with Brazilian institutions, this review concluded that most of the retracted health and life sciences publications were retracted due to research misconduct. Because the number of publications is the most valued indicator of scientific productivity for funding and career progression purposes, a systematic effort from the national research councils, funding agencies, universities and scientific journals is needed to avoid an escalating trend of research misconduct. More investigations are needed to comprehend the underlying factors of research misconduct and its increasing manifestation.},
  file = {/home/gabriel/Dropbox/zotero-library/Stavale et al_2019_Research misconduct in health and life sciences research.pdf},
  journal = {PLOS ONE},
  keywords = {Bibliometrics,Brazil,Citation analysis,Database searching,Medical journals,Medicine and health sciences,Research integrity,Scientific misconduct},
  language = {en},
  number = {4}
}

@book{stengers2018,
  title = {Another {{Science}} Is {{Possible}}: {{A Manifesto}} for {{Slow Science}}},
  shorttitle = {Another {{Science}} Is {{Possible}}},
  author = {Stengers, Isabelle},
  year = {2018},
  month = mar,
  publisher = {{John Wiley \& Sons}},
  abstract = {Like fast food, fast science is quickly prepared, not particularly good, and it clogs up the system. Efforts to tackle our most pressing issues have been stymied by conflict within the scientific community and mixed messages symptomatic of a rushed approach. What is more, scientific research is being shaped by the bubbles and crashes associated with economic speculation and the market. A focus on conformism, competitiveness, opportunism and flexibility has made it extremely difficult to present cases of failure to the public, for fear that it will lose confidence in science altogether. In this bold new book, distinguished philosopher Isabelle Stengers shows that research is deeply intertwined with broader social interests, which means that science cannot race ahead in isolation but must learn instead to slow down. Stengers offers a path to an alternative science, arguing that researchers should stop seeing themselves as the 'thinking, rational brain of humanity' and refuse to allow their expertise to be used to shut down the concerns of the public, or to spread the belief that scientific progress is inevitable and will resolve all of society's problems. Rather, science must engage openly and honestly with an intelligent public and be clear about the kind of knowledge it is capable of producing. This timely and accessible book will be of great interest to students, scholars and policymakers in a wide range of fields, as well anyone concerned with the role of science and its future.},
  file = {/home/gabriel/Dropbox/zotero-library/Stengers_2018_Another Science is Possible.pdf},
  googlebooks = {oxJSDwAAQBAJ},
  isbn = {978-1-5095-2182-1},
  keywords = {Philosophy / General,Science / Philosophy \& Social Aspects},
  language = {en}
}

@article{stern2019,
  title = {A Proposal for the Future of Scientific Publishing in the Life Sciences},
  author = {Stern, Bodo M. and O'Shea, Erin K.},
  year = {2019},
  month = feb,
  volume = {17},
  pages = {e3000116},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3000116},
  abstract = {Science advances through rich, scholarly discussion. More than ever before, digital tools allow us to take that dialogue online. To chart a new future for open publishing, we must consider alternatives to the core features of the legacy print publishing system, such as an access paywall and editorial selection before publication. Although journals have their strengths, the traditional approach of selecting articles before publication (``curate first, publish second'') forces a focus on ``getting into the right journals,'' which can delay dissemination of scientific work, create opportunity costs for pushing science forward, and promote undesirable behaviors among scientists and the institutions that evaluate them. We believe that a ``publish first, curate second'' approach with the following features would be a strong alternative: authors decide when and what to publish; peer review reports are published, either anonymously or with attribution; and curation occurs after publication, incorporating community feedback and expert judgment to select articles for target audiences and to evaluate whether scientific work has stood the test of time. These proposed changes could optimize publishing practices for the digital age, emphasizing transparency, peer-mediated improvement, and post-publication appraisal of scientific articles.},
  file = {/home/gabriel/Dropbox/zotero-library/Stern_O’Shea_2019_A proposal for the future of scientific publishing in the life sciences.pdf},
  journal = {PLOS Biology},
  keywords = {Bibliometrics,Careers,Citation analysis,Internet,Peer review,Quality control,Scientific publishing,Scientists,todo},
  language = {en},
  number = {2}
}

@article{subramanyam1983,
  title = {Bibliometric Studies of Research Collaboration: {{A}} Review},
  shorttitle = {Bibliometric Studies of Research Collaboration},
  author = {Subramanyam, K.},
  year = {1983},
  month = jan,
  volume = {6},
  pages = {33--38},
  issn = {0165-5515, 1741-6485},
  doi = {10.1177/016555158300600105},
  abstract = {Scientific research is becoming an increasingly collaborative endeavour. The nature and magnitude of collaboration vary from one discipline to another, and depend upon such factors as the nature of the research problem, the research environ ment, and demographic factors. Earlier studies have shown a high degree of correlation between collaboration and research productivity, and between collaboration and financial support for research. The extent of collaboration cannot be easily determined by traditional methods of survey and observation. Bibliometric methods offer a convenient and non-reactive tool for studying collaboration in research. In this paper, several types of collaboration have been identified, and earlier research on collaboration has been reviewed. Further research is needed to refine the methods of defining and assessing collaboration and its impact on the organization of research and communica tion in science.},
  file = {/home/gabriel/Dropbox/zotero-library/Subramanyam_1983_Bibliometric studies of research collaboration.pdf},
  journal = {Journal of Information Science},
  keywords = {fav},
  language = {en},
  number = {1}
}

@article{tahamtan2016,
  title = {Factors Affecting Number of Citations: A Comprehensive Review of the Literature},
  shorttitle = {Factors Affecting Number of Citations},
  author = {Tahamtan, Iman and Safipour Afshar, Askar and Ahamdzadeh, Khadijeh},
  year = {2016},
  month = jun,
  volume = {107},
  pages = {1195--1225},
  issn = {0138-9130, 1588-2861},
  doi = {10.1007/s11192-016-1889-2},
  file = {/home/gabriel/Dropbox/zotero-library/Tahamtan et al_2016_Factors affecting number of citations.pdf},
  journal = {Scientometrics},
  keywords = {fav},
  language = {en},
  number = {3}
}

@article{tennant2018,
  title = {The State of the Art in Peer Review},
  author = {Tennant, Jonathan P.},
  year = {2018},
  month = oct,
  volume = {365},
  issn = {1574-6968},
  doi = {10.1093/femsle/fny204},
  abstract = {Scholarly communication is in a perpetual state of disruption. Within this, peer review of research articles remains an essential part of the formal publication process, distinguishing it from virtually all other modes of communication. In the last several years, there has been an explosive wave of innovation in peer review research, platforms, discussions, tools and services. This is largely coupled with the ongoing and parallel evolution of scholarly communication as it adapts to rapidly changing environments, within what is widely considered as the 'open research' or 'open science' movement. Here, we summarise the current ebb and flow around changes to peer review and consider its role in a modern digital research and communications infrastructure and suggest why uptake of new models of peer review appears to have been so low compared to what is often viewed as the 'traditional' method of peer review. Finally, we offer some insight into the potential futures of scholarly peer review and consider what impacts this might have on the broader scholarly research ecosystem. In particular, we focus on the key traits of certification and reputation, moderation and quality control and engagement incentives, and discuss how these interact with socio-technical aspects of peer review and academic culture.},
  file = {/home/gabriel/Dropbox/zotero-library/Tennant_2018_The state of the art in peer review.pdf},
  journal = {FEMS microbiology letters},
  keywords = {Forecasting,Humans,Peer Review; Research,Publishing,Scholarly Communication,todo},
  language = {eng},
  number = {19},
  pmcid = {PMC6140953},
  pmid = {30137294}
}

@article{tennant2020,
  title = {The Limitations to Our Understanding of Peer Review},
  author = {Tennant, Jonathan P. and {Ross-Hellauer}, Tony},
  year = {2020},
  volume = {5},
  pages = {6},
  issn = {2058-8615},
  doi = {10.1186/s41073-020-00092-1},
  abstract = {Peer review is embedded in the core of our knowledge generation systems, perceived as a method for establishing quality or scholarly legitimacy for research, while also often distributing academic prestige and standing on individuals. Despite its critical importance, it curiously remains poorly understood in a number of dimensions. In order to address this, we have analysed peer review to assess where the major gaps in our theoretical and empirical understanding of it lie. We identify core themes including editorial responsibility, the subjectivity and bias of reviewers, the function and quality of peer review, and the social and epistemic implications of peer review. The high-priority gaps are focused around increased accountability and justification in decision-making processes for editors and developing a deeper, empirical understanding of the social impact of peer review. Addressing this at the bare minimum will require the design of a consensus for a minimal set of standards for what constitutes peer review, and the development of a shared data infrastructure to support this. Such a field requires sustained funding and commitment from publishers and research funders, who both have a commitment to uphold the integrity of the published scholarly record. We use this to present a guide for the future of peer review, and the development of a new research discipline based on the study of peer review.},
  file = {/home/gabriel/Dropbox/zotero-library/Tennant_Ross-Hellauer_2020_The limitations to our understanding of peer review.pdf},
  journal = {Research Integrity and Peer Review},
  keywords = {Open peer review,Peer review studies,Quality assurance,Quality control,Reproducibility,Research impact,Scholarly communication,Scholarly publishing,todo},
  language = {eng},
  pmcid = {PMC7191707},
  pmid = {32368354}
}

@article{thelwall2013,
  title = {Do {{Altmetrics Work}}? {{Twitter}} and {{Ten Other Social Web Services}}},
  shorttitle = {Do {{Altmetrics Work}}?},
  author = {Thelwall, Mike and Haustein, Stefanie and Larivi{\`e}re, Vincent and Sugimoto, Cassidy R.},
  year = {2013},
  month = may,
  volume = {8},
  pages = {e64841},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0064841},
  abstract = {Altmetric measurements derived from the social web are increasingly advocated and used as early indicators of article impact and usefulness. Nevertheless, there is a lack of systematic scientific evidence that altmetrics are valid proxies of either impact or utility although a few case studies have reported medium correlations between specific altmetrics and citation rates for individual journals or fields. To fill this gap, this study compares 11 altmetrics with Web of Science citations for 76 to 208,739 PubMed articles with at least one altmetric mention in each case and up to 1,891 journals per metric. It also introduces a simple sign test to overcome biases caused by different citation and usage windows. Statistically significant associations were found between higher metric scores and higher citations for articles with positive altmetric scores in all cases with sufficient evidence (Twitter, Facebook wall posts, research highlights, blogs, mainstream media and forums) except perhaps for Google+ posts. Evidence was insufficient for LinkedIn, Pinterest, question and answer sites, and Reddit, and no conclusions should be drawn about articles with zero altmetric scores or the strength of any correlation between altmetrics and citations. Nevertheless, comparisons between citations and metric values for articles published at different times, even within the same year, can remove or reverse this association and so publishers and scientometricians should consider the effect of time when using altmetrics to rank articles. Finally, the coverage of all the altmetrics except for Twitter seems to be low and so it is not clear if they are prevalent enough to be useful in practice.},
  file = {/home/gabriel/Dropbox/zotero-library/Thelwall et al_2013_Do Altmetrics Work.pdf},
  journal = {PLOS ONE},
  keywords = {Altmetrics,Bibliometrics,Citation analysis,Libraries,Medical journals,Scientific publishing,Social media,todo,Twitter},
  language = {en},
  number = {5}
}

@article{thompson2015,
  title = {A {{Descriptive}} and {{Historical Review}} of {{Bibliometrics}} with {{Applications}} to {{Medical Sciences}}},
  author = {Thompson, Dennis F. and Walker, Cheri K.},
  year = {2015},
  volume = {35},
  pages = {551--559},
  issn = {1875-9114},
  doi = {10.1002/phar.1586},
  abstract = {The discipline of bibliometrics involves the application of mathematical and statistical methods to scholarly publications. The first attempts at systematic data collection were provided by Alfred Lotka and Samuel Bradford, who subsequently established the foundational laws of bibliometrics. Eugene Garfield ushered in the modern era of bibliometrics with the routine use of citation analysis and systematized processing. Key elements of bibliometric analysis include database coverage, consistency and accuracy of the data, data fields, search options, and analysis and use of metrics. A number of bibliometric applications are currently being used in medical science and health care. Bibliometric parameters and indexes may be increasingly used by grant funding sources as measures of research success. Universities may build benchmarking standards from bibliometric data to determine academic achievement through promotion and tenure guidelines in the future. This article reviews the history, definition, laws, and elements of bibliometric principles and provides examples of bibliometric applications to the broader health care community. To accomplish this, the Medline (1966\textendash 2014) and Web of Science (1945\textendash 2014) databases were searched to identify relevant articles; select articles were also cross-referenced. Articles selected were those that provided background, history, descriptive analysis, and application of bibliometric principles and metrics to medical science and health care. No attempt was made to cover all areas exhaustively; rather, key articles were chosen that illustrate bibliometric concepts and enhance the reader's knowledge. It is important that faculty and researchers understand the limitations and appropriate uses of bibliometric data. Bibliometrics has considerable potential as a research area for health care scientists and practitioners that can be used to discover new information about academic trends, pharmacotherapy, disease, and broader health sciences trends.},
  annotation = {\_eprint: https://accpjournals.onlinelibrary.wiley.com/doi/pdf/10.1002/phar.1586},
  copyright = {\textcopyright{} 2015 Pharmacotherapy Publications, Inc.},
  file = {/home/gabriel/Dropbox/zotero-library/Thompson_Walker_2015_A Descriptive and Historical Review of Bibliometrics with Applications to.pdf},
  journal = {Pharmacotherapy: The Journal of Human Pharmacology and Drug Therapy},
  keywords = {application,bibliometrics,fav,history,laws,medicine,pharmacy,publications,top5},
  language = {en},
  number = {6}
}

@book{todeschini2016,
  title = {Handbook of Bibliometric Indicators: Quantitative Tools for Studying and Evaluating Research},
  shorttitle = {Handbook of Bibliometric Indicators},
  author = {Todeschini, Roberto and Baccini, Alberto},
  year = {2016},
  publisher = {{Wiley-VCH Verlag GmbH \& Co.KGaA}},
  address = {{Weinheim}},
  annotation = {OCLC: 953444623},
  file = {/home/gabriel/Dropbox/zotero-library/Todeschini_Baccini_2016_Handbook of bibliometric indicators.pdf},
  isbn = {978-3-527-33704-0 978-3-527-68194-5 978-3-527-68195-2 978-3-527-68193-8 978-3-527-68196-9},
  language = {eng}
}

@article{torre,
  title = {{Nuovi indicatori bibliometrici nella letteratura scientifica: un panorama in continua evoluzione}},
  author = {Torre, G La and Sciarra, I and Chiappetta, M and Monteduro, A},
  pages = {7},
  abstract = {Introduction. Bibliometrics is a science which evaluates the impact of the scientific work of a journal or of an author, using mathematical and statistical tools. Impact Factor (IF) is the first bibliometric parameter created, and after it many others have been progressively conceived in order to go beyond its limits. Currently bibliometric indexes are used for academic purposes, among them to evaluate the eligibility of a researcher to compete for the National Scientific Qualification, in order to access to competitive exams to become professor. Objective. Aim of this study is to identify the most relevant bibliometric indexes and to summarized their characteristics. Methods. A revision of bibliometric indexes as been conducted, starting from the classic ones and completing with the most recent ones. Results. The two most used bibliometric indexes are the IF, which measures the scientific impact of a periodical and bases on Web of Science citation database, and the h-index, which measures the impact of the scientific work of a researcher, basing on Scopus database. Besides them other indexes have been created more recently, such as the SCImago Journal Rank Indicator (SJR), the Source Normalised Impact per Paper (SNIP) and the CiteScore index. They are all based on Scopus database and evaluate, in different ways, the citational impact of a periodic. The i10-index instead is provided from Google Scholar database and allows to evaluate the impact of the scientific production of a researcher. Recently two softwares have been introduced: the first one, Publish or Perish, allows to evaluate the scientific work of a researcher, through the assessment of many indexes; the second one, Altmetric, measure the use in the Web of the academic papers, instead of measuring citations, by means of alternative metrics respect to the traditional ones. Conclusions. Each analized index shows advantages but also criticalities. Therefore the combined use of more than one indexes, citational and not, should be preferred, in order to correctly evaluate the work of reserchers and to finally improve the quality and the development of scientific research. Clin Ter 2017; 168(2):e65-71. doi: 10.7417/CT.2017.1985},
  file = {/home/gabriel/Dropbox/zotero-library/Torre et al_Nuovi indicatori bibliometrici nella letteratura scientifica.pdf},
  language = {it}
}

@article{tran2019,
  title = {Global {{Evolution}} of {{Research}} in {{Artificial Intelligence}} in {{Health}} and {{Medicine}}: {{A Bibliometric Study}}},
  shorttitle = {Global {{Evolution}} of {{Research}} in {{Artificial Intelligence}} in {{Health}} and {{Medicine}}},
  author = {Tran, Bach and Vu, Giang and Ha, Giang and Vuong, Quan-Hoang and Ho, Manh-Tung and Vuong, Thu-Trang and La, Viet-Phuong and Ho, Manh-Toan and Nghiem, Kien-Cuong and Nguyen, Huong and Latkin, Carl and Tam, Wilson and Cheung, Ngai-Man and Nguyen, Hong-Kong and Ho, Cyrus and Ho, Roger},
  year = {2019},
  month = mar,
  volume = {8},
  pages = {360},
  issn = {2077-0383},
  doi = {10.3390/jcm8030360},
  abstract = {The increasing application of Artificial Intelligence (AI) in health and medicine has attracted a great deal of research interest in recent decades. This study aims to provide a global and historical picture of research concerning AI in health and medicine. A total of 27,451 papers that were published between 1977 and 2018 (84.6\% were dated 2008\textendash 2018) were retrieved from the Web of Science platform. The descriptive analysis examined the publication volume, and authors and countries collaboration. A global network of authors' keywords and content analysis of related scientific literature highlighted major techniques, including Robotic, Machine learning, Artificial neural network, Artificial intelligence, Natural language process, and their most frequent applications in Clinical Prediction and Treatment. The number of cancer-related publications was the highest, followed by Heart Diseases and Stroke, Vision impairment, Alzheimer's, and Depression. Moreover, the shortage in the research of AI application to some high burden diseases suggests future directions in AI research. This study offers a first and comprehensive picture of the global efforts directed towards this increasingly important and prolific field of research and suggests the development of global and national protocols and regulations on the justification and adaptation of medical AI products.},
  file = {/home/gabriel/Dropbox/zotero-library/Tran et al_2019_Global Evolution of Research in Artificial Intelligence in Health and Medicine.pdf},
  journal = {Journal of Clinical Medicine},
  language = {en},
  number = {3}
}

@article{trust2020,
  title = {What Researchers Think about the Culture They Work In},
  author = {Trust, Wellcome},
  year = {2020},
  file = {/home/gabriel/Dropbox/zotero-library/Trust_2020_What researchers think about the culture they work in.pdf},
  keywords = {fav}
}

@article{urbizagastegui,
  title = {A {{BIBLIOMETRIA}}: {{HISTORIA}}, {{LEGITIMA\c{C}\~AO E ESTRUTURA}}},
  shorttitle = {A {{BIBLIOMETRIA}}},
  author = {Urbizagastegui, Ruben},
  file = {/home/gabriel/Dropbox/zotero-library/Urbizagastegui_A BIBLIOMETRIA.pdf},
  keywords = {done},
  language = {en}
}

@article{vanleeuwen2001,
  title = {The Use of Combined Bibliometric Methods in Research Funding Policy},
  author = {{van Leeuwen}, T N and {van der Wurff}, L J and {van Raan}, A F J},
  year = {2001},
  month = dec,
  volume = {10},
  pages = {195--201},
  issn = {09582029, 14715449},
  doi = {10.3152/147154401781777015},
  file = {/home/gabriel/Dropbox/zotero-library/van Leeuwen et al_2001_The use of combined bibliometric methods in research funding policy.pdf},
  journal = {Research Evaluation},
  language = {en},
  number = {3}
}

@incollection{vanraan2019,
  title = {Measuring {{Science}}: {{Basic Principles}} and {{Application}} of {{Advanced Bibliometrics}}},
  shorttitle = {Measuring {{Science}}},
  booktitle = {Springer {{Handbook}} of {{Science}} and {{Technology Indicators}}},
  author = {{van Raan}, Anthony},
  editor = {Gl{\"a}nzel, Wolfgang and Moed, Henk F. and Schmoch, Ulrich and Thelwall, Mike},
  year = {2019},
  pages = {237--280},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-02511-3_10},
  abstract = {We begin with a short history of measuring science and discuss how the Science Citation Index has revolutionized the quantitative study of science and created a strong application potential. After reviewing the rationale of bibliometric analysis, we present the basic principle of the bibliometric methodology, with complex citation networks as a starting point. We show that the two main pillars of advanced bibliometric methods, citation-based analysis and science mapping, are both reducible to one and the same principle. From this basic principle we deduce a set of main indicators, particularly for the assessment of research output and international impact. Important elements include new approaches for identifying fields and research themes on the basis of a publication-level rather than a journal-level network; publication and citation counting; normalization of citation measures; the use of indicators based on averages versus those based on citation distributions; and weighting procedures and statistical reliability. In this account of the state of the art of advanced bibliometrics , we highlight in particular the developments in our Leiden institute, given its long-standing, extensive, and broad experience.The next part of this chapter deals with practical applications of indicators, particularly real-life examples of evaluation studies. We further discuss several crucial issues such as the use of journal impact factors and h-index; the relation between peer review judgment and bibliometric findings; definition and delimitation of fields; assignment of publications; the influence of open access; webometrics and altmetrics; ranking of universities; and general objections to bibliometric analysis.The second main pillar of the advanced bibliometric methodology is the development of science maps. We discuss the basic elements and the construction of both citation-relation and word-relation science maps. Further, we present a method to combine the two main pillars: the integration of citation analysis in science maps. This combined citation analysis and science mapping can be used to explore research related to socioeconomic problems. Recently developed bibliometric instruments enable tunable mapping, which opens up new analytical opportunities in monitoring scientific research. Finally, we contend that bibliometric indicators and maps are not just evaluation tools for science policymakers, research managers, and individual researchers, but also powerful instruments in the study of science.},
  file = {/home/gabriel/Zotero/storage/D5CSCDT4/van Raan - 2019 - Measuring Science Basic Principles and Applicatio},
  isbn = {978-3-030-02511-3},
  keywords = {advanced bibliometrics,bibliometric networks,fav,guidelines for the proper use of bibliometric indicators,history of scientometrics,indicators of research output and impact,measuring science,methodological and technical issues in bibliometics,practical application of bibliometric indicators,ranking of universities,science maps,todo},
  language = {en},
  series = {Springer {{Handbooks}}}
}

@article{vasconcelos2009,
  title = {Discussing Plagiarism in {{Latin American}} Science},
  author = {Vasconcelos, Sonia and Leta, Jacqueline and Costa, L{\'i}dia and Pinto, Andr{\'e} and Sorenson, Martha M},
  year = {2009},
  month = jul,
  volume = {10},
  pages = {677--682},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {1469-221X},
  doi = {10.1038/embor.2009.134},
  file = {/home/gabriel/Dropbox/zotero-library/Vasconcelos et al_2009_Discussing plagiarism in Latin American science.pdf},
  journal = {EMBO reports},
  number = {7}
}

@misc{vasconcelos2013,
  title = {Integridade Em Pesquisa e o Papel Institucional: The Time Has Come! | {{SciELO}} Em {{Perspectiva}}},
  shorttitle = {Integridade Em Pesquisa e o Papel Institucional},
  author = {Vasconcelos, Sonia},
  year = {2013},
  month = sep,
  abstract = {Ao destacar a import\^ancia da realiza\c{c}\~ao da 4\textordfeminine{} Confer\^encia Mundial sobre Integridade na Pesquisa no Brasil em 2015, Sonia Vasconcelos real\c{c}a o reconhecimento do},
  language = {en-US}
}

@article{vasconcelos2015,
  title = {Brazilian {{Science}} and {{Research Integrity}}: {{Where}} Are {{We}}? {{What Next}}?},
  shorttitle = {Brazilian {{Science}} and {{Research Integrity}}},
  author = {Vasconcelos, Sonia M. R. and Sorenson, Martha M. and Watanabe, Edson H. and Foguel, Debora and Pal{\'a}cios, Marisa},
  year = {2015-Apr-Jun},
  volume = {87},
  pages = {1259--1269},
  publisher = {{Academia Brasileira de Ci\^encias}},
  issn = {0001-3765, 0001-3765, 1678-2690},
  doi = {10.1590/0001-3765201520150165},
  abstract = {Building a world-class scientific community requires first-class ingredients at many different levels: funding, training, management, international collaborations, creativity, ethics, and an understanding of research integrity practices. All over the world, addressing these practices has been high on the science policy agenda of major research systems. Universities have a central role in fostering a culture of research integrity, which has posed additional challenges for faculty, students and administrators - but also opportunities. In Brazil, the leading universities and governmental funding agencies are collaborating on this project, but much remains to be done.},
  file = {/home/gabriel/Dropbox/zotero-library/Vasconcelos et al_2015_Brazilian Science and Research Integrity.pdf},
  journal = {Anais da Academia Brasileira de Ci\^encias},
  keywords = {4th World Conference on Research Integrity,academic integrity,international collaborations,research ethics education,Responsible conduct of research,science policy},
  language = {en}
}

@article{vilaca2015,
  title = {{Coment\'arios sobre avalia\c{c}\~ao, press\~ao por publica\c{c}\~ao, produtivismo acad\^emico e \'etica cient\'ifica}},
  author = {Vila{\c c}a, Murilo Mariano and Palma, Alexandre},
  year = {2015-Oct-Dec},
  volume = {45},
  pages = {794--816},
  publisher = {{Funda\c{c}\~ao Carlos Chagas}},
  issn = {0100-1574, 0100-1574, 1980-5314},
  doi = {10.1590/198053142836},
  abstract = {Aceitando o convite feito pelo autor, nosso coment\'ario ao artigo de Moys\'es Kuhlmann Jr. (2014) tem o objetivo de qualificar um debate. Seguindo a divis\~ao do artigo, expomos nossos pontos de desacordo e acordo em duas partes. Na primeira, contra a desqualifica\c{c}\~ao do debate, analisamos os argumentos e as afirma\c{c}\~oes presentes no artigo, fundamentando-nos em refer\^encias dos estudos filos\'oficos acerca dos usos argumentativo, ret\'orico e ilocucion\'ario/perlocucion\'ario da linguagem. Por meio do termo fal\'acia, utilizado pelo autor, problematizamos uma tend\^encia presente no debate e postulamos a distin\c{c}\~ao entre an\'alise cr\'itica e t\'atica de desqualifica\c{c}\~ao. Na segunda parte, pela qualifica\c{c}\~ao do debate, reiteramos pontos destacados pelo autor, apresentando contribui\c{c}\~oes para um debate em aberto.},
  file = {/home/gabriel/Dropbox/zotero-library/Vilaça_Palma_2015_Comentários sobre avaliação, pressão por publicação, produtivismo acadêmico e.pdf},
  journal = {Cadernos de Pesquisa},
  keywords = {Avaliação da Pós-Graduação,Ética Científica,Pressão por Publicação,Produtivismo},
  language = {pt}
}

@article{wallin2005,
  title = {Bibliometric {{Methods}}: {{Pitfalls}} and {{Possibilities}}},
  shorttitle = {Bibliometric {{Methods}}},
  author = {Wallin, Johan A.},
  year = {2005},
  volume = {97},
  pages = {261--275},
  issn = {1742-7843},
  doi = {10.1111/j.1742-7843.2005.pto_139.x},
  abstract = {Abstract: Bibliometric studies are increasingly being used for research assessment. Bibliometric indicators are strongly methodology-dependent but for all of them, various types of data normalization are an indispensable requirement. Bibliometric studies have many pitfalls; technical skill, critical sense and a precise knowledge about the examined scientific domain are required to carry out and interpret bibliometric investigations correctly.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1742-7843.2005.pto\_139.x},
  file = {/home/gabriel/Dropbox/zotero-library/Wallin_2005_Bibliometric Methods.pdf},
  journal = {Basic \& Clinical Pharmacology \& Toxicology},
  keywords = {done},
  language = {en},
  number = {5}
}

@article{waltman2016,
  title = {A Review of the Literature on Citation Impact Indicators},
  author = {Waltman, Ludo},
  year = {2016},
  month = may,
  volume = {10},
  pages = {365--391},
  issn = {1751-1577},
  doi = {10.1016/j.joi.2016.02.007},
  abstract = {Citation impact indicators nowadays play an important role in research evaluation, and consequently these indicators have received a lot of attention in the bibliometric and scientometric literature. This paper provides an in-depth review of the literature on citation impact indicators. First, an overview is given of the literature on bibliographic databases that can be used to calculate citation impact indicators (Web of Science, Scopus, and Google Scholar). Next, selected topics in the literature on citation impact indicators are reviewed in detail. The first topic is the selection of publications and citations to be included in the calculation of citation impact indicators. The second topic is the normalization of citation impact indicators, in particular normalization for field differences. Counting methods for dealing with co-authored publications are the third topic, and citation impact indicators for journals are the last topic. The paper concludes by offering some recommendations for future research.},
  file = {/home/gabriel/Dropbox/zotero-library/Waltman_2016_A review of the literature on citation impact indicators.pdf},
  journal = {Journal of Informetrics},
  keywords = {Bibliographic database,Citation analysis,Citation impact indicator,Counting method,fav,Normalization,todo},
  language = {en},
  number = {2}
}

@article{wang2019,
  title = {Which Can Better Predict the Future Success of Articles? {{Bibliometric}} Indices or Alternative Metrics},
  shorttitle = {Which Can Better Predict the Future Success of Articles?},
  author = {Wang, Mingyang and Wang, Zhenyu and Chen, Guangsheng},
  year = {2019},
  month = jun,
  volume = {119},
  pages = {1575--1595},
  issn = {0138-9130, 1588-2861},
  doi = {10.1007/s11192-019-03052-9},
  abstract = {In this paper, we made a survey on the prediction capability of bibliometric indices and alternative metrics on the future success of articles by establishing a machine learning framework. Twenty-three bibliometric and alternative indices were collected to establish the feature space for the predication task. In order to eliminate the possible redundancy in feature space, three feature selection techniques of Relief-F, principal component analysis and entropy weighted method were used to rank the features according to their contribution to the original data set. Combining the fractal dimension of the data set, the intrinsic features which can better represent the original feature space were extracted. Three classifiers of Na\"ive Bayes, KNN and random forest were performed to detect the classification performance of these features. Experimental results show that both bibliometric indices and alternative metrics are beneficial to articles' growth. Early citation features, early Web usage statistics, as well as the reputation of the first author are the most valuable indicators in making an article more influential in the future.},
  file = {/home/gabriel/Dropbox/zotero-library/Wang et al_2019_Which can better predict the future success of articles.pdf},
  journal = {Scientometrics},
  keywords = {done},
  language = {en},
  number = {3}
}

@article{wang2021,
  title = {Identifying 'seed' Papers in Sciences},
  author = {Wang, Jean J. and Shao, Sarah X. and Ye, Fred Y.},
  year = {2021},
  month = apr,
  issn = {1588-2861},
  doi = {10.1007/s11192-021-03980-5},
  abstract = {A concise quantitative method is established for identifying `seed' papers in sciences. The method is set up following h-type metrics based on co-citation network analysis. With defining original-seed (O-Seed) and dominant-seed (D-Seed) by measurable h-strength and second-order h-type degree centrality, O-seed resembles to be a `root' and D-seed develops to become `stem'. Using dataset from Web of Science (WoS), the `seed' papers in research fields of graphene, genome editing, and h-set studies are identified. Graphene D-Seed paper and genome editing D-Seed paper are representative outputs of the 2010 Nobel Prize in Physics and the 2020 Nobel Prize in Chemistry respectively. H-set O-Seed and D-Seed are the same paper that first proposed the concept of h-index. The `seed' papers are characterized by not only high citations, but also network structure and core function in sciences.},
  file = {/home/gabriel/Dropbox/zotero-library/Wang et al_2021_Identifying 'seed' papers in sciences.pdf},
  journal = {Scientometrics},
  language = {en}
}

@article{wicherts2016,
  title = {Peer {{Review Quality}} and {{Transparency}} of the {{Peer}}-{{Review Process}} in {{Open Access}} and {{Subscription Journals}}},
  author = {Wicherts, Jelte M.},
  year = {2016},
  volume = {11},
  pages = {e0147913},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0147913},
  abstract = {BACKGROUND: Recent controversies highlighting substandard peer review in Open Access (OA) and traditional (subscription) journals have increased the need for authors, funders, publishers, and institutions to assure quality of peer-review in academic journals. I propose that transparency of the peer-review process may be seen as an indicator of the quality of peer-review, and develop and validate a tool enabling different stakeholders to assess transparency of the peer-review process. METHODS AND FINDINGS: Based on editorial guidelines and best practices, I developed a 14-item tool to rate transparency of the peer-review process on the basis of journals' websites. In Study 1, a random sample of 231 authors of papers in 92 subscription journals in different fields rated transparency of the journals that published their work. Authors' ratings of the transparency were positively associated with quality of the peer-review process but unrelated to journal's impact factors. In Study 2, 20 experts on OA publishing assessed the transparency of established (non-OA) journals, OA journals categorized as being published by potential predatory publishers, and journals from the Directory of Open Access Journals (DOAJ). Results show high reliability across items ({$\alpha$} = .91) and sufficient reliability across raters. Ratings differentiated the three types of journals well. In Study 3, academic librarians rated a random sample of 140 DOAJ journals and another 54 journals that had received a hoax paper written by Bohannon to test peer-review quality. Journals with higher transparency ratings were less likely to accept the flawed paper and showed higher impact as measured by the h5 index from Google Scholar. CONCLUSIONS: The tool to assess transparency of the peer-review process at academic journals shows promising reliability and validity. The transparency of the peer-review process can be seen as an indicator of peer-review quality allowing the tool to be used to predict academic quality in new journals.},
  file = {/home/gabriel/Dropbox/zotero-library/Wicherts_2016_Peer Review Quality and Transparency of the Peer-Review Process in Open Access.pdf},
  journal = {PloS One},
  keywords = {Access to Information,Bibliometrics,Biomedical Research,Editorial Policies,Humans,Peer Review; Research,Periodicals as Topic,Quality Control},
  language = {eng},
  number = {1},
  pmcid = {PMC4732690},
  pmid = {26824759}
}

@article{williams2017,
  title = {Altmetrics: An Overview and Evaluation},
  shorttitle = {Altmetrics},
  author = {Williams, Ann E.},
  year = {2017},
  month = jan,
  volume = {41},
  pages = {311--317},
  publisher = {{Emerald Publishing Limited}},
  issn = {1468-4527},
  doi = {10.1108/OIR-10-2016-0294},
  abstract = {Purpose The purpose of this paper is to provide an overview and critique of altmetrics, an understudied yet increasingly important arena of study for scholars, academics, and professional researchers. Design/methodology/approach The paper is organized into six parts: the first defines altmetrics; the second examines how altmetrics work; the third presents multiple typologies under which altmetrics can be classified and studied; the fourth details the technological capabilities of altmetrics; the fifth presents a critical evaluation of the ``pros and cons'' of altmetrics; and, the sixth outlines some directions for future and ongoing research. Findings The conclusions detail the strengths and limitations of altmetrics and point toward avenues for continued research and development. Originality/value This paper is among the first to provide a substantive review and evaluation of altmetrics for academics to consider when adopting, utilizing, and researching these tools.},
  file = {/home/gabriel/Dropbox/zotero-library/Williams_2017_Altmetrics.pdf},
  journal = {Online Information Review},
  keywords = {Academic networks,Altmetrics,Research impact,todo},
  number = {3}
}

@article{zancanaro2015,
  title = {A Bibliometric Mapping of Open Educational Resources},
  author = {Zancanaro, Airton and Todesco, Jos{\'e} Leomar and Ramos, Fernando},
  year = {2015},
  month = jan,
  volume = {16},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v16i1.1960},
  abstract = {Open educational resources (OER) is a topic that has aroused increasing interest by researchers as a powerful contribution to improve the educational system quality and openness, both in face to face and distance education. The goal of this research is to map publications related to OER, dating from 2002 to 2013, and available through the Web of Science and Scopus scientific databases as well as in the OER Knowledge Cloud open repository. Data were used to explore relevant aspects related to the scientific production in OER, such as: (i) number of publications per year; (ii) most cited publications; (iii) authors with higher number of publications; (iv) institutions and countries with more publications and (v) most referenced bibliography by the authors. The analysis has included 544 papers, written by 843 authors, from 338 institutions, from 61 different countries. Moreover, the analysis has included the publications referenced and the author's keywords, considering 6,355 different publications and 929 different keywords. Besides presenting a bibliographic mapping of the research on OER, this paper also intends to contribute to consolidate the idea that OER is a promising field for researchers, in line with the spreading of the Open movement.},
  file = {/home/gabriel/Dropbox/zotero-library/Zancanaro et al_2015_A bibliometric mapping of open educational resources.pdf},
  journal = {The International Review of Research in Open and Distributed Learning},
  language = {en},
  number = {1}
}

@article{zhang2021,
  title = {Does Open Data Boost Journal Impact: Evidence from {{Chinese}} Economics},
  shorttitle = {Does Open Data Boost Journal Impact},
  author = {Zhang, Liwei and Ma, Liang},
  year = {2021},
  month = apr,
  volume = {126},
  pages = {3393--3419},
  issn = {1588-2861},
  doi = {10.1007/s11192-021-03897-z},
  abstract = {To encourage research transparency and replication, more and more journals have been requiring authors to share original datasets and analytic procedures supporting their publications. Does open data boost journal impact? In this article, we report one of the first empirical studies to assess the effects of open data on journal impact. China Industrial Economics (CIE) mandated authors to open their research data in the end of 2016, which is the first to embrace open data among Chinese journals and provides a natural experiment for policy evaluation. We use the data of 37 Chinese economics journals from 2001 to 2019 and apply synthetic control method to causally estimate the effects of open data, and our results show that open data has significantly increased the citations of journal articles. On average, the current- and second-year citations of articles published with CIE have increased by 1\,\textasciitilde\,4 times, and articles published before the open data policy also benefited from the spillover effect. Our findings suggest that journals can leverage compulsory open data to develop reputation and amplify academic impacts.},
  file = {/home/gabriel/Dropbox/zotero-library/Zhang_Ma_2021_Does open data boost journal impact.pdf},
  journal = {Scientometrics},
  language = {en},
  number = {4}
}

@misc{zotero-1031,
  title = {Altmetrics in {{Evolution}}: {{Defining}} and {{Redefining}} the {{Ontology}} of {{Article}}-{{Level Metrics}} | {{Request PDF}}},
  file = {/home/gabriel/Dropbox/zotero-library/Altmetrics in Evolution.pdf},
  howpublished = {https://www.researchgate.net/publication/270156387\_Altmetrics\_in\_Evolution\_Defining\_and\_Redefining\_the\_Ontology\_of\_Article-Level\_Metrics},
  keywords = {todo}
}

@misc{zotero-1131,
  title = {Biblioteca {{Digital}} Do {{IPG}}: {{M\'etricas}} de {{Informa\c{c}\~ao}}: {{O}} Fator de Impacto Na Pr\'atica},
  howpublished = {http://bdigital.ipg.pt/dspace/handle/10314/3371}
}

@misc{zotero-1266,
  title = {How Young Researchers Can Re-Shape the Evaluation of Their Work},
  abstract = {Looking beyond bibliometrics to evaluate success.},
  howpublished = {https://www.natureindex.com/news-blog/how-young-researchers-can-re-shape-research-evaluation-universities}
}

@misc{zotero-886,
  title = {{{SCIENTOMETRICS}}, {{TECHNIQUES}}, {{SOURCES AND THEIR KEY POINTS TO ANALYSIS OF LIS RESEARCH}}: {{AN OVERVIEW}}},
  file = {/home/gabriel/Dropbox/zotero-library/SCIENTOMETRICS, TECHNIQUES, SOURCES AND THEIR KEY POINTS TO ANALYSIS OF LIS.pdf},
  howpublished = {https://scholar.googleusercontent.com/scholar?q=cache:yGZ8PRdKnlUJ:scholar.google.com/+softwares+in+scientometrics+research\&hl=en\&as\_sdt=0,5\&as\_ylo=2017},
  keywords = {todo}
}

@misc{zotero-891,
  title = {Scientometrics of {{Scientometrics}}: {{Mapping Historical Footprint}} and {{Emerging Technologies}} in {{Scientometrics}} | {{IntechOpen}}},
  file = {/home/gabriel/Dropbox/zotero-library/Scientometrics of Scientometrics.pdf},
  howpublished = {https://www.intechopen.com/books/scientometrics/scientometrics-of-scientometrics-mapping-historical-footprint-and-emerging-technologies-in-scientome},
  keywords = {todo}
}

@misc{zotero-904,
  title = {Scientometrics - {{Google Books}}},
  howpublished = {https://books.google.com.br/books?hl=en\&lr=\&id=fy6RDwAAQBAJ\&oi=fnd\&pg=PA9\&dq=scientometrics+history\&ots=JdBDtDm1dv\&sig=q08qlZYAf0noJpk6IAZP125rdaQ\#v=onepage\&q=scientometrics\%20history\&f=false}
}

@misc{zotero-983,
  title = {{{BLDE University Journal}} of {{Health Sciences}} - {{Citation}} Impact: {{Manipulation}} and Monopoly : {{Download PDF}}},
  howpublished = {https://www.bldeujournalhs.in/downloadpdf.asp?issn=2468-838X;year=2017;volume=2;issue=2;spage=67;epage=68;aulast=Das;type=2}
}


